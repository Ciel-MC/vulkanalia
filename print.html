<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Vulkan Tutorial (Rust)</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="overview.html"><strong aria-hidden="true">2.</strong> Overview</a></li><li class="chapter-item expanded "><a href="development_environment.html"><strong aria-hidden="true">3.</strong> Development environment</a></li><li class="chapter-item expanded "><a href="faq.html"><strong aria-hidden="true">4.</strong> FAQ</a></li><li class="chapter-item expanded affix "><li class="part-title">Setup</li><li class="chapter-item expanded "><a href="setup/base_code.html"><strong aria-hidden="true">5.</strong> Base code</a></li><li class="chapter-item expanded "><a href="setup/instance.html"><strong aria-hidden="true">6.</strong> Instance</a></li><li class="chapter-item expanded "><a href="setup/validation_layers.html"><strong aria-hidden="true">7.</strong> Validation layers</a></li><li class="chapter-item expanded "><a href="setup/physical_devices_and_queue_families.html"><strong aria-hidden="true">8.</strong> Physical devices and queue families</a></li><li class="chapter-item expanded "><a href="setup/logical_device_and_queues.html"><strong aria-hidden="true">9.</strong> Logical device and queues</a></li><li class="chapter-item expanded affix "><li class="part-title">Presentation</li><li class="chapter-item expanded "><a href="presentation/window_surface.html"><strong aria-hidden="true">10.</strong> Window surface</a></li><li class="chapter-item expanded "><a href="presentation/swapchain.html"><strong aria-hidden="true">11.</strong> Swapchain</a></li><li class="chapter-item expanded "><a href="presentation/image_views.html"><strong aria-hidden="true">12.</strong> Image views</a></li><li class="chapter-item expanded affix "><li class="part-title">Pipeline</li><li class="chapter-item expanded "><a href="pipeline/introduction.html"><strong aria-hidden="true">13.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="pipeline/shader_modules.html"><strong aria-hidden="true">14.</strong> Shader modules</a></li><li class="chapter-item expanded "><a href="pipeline/fixed_functions.html"><strong aria-hidden="true">15.</strong> Fixed functions</a></li><li class="chapter-item expanded "><a href="pipeline/render_passes.html"><strong aria-hidden="true">16.</strong> Render passes</a></li><li class="chapter-item expanded "><a href="pipeline/conclusion.html"><strong aria-hidden="true">17.</strong> Conclusion</a></li><li class="chapter-item expanded affix "><li class="part-title">Drawing</li><li class="chapter-item expanded "><a href="drawing/framebuffers.html"><strong aria-hidden="true">18.</strong> Framebuffers</a></li><li class="chapter-item expanded "><a href="drawing/command_buffers.html"><strong aria-hidden="true">19.</strong> Command buffers</a></li><li class="chapter-item expanded "><a href="drawing/rendering_and_presentation.html"><strong aria-hidden="true">20.</strong> Rendering and presentation</a></li><li class="chapter-item expanded affix "><li class="part-title">Swapchain</li><li class="chapter-item expanded "><a href="swapchain/recreation.html"><strong aria-hidden="true">21.</strong> Recreation</a></li><li class="chapter-item expanded affix "><li class="part-title">Vertex buffers</li><li class="chapter-item expanded "><a href="vertex/vertex_input_description.html"><strong aria-hidden="true">22.</strong> Vertex input description</a></li><li class="chapter-item expanded "><a href="vertex/vertex_buffer_creation.html"><strong aria-hidden="true">23.</strong> Vertex buffer creation</a></li><li class="chapter-item expanded "><a href="vertex/staging_buffer.html"><strong aria-hidden="true">24.</strong> Staging buffer</a></li><li class="chapter-item expanded "><a href="vertex/index_buffer.html"><strong aria-hidden="true">25.</strong> Index buffer</a></li><li class="chapter-item expanded affix "><li class="part-title">Uniform buffers</li><li class="chapter-item expanded "><a href="uniform/descriptor_layout_and_buffer.html"><strong aria-hidden="true">26.</strong> Descriptor layout and buffer</a></li><li class="chapter-item expanded "><a href="uniform/descriptor_pool_and_sets.html"><strong aria-hidden="true">27.</strong> Descriptor pool and sets</a></li><li class="chapter-item expanded affix "><li class="part-title">Texture mapping</li><li class="chapter-item expanded "><a href="texture/images.html"><strong aria-hidden="true">28.</strong> Images</a></li><li class="chapter-item expanded "><a href="texture/image_view_and_sampler.html"><strong aria-hidden="true">29.</strong> Image view and sampler</a></li><li class="chapter-item expanded "><a href="texture/combined_image_sampler.html"><strong aria-hidden="true">30.</strong> Combined image sampler</a></li><li class="chapter-item expanded affix "><li class="part-title">Model</li><li class="chapter-item expanded "><a href="model/depth_buffering.html"><strong aria-hidden="true">31.</strong> Depth buffering</a></li><li class="chapter-item expanded "><a href="model/loading_models.html"><strong aria-hidden="true">32.</strong> Loading models</a></li><li class="chapter-item expanded affix "><li class="part-title">Advanced</li><li class="chapter-item expanded "><a href="advanced/generating_mipmaps.html"><strong aria-hidden="true">33.</strong> Generating mipmaps</a></li><li class="chapter-item expanded "><a href="advanced/multisampling.html"><strong aria-hidden="true">34.</strong> Multisampling</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                    </div>

                    <h1 class="menu-title">Vulkan Tutorial (Rust)</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        <a href="https://github.com/KyleMayes/vulkanalia" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#introduction" id="introduction">Introduction</a></h1>
<p>This tutorial is an adaptation of <a href="https://vulkan-tutorial.com">https://vulkan-tutorial.com</a> to use Rust instead of C/C++.</p>
<p>The vast majority of the credit for this tutorial should go the author of <a href="https://vulkan-tutorial.com">https://vulkan-tutorial.com</a>, <a href="https://github.com/Overv">Alexander Overvoorde</a>.</p>
<h2><a class="header" href="#about" id="about">About</a></h2>
<p>This tutorial will teach you the basics of using the <a href="https://www.khronos.org/vulkan/">Vulkan</a> graphics and compute API. Vulkan is a new API by the <a href="https://www.khronos.org/">Khronos group</a> (known for OpenGL) that provides a much better abstraction of modern graphics cards. This new interface allows you to better describe what your application intends to do, which can lead to better performance and less surprising driver behavior compared to existing APIs like <a href="https://en.wikipedia.org/wiki/OpenGL">OpenGL</a> and <a href="https://en.wikipedia.org/wiki/Direct3D">Direct3D</a>. The ideas behind Vulkan are similar to those of <a href="https://en.wikipedia.org/wiki/Direct3D#Direct3D_12">Direct3D 12</a> and <a href="https://en.wikipedia.org/wiki/Metal_(API)">Metal</a>, but Vulkan has the advantage of being fully cross-platform and allows you to develop for Windows, Linux and Android at the same time (and iOS and macOS via <a href="https://github.com/KhronosGroup/MoltenVK">MoltenVK</a>).</p>
<p>However, the price you pay for these benefits is that you have to work with a significantly more verbose API. Every detail related to the graphics API needs to be set up from scratch by your application, including initial frame buffer creation and memory management for objects like buffers and texture images. The graphics driver will do a lot less hand holding, which means that you will have to do more work in your application to ensure correct behavior.</p>
<p>The takeaway message here is that Vulkan is not for everyone. It is targeted at programmers who are enthusiastic about high performance computer graphics, and are willing to put some work in. If you are more interested in game development, rather than computer graphics, then you may wish to stick to OpenGL or Direct3D, which will not be deprecated in favor of Vulkan anytime soon. Another alternative is to use an engine like <a href="https://en.wikipedia.org/wiki/Unreal_Engine#Unreal_Engine_4">Unreal Engine</a> or <a href="https://en.wikipedia.org/wiki/Unity_(game_engine)">Unity</a>, which will be able to use Vulkan while exposing a much higher level API to you.</p>
<p>With that out of the way, let's cover some prerequisites for following this tutorial:</p>
<ul>
<li>A graphics card and driver compatible with Vulkan (<a href="https://developer.nvidia.com/vulkan-driver">NVIDIA</a>, <a href="http://www.amd.com/en-us/innovations/software-technologies/technologies-gaming/vulkan">AMD</a>, <a href="https://software.intel.com/en-us/blogs/2016/03/14/new-intel-vulkan-beta-1540204404-graphics-driver-for-windows-78110-1540">Intel</a>)</li>
<li>Experience with Rust</li>
<li>Rust 1.47 or later</li>
<li>Some existing experience with 3D computer graphics</li>
</ul>
<p>This tutorial will not assume knowledge of OpenGL or Direct3D concepts, but it does require you to know the basics of 3D computer graphics. It will not explain the math behind perspective projection, for example. See <a href="https://paroj.github.io/gltut/">this online book</a> for a great introduction of computer graphics concepts. Some other great computer graphics resources are:</p>
<ul>
<li><a href="https://github.com/petershirley/raytracinginoneweekend">Ray tracing in one weekend</a></li>
<li><a href="http://www.pbr-book.org/">Physically Based Rendering book</a></li>
<li>Vulkan being used in a real engine in the open-source <a href="https://github.com/Novum/vkQuake">Quake</a> and <a href="https://github.com/DustinHLand/vkDOOM3">DOOM 3</a></li>
</ul>
<p>If you want a C or C++ tutorial instead, see the original tutorial: <a href="https://vulkan-tutorial.com">https://vulkan-tutorial.com</a></p>
<p>This tutorial will be using the <a href="https://github.com/KyleMayes/vulkanalia"><code>vulkanalia</code></a> crate to provide access to the Vulkan API from Rust. <code>vulkanalia</code> only provides a thin wrapper over the Vulkan API to make it a bit easier to use from Rust. This means that while you should have never have any difficulty in determining exactly how your Rust programs are interacting with the Vulkan API, you will be shielded from very little of the danger and verbosity of the Vulkan API.</p>
<p>If you want a Rust Vulkan tutorial that uses a crate which provides a safe and relatively concise wrapper around the Vulkan API, see this tutorial: <a href="https://github.com/bwasty/vulkan-tutorial-rs">https://github.com/bwasty/vulkan-tutorial-rs</a></p>
<h2><a class="header" href="#tutorial-structure" id="tutorial-structure">Tutorial structure</a></h2>
<p>We'll start with an overview of how Vulkan works and the work we'll have to do to get the first triangle on the screen. The purpose of all the smaller steps will make more sense after you've understood their basic role in the whole picture. Next, we'll set up the development environment with the <a href="https://lunarg.com/vulkan-sdk/">Vulkan SDK</a>.</p>
<p>After that we'll implement all of the basic components of a Vulkan program that are necessary to render your first triangle. Each chapter will follow roughly the following structure:</p>
<ul>
<li>Introduce a new concept and its purpose</li>
<li>Use all of the relevant API calls to integrate it into your program</li>
<li>Abstract parts of it into helper functions</li>
</ul>
<p>Although each chapter is written as a follow-up on the previous one, it is also possible to read the chapters as standalone articles introducing a certain Vulkan feature. That means that the site is also useful as a reference. All of the Vulkan functions and types are linked to the specification, so you can click them to learn more. Vulkan is a very new API, so there may be some shortcomings in the specification itself. You are encouraged to submit feedback to <a href="https://github.com/KhronosGroup/Vulkan-Docs">this Khronos repository</a>.</p>
<p>As mentioned before, the Vulkan API has a rather verbose API with many parameters to give you maximum control over the graphics hardware. This causes basic operations like creating a texture to take a lot of steps that have to be repeated every time. Therefore we'll be creating our own collection of helper functions throughout the tutorial.</p>
<p>Every chapter will also conclude with a link to the full code listing up to that point. You can refer to it if you have any doubts about the structure of the code, or if you're dealing with a bug and want to compare. All of the code files have been tested on graphics cards from multiple vendors to verify correctness. Each chapter also has a comment section at the end where you can ask any questions that are relevant to the specific subject matter. Please specify your platform, driver version, source code, expected behavior and actual behavior to help us help you.</p>
<p>This tutorial is intended to be a community effort. Vulkan is still a very new API and best practices have not really been established yet. If you have any type of feedback on the tutorial and site itself, then please don't hesitate to submit an issue or pull request to the <a href="https://github.com/KyleMayes/vulkanalia">GitHub repository</a>.</p>
<p>After you've gone through the ritual of drawing your very first Vulkan powered triangle onscreen, we'll start expanding the program to include linear transformations, textures and 3D models.</p>
<p>If you've played with graphics APIs before, then you'll know that there can be a lot of steps until the first geometry shows up on the screen. There are many of these initial steps in Vulkan, but you'll see that each of the individual steps is easy to understand and does not feel redundant. It's also important to keep in mind that once you have that boring looking triangle, drawing fully textured 3D models does not take that much extra work, and each step beyond that point is much more rewarding.</p>
<p>If you encounter any problems while following the tutorial, check the FAQ to see if your problem and its solution is already listed there. Next, you might find someone who had the same problem (if it is not Rust-specific) in the comment section for the corresponding chapter in the <a href="https://vulkan-tutorial.com/">original tutorial</a>.</p>
<h1><a class="header" href="#overview" id="overview">Overview</a></h1>
<p>This chapter will start off with an introduction of Vulkan and the problems it addresses. After that we're going to look at the ingredients that are required for the first triangle. This will give you a big picture to place each of the subsequent chapters in. We will conclude by covering the structure of the Vulkan API as implemented by <code>vulkanalia</code>.</p>
<h2><a class="header" href="#origin-of-vulkan" id="origin-of-vulkan">Origin of Vulkan</a></h2>
<p>Just like the previous graphics APIs, Vulkan is designed as a cross-platform abstraction over <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPUs</a>. The problem with most of these APIs is that the era in which they were designed featured graphics hardware that was mostly limited to configurable fixed functionality. Programmers had to provide the vertex data in a standard format and were at the mercy of the GPU manufacturers with regards to lighting and shading options.</p>
<p>As graphics card architectures matured, they started offering more and more programmable functionality. All this new functionality had to be integrated with the existing APIs somehow. This resulted in less than ideal abstractions and a lot of guesswork on the graphics driver side to map the programmer's intent to the modern graphics architectures. That's why there are so many driver updates for improving the performance in games, sometimes by significant margins. Because of the complexity of these drivers, application developers also need to deal with inconsistencies between vendors, like the syntax that is accepted for <a href="https://en.wikipedia.org/wiki/Shader">shaders</a>. Aside from these new features, the past decade also saw an influx of mobile devices with powerful graphics hardware. These mobile GPUs have different architectures based on their energy and space requirements. One such example is <a href="https://en.wikipedia.org/wiki/Tiled_rendering">tiled rendering</a>, which would benefit from improved performance by offering the programmer more control over this functionality. Another limitation originating from the age of these APIs is limited multi-threading support, which can result in a bottleneck on the CPU side.</p>
<p>Vulkan solves these problems by being designed from scratch for modern graphics architectures. It reduces driver overhead by allowing programmers to clearly specify their intent using a more verbose API, and allows multiple threads to create and submit commands in parallel. It reduces inconsistencies in shader compilation by switching to a standardized byte code format with a single compiler. Lastly, it acknowledges the general purpose processing capabilities of modern graphics cards by unifying the graphics and compute functionality into a single API.</p>
<h2><a class="header" href="#what-it-takes-to-draw-a-triangle" id="what-it-takes-to-draw-a-triangle">What it takes to draw a triangle</a></h2>
<p>We'll now look at an overview of all the steps it takes to render a triangle in a well-behaved Vulkan program. All of the concepts introduced here will be elaborated on in the next chapters. This is just to give you a big picture to relate all of the individual components to.</p>
<h3><a class="header" href="#step-1---instance-and-physical-device-selection" id="step-1---instance-and-physical-device-selection">Step 1 - Instance and physical device selection</a></h3>
<p>A Vulkan application starts by setting up the Vulkan API through a <code>VkInstance</code>. An instance is created by describing your application and any API extensions you will be using. After creating the instance, you can query for Vulkan supported hardware and select one or more <code>VkPhysicalDevice</code>s to use for operations. You can query for properties like VRAM size and device capabilities to select desired devices, for example to prefer using dedicated graphics cards.</p>
<h3><a class="header" href="#step-2---logical-device-and-queue-families" id="step-2---logical-device-and-queue-families">Step 2 - Logical device and queue families</a></h3>
<p>After selecting the right hardware device to use, you need to create a <code>VkDevice</code> (logical device), where you describe more specifically which <code>VkPhysicalDeviceFeatures</code> you will be using, like multi-viewport rendering and 64-bit floats. You also need to specify which queue families you would like to use. Most operations performed with Vulkan, like draw commands and memory operations, are asynchronously executed by submitting them to a <code>VkQueue</code>. Queues are allocated from queue families, where each queue family supports a specific set of operations in its queues. For example, there could be separate queue families for graphics, compute and memory transfer operations. The availability of queue families could also be used as a distinguishing factor in physical device selection. It is possible for a device with Vulkan support to not offer any graphics functionality, however all graphics cards with Vulkan support today will generally support all queue operations that we're interested in.</p>
<h3><a class="header" href="#step-3---window-surface-and-swapchain" id="step-3---window-surface-and-swapchain">Step 3 - Window surface and swapchain</a></h3>
<p>Unless you're only interested in offscreen rendering, you will need to create a window to present rendered images to. Windows can be created with the native platform APIs or libraries like <a href="http://www.glfw.org/">GLFW</a>, <a href="https://www.libsdl.org/">SDL</a>, or the <a href="https://github.com/rust-windowing/winit"><code>winit</code></a> crate. We will be using the <code>winit</code> crate in this tutorial, but more about that in the next chapter.</p>
<p>We need two more components to actually render to a window: a window surface (<code>VkSurfaceKHR</code>) and a swapchain (<code>VkSwapchainKHR</code>). Note the <code>KHR</code> postfix, which means that these objects are part of a Vulkan extension. The Vulkan API itself is completely platform agnostic, which is why we need to use the standardized WSI (Window System Interface) extension to interact with the window manager. The surface is a cross-platform abstraction over windows to render to and is generally instantiated by providing a reference to the native window handle, for example <code>HWND</code> on Windows. However, <code>vulkanalia</code> has optional integration with the <code>winit</code> crate which we will be leveraging to handle the platform-specific details of creating a window and associated surface for us.</p>
<p>The swapchain is a collection of render targets. Its basic purpose is to ensure that the image that we're currently rendering to is different from the one that is currently on the screen. This is important to make sure that only complete images are shown. Every time we want to draw a frame we have to ask the swapchain to provide us with an image to render to. When we've finished drawing a frame, the image is returned to the swapchain for it to be presented to the screen at some point. The number of render targets and conditions for presenting finished images to the screen depends on the present mode. Common present modes are  double buffering (vsync) and triple buffering. We'll look into these in the swapchain creation chapter.</p>
<p>Some platforms allow you to render directly to a display without interacting with any window manager through the <code>VK_KHR_display</code> and <code>VK_KHR_display_swapchain</code> extensions. These allow you to create a surface that represents the entire screen and could be used to implement your own window manager, for example.</p>
<h3><a class="header" href="#step-4---image-views-and-framebuffers" id="step-4---image-views-and-framebuffers">Step 4 - Image views and framebuffers</a></h3>
<p>To draw to an image acquired from the swapchain, we have to wrap it into a <code>VkImageView</code> and <code>VkFramebuffer</code>. An image view references a specific part of an image to be used, and a framebuffer references image views that are to be used for color, depth and stencil targets. Because there could be many different images in the swapchain, we'll preemptively create an image view and framebuffer for each of them and select the right one at draw time.</p>
<h3><a class="header" href="#step-5---render-passes" id="step-5---render-passes">Step 5 - Render passes</a></h3>
<p>Render passes in Vulkan describe the type of images that are used during rendering operations, how they will be used, and how their contents should be treated. In our initial triangle rendering application, we'll tell Vulkan that we will use a single image as color target and that we want it to be cleared to a solid color right before the drawing operation. Whereas a render pass only describes the type of images, a <code>VkFramebuffer</code> actually binds specific images to these slots.</p>
<h3><a class="header" href="#step-6---graphics-pipeline" id="step-6---graphics-pipeline">Step 6 - Graphics pipeline</a></h3>
<p>The graphics pipeline in Vulkan is set up by creating a <code>VkPipeline</code> object. It describes the configurable state of the graphics card, like the viewport size and depth buffer operation and the programmable state using <code>VkShaderModule</code> objects. The <code>VkShaderModule</code> objects are created from shader byte code. The driver also needs to know which render targets will be used in the pipeline, which we specify by referencing the render pass.</p>
<p>One of the most distinctive features of Vulkan compared to existing APIs, is that almost all configuration of the graphics pipeline needs to be set in advance. That means that if you want to switch to a different shader or slightly change your vertex layout, then you need to entirely recreate the graphics pipeline. That means that you will have to create many <code>VkPipeline</code> objects in advance for all the different combinations you need for your rendering operations. Only some basic configuration, like viewport size and clear color, can be changed dynamically. All of the state also needs to be described explicitly, there is no default color blend state, for example.</p>
<p>The good news is that because you're doing the equivalent of ahead-of-time compilation versus just-in-time compilation, there are more optimization opportunities for the driver and runtime performance is more predictable, because large state changes like switching to a different graphics pipeline are made very explicit.</p>
<h3><a class="header" href="#step-7---command-pools-and-command-buffers" id="step-7---command-pools-and-command-buffers">Step 7 - Command pools and command buffers</a></h3>
<p>As mentioned earlier, many of the operations in Vulkan that we want to execute, like drawing operations, need to be submitted to a queue. These operations first need to be recorded into a <code>VkCommandBuffer</code> before they can be submitted. These command buffers are allocated from a <code>VkCommandPool</code> that is associated with a specific queue family. To draw a simple triangle, we need to record a command buffer with the following operations:</p>
<ul>
<li>Begin the render pass</li>
<li>Bind the graphics pipeline</li>
<li>Draw 3 vertices</li>
<li>End the render pass</li>
</ul>
<p>Because the image in the framebuffer depends on which specific image the swapchain will give us, we need to record a command buffer for each possible image and select the right one at draw time. The alternative would be to record the command buffer again every frame, which is not as efficient.</p>
<h3><a class="header" href="#step-8---main-loop" id="step-8---main-loop">Step 8 - Main loop</a></h3>
<p>Now that the drawing commands have been wrapped into a command buffer, the main loop is quite straightforward. We first acquire an image from the swapchain with <code>vkAcquireNextImageKHR</code>. We can then select the appropriate command buffer for that image and execute it with <code>vkQueueSubmit</code>. Finally, we return the image to the swapchain for presentation to the screen with <code>vkQueuePresentKHR</code>.</p>
<p>Operations that are submitted to queues are executed asynchronously. Therefore we have to use synchronization objects like semaphores to ensure a correct order of execution. Execution of the draw command buffer must be set up to wait on image acquisition to finish, otherwise it may occur that we start rendering to an image that is still being read for presentation on the screen. The <code>vkQueuePresentKHR</code> call in turn needs to wait for rendering to be finished, for which we'll use a second semaphore that is signaled after rendering completes.</p>
<h3><a class="header" href="#summary" id="summary">Summary</a></h3>
<p>This whirlwind tour should give you a basic understanding of the work ahead for drawing the first triangle. A real-world program contains more steps, like allocating vertex buffers, creating uniform buffers and uploading texture images that will be covered in subsequent chapters, but we'll start simple because Vulkan has enough of a steep learning curve as it is. Note that we'll cheat a bit by initially embedding the vertex coordinates in the vertex shader instead of using a vertex buffer. That's because managing vertex buffers requires some familiarity with command buffers first.</p>
<p>So in short, to draw the first triangle we need to:</p>
<ul>
<li>Create a <code>VkInstance</code></li>
<li>Select a supported graphics card (<code>VkPhysicalDevice</code>)</li>
<li>Create a <code>VkDevice</code> and <code>VkQueue</code> for drawing and presentation</li>
<li>Create a window, window surface and swapchain</li>
<li>Wrap the swapchain images into <code>VkImageView</code></li>
<li>Create a render pass that specifies the render targets and usage</li>
<li>Create framebuffers for the render pass</li>
<li>Set up the graphics pipeline</li>
<li>Allocate and record a command buffer with the draw commands for every possible swapchain image</li>
<li>Draw frames by acquiring images, submitting the right draw command buffer and returning the images back to the swapchain</li>
</ul>
<p>It's a lot of steps, but the purpose of each individual step will be made very simple and clear in the upcoming chapters. If you're confused about the relation of a single step compared to the whole program, you should refer back to this chapter.</p>
<h2><a class="header" href="#api-concepts" id="api-concepts">API concepts</a></h2>
<p>The Vulkan API is defined in terms of the C programming language. This API is defined in the Vulkan API Registry which is <a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/xml/vk.xml">an XML file</a> which serves the purpose of being a machine readable definition of the Vulkan API.</p>
<p>The Vulkan <a href="https://github.com/KhronosGroup/Vulkan-Headers">C and C++ headers</a> that are part of the Vulkan SDK you will be installing in the next chapter are generated from this Vulkan API Registry. However, we will not be using these headers, directly or indirectly, because <code>vulkanalia</code> includes a Rust interface to the Vulkan API generated from the Vulkan API registry.</p>
<p>Underneath <code>vulkanalia</code> is the <a href="https://docs.rs/vulkanalia-sys"><code>vulkanalia-sys</code></a> crate which defines the raw types (commands, enums, bitmasks, structs, etc.) defined by the Vulkan API Registry. These raw types are re-exported from the <code>vulkanalia</code> crate in the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/index.html"><code>vk</code></a> module along with some other types generated from the Vulkan API Registry which allow for somewhat simpler and less error-prone usage of the Vulkan API from Rust.</p>
<h3><a class="header" href="#type-names" id="type-names">Type Names</a></h3>
<p>Because Rust has support for namespaces unlike C, the <code>vulkanalia</code> API omits the parts of Vulkan type names that are used for namespacing purposes in C. Types such as structs, unions, and enums lose their <code>Vk</code> prefix (e.g., <code>VkInstance</code> becomes <code>vk::Instance</code> where <code>vk</code> is the the module of the same name in <code>vulkanalia</code>).</p>
<h3><a class="header" href="#enums" id="enums">Enums</a></h3>
<p>Vulkan enums are modeled as structs and the enum values are modeled as associated constants on the struct. Rust enums are not used to model Vulkan enums because use of Rust enums in FFI can lead to <a href="https://github.com/rust-lang/rust/issues/36927">undefined behavior</a>.</p>
<p>Since we don't need to worry about name conflicts between the enum values for different enums (or different libraries), the portions of the enum value names used for namespacing purposes are omitted.</p>
<p>For example, the <code>VK_OBJECT_TYPE_INSTANCE</code> enum value is the <code>INSTANCE</code> value for the <code>VkObjectType</code> enum. In <code>vulkanalia</code>, this enum value becomes <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.ObjectType.html#associatedconstant.INSTANCE"><code>vk::ObjectType::INSTANCE</code></a>.</p>
<h3><a class="header" href="#bitmasks" id="bitmasks">Bitmasks</a></h3>
<p>Vulkan bitmasks are modeled as structs with the bitflags as associated constants (similarly to enums) which are generated by the <code>bitflags!</code> macro from the <a href="https://github.com/bitflags/bitflags"><code>bitflags</code></a> crate.</p>
<p>Like with enums values, the portions of bitmask names used for namespacing purposes are omitted.</p>
<p>For example, the <code>VK_BUFFER_USAGE_TRANSFER_SRC_BIT</code> bitflag is the <code>TRANSFER_SRC</code> bitflag for the <code>VkBufferUsageFlags</code> bitmask. In <code>vulkanalia</code>, this becomes <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.BufferUsageFlags.html#associatedconstant.TRANSFER_SRC"><code>vk::BufferUsageFlags::TRANSFER_SRC</code></a>.</p>
<h3><a class="header" href="#commands" id="commands">Commands</a></h3>
<p>The raw Vulkan commands are defined in <code>vulkanalia</code> with the <code>PFN_</code> (pointer to function) prefix. So <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/type.PFN_vkEnumerateInstanceExtensionProperties.html"><code>vk::PFN_vkEnumerateInstanceExtensionProperties</code></a> refers to a function pointer for the <code>vkEnumerateInstanceExtensionProperties</code> Vulkan command.</p>
<p>If we want to actually call these Vulkan commands, we first need to load them. Vulkan commands are loaded by and stored in four structs, the contents of which are determined by how those commands are loaded. Only two Vulkan commands are directly loaded from a Vulkan shared library, <code>vkGetInstanceProcAddr</code> and <code>vkGetDeviceProcAddr</code>. These commands are then used to load all of the other Vulkan commands. The four structs are (note that Vulkan instances and devices are a topic that will be covered in future chapters):</p>
<ul>
<li><a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.StaticCommands.html"><code>vk::StaticCommands</code></a> – the Vulkan commands listed above which are loaded directly from a Vulkan shared library</li>
<li><a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.EntryCommands.html"><code>vk::EntryCommands</code></a> – the Vulkan commands loaded using <code>vkGetInstanceProcAddr</code> and a null Vulkan instance (i.e., Vulkan commands not tied to a particular Vulkan instance)</li>
<li><a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.InstanceCommands.html"><code>vk::InstanceCommands</code></a> – the Vulkan commands loaded using <code>vkGetInstanceProcAddr</code> and a valid Vulkan instance</li>
<li><a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.DeviceCommands.html"><code>vk::DeviceCommands</code></a> – the Vulkan commands loaded using <code>vkGetDeviceProcAddr</code> and a valid Vulkan device</li>
</ul>
<p>These structs allow you to easily load and call raw Vulkan commands from Rust, but <code>vulkanalia</code> offers wrappers around the raw Vulkan commands which make calling them from Rust easier and less error-prone.</p>
<h3><a class="header" href="#command-wrappers" id="command-wrappers">Command wrappers</a></h3>
<p>An example of a typical Vulkan command signature looks like this in C:</p>
<pre><code class="language-c">VkResult vkEnumerateInstanceExtensionProperties(
    const char* pLayerName,
    uint32_t* pPropertyCount,
    VkExtensionProperties* pProperties
);
</code></pre>
<p>Someone who is familiar with the conventions of the Vulkan API could quickly see how this command is supposed to be used from this signature alone despite it not including some key information.</p>
<p>For those new to the Vulkan API, a look at the <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/vkEnumerateDeviceExtensionProperties.html">documentation</a> for this command will be more illuminating. The description of the behavior of this command in the documentation suggests that using this command to list the available extensions will be a multi-step process:</p>
<ol>
<li>Call the command to get the number of extensions</li>
<li>Allocate a buffer that can contain the specified number of extensions</li>
<li>Call the command again to populate the buffer with the extensions</li>
</ol>
<p>So in C++, this might look like this (ignoring the result of the command for simplicity):</p>
<pre><code class="language-c++">// 1.
uint32_t pPropertyCount;
vkEnumerateInstanceExtensionProperties(NULL, &amp;pPropertyCount, NULL);

// 2.
std::vector&lt;VkExtensionProperties&gt; pProperties{pPropertyCount};

// 3.
vkEnumerateInstanceExtensionProperties(NULL, &amp;pPropertyCount, pProperties.data());
</code></pre>
<p>The Rust signature for the command wrapper looks like this:</p>
<pre><code class="language-rust noplaypen">fn enumerate_instance_extension_properties(
    &amp;self,
    layer_name: Option&lt;&amp;[u8]&gt;,
) -&gt; VkResult&lt;Vec&lt;ExtensionProperties&gt;&gt;;
</code></pre>
<p>These command wrappers simplify usage of Vulkan commands by handling the need to call some commands twice such as in this case as well as capturing the fallibility of the underlying command by returning a (Rust) <code>Result</code> (<a href="https://docs.rs/vulkanalia/latest/vulkanalia/type.VkResult.html"><code>VkResult&lt;T&gt;</code></a> in this case is a type alias for <code>Result&lt;T, vk::Result&gt;</code>). Note that the <code>layer_name</code> argument is optional, a fact which is defined by the Vulkan API Registry but cannot be indicated by a C function signature alone.</p>
<p>You likely noticed the <code>&amp;self</code> parameter in the above command wrapper. These command wrappers are defined in traits which are implemented for types exposed by <code>vulkanalia</code>. The traits can be separated into two categories: version traits and extension traits. The version traits offer command wrappers for the commands which are a standard part of Vulkan whereas the extension traits offer command wrappers for the commands which are defined as part of Vulkan extensions.</p>
<p>For example, the above command wrapper is in the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.EntryV1_0.html"><code>vk::EntryV1_0</code></a> trait since it is a standard Vulkan command that is part of Vulkan 1.0 and is not dependent on a valid Vulkan instance or version (as described in the previous section).</p>
<p>A Vulkan device command that was added in Vulkan 1.2 would be in the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_2.html"><code>vk::DeviceV1_2</code></a> trait. <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.KhrSurfaceExtension.html"><code>vk::KhrSurfaceExtension</code></a> is an example of an extension trait that we will be using in future chapters to call Vulkan commands that are defined as part of the <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VK_KHR_surface.html"><code>VK_KHR_surface</code></a> extension.</p>
<p>These traits are defined for types which contain both the loaded commands and the required Vulkan instance or device (if any). These types have been lovingly hand-crafted and are not part of the generated Vulkan bindings in the <code>vk</code> module of <code>vulkanalia</code>. They will be used in future chapters and are the <code>Entry</code>, <code>Instance</code>, and <code>Device</code> structs and can be found in the <code>Structs</code> section of the <a href="https://docs.rs/vulkanalia"><code>vulkanalia</code> documentation</a>.</p>
<h3><a class="header" href="#builders" id="builders">Builders</a></h3>
<p>The Vulkan API heavily utilizes structs as parameters for Vulkan commands. Many of these structs have a field which indicates the type of the struct. In the C API (called from C++ in this example), this field (<code>sType</code>) would need to be set explicitly, for example:</p>
<pre><code class="language-c++">std::vector&lt;const char*&gt; extensions{/* 3 extension names */};

VkInstanceCreateInfo info;
info.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO;
info.enabledExtensionCount = static_cast&lt;uint32_t&gt;(extensions.size());
info.ppEnabledExtensionNames = extensions.data();

VkInstance instance;
vkCreateInstance(&amp;info, NULL, &amp;instance);
</code></pre>
<p><code>vulkanalia</code> retains this approach but makes it a bit easier to work with while also preventing certain classes of errors. <code>vulkanalia</code> has builder structs which simplify the construction of Vulkan structs by populating the struct with defaults which will include the appropriate value for structure type field when present. These builder structs also simplify the setting of linked fields that represent arrays such as <code>enabledExtensionCount</code> and <code>ppEnabledExtensionNames</code> in the above code. Using <code>vulkanalia</code> the above code would become:</p>
<pre><code class="language-rust noplaypen">let extensions = &amp;[/* 3 extensions */];

let info = vk::InstanceCreateInfo::builder()
    .enabled_extension_names(extensions)
    .build();

let instance = entry.create_instance(&amp;info, None).unwrap();
</code></pre>
<p>Here we create a builder struct instance (<a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.InstanceCreateInfoBuilder.html"><code>vk::InstanceCreateInfoBuilder</code></a>) for the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.InstanceCreateInfo.html"><code>vk::InstanceCreateInfo</code></a> struct that will be initially be populated with default values which includes setting the <code>s_type</code> field to <code>vk::StructureType::INSTANCE_CREATE_INFO</code>. Then we set the enabled extension names (which will set both the <code>enabled_extension_count</code> and <code>enabled_extension_name</code> fields). Then we can build our <code>vk::InstanceCreateInfo</code> struct and pass it to the Vulkan command wrapper.</p>
<p>However, the above Rust code involves a certain degree of danger. The builder structs have lifetimes which enforce that the references stored in them live at least as long as the struct. In the above example, this means that the Rust compiler will make sure that the value passed to the <code>enabled_extension_names</code> method lives at least as long as the builder struct. However, as soon as we call <code>build()</code> to get the raw Vulkan struct these lifetimes are discarded which means the Rust compiler can't prevent us from attempting to access a value that has been dropped.</p>
<p>The following code will (hopefully) crash since the temporary <code>Vec</code> passed to the <code>enabled_extension_names</code> value will have been dropped by the time we call the Vulkan command with our <code>vk::InstanceCreateInfo</code> struct:</p>
<pre><code class="language-rust noplaypen">let info = vk::InstanceCreateInfo::builder()
    .enabled_extension_names(&amp;vec![/* 3 extensions */])
    .build();

let instance = entry.create_instance(&amp;info, None).unwrap();
</code></pre>
<p>Fortunately, <code>vulkanalia</code> has a solution for this. Simply don't call <code>build()</code> and instead pass the builder struct to the command wrapper instead! Anywhere a Vulkan struct is expected in a command wrapper you can instead provide the associated builder struct. If you remove the <code>build()</code> call from the above code the Rust compiler will be able to use the lifetimes on the builder struct to reject this incorrect code with <code>error[E0716]: temporary value dropped while borrowed</code>.</p>
<h3><a class="header" href="#preludes" id="preludes">Preludes</a></h3>
<p><code>vulkanalia</code> offers <a href="https://docs.rs/vulkanalia/latest/vulkanalia/prelude/index.html">prelude modules</a> that expose the basic types needed to use the crate. One prelude module is available per Vulkan version and each will expose the relevant command traits along with other very frequently used types:</p>
<pre><code class="language-rust noplaypen">// Vulkan 1.0
use vulkanalia::prelude::v1_0::*;

// Vulkan 1.1
use vulkanalia::prelude::v1_1::*;

// Vulkan 1.2
use vulkanalia::prelude::v1_2::*;
</code></pre>
<h2><a class="header" href="#validation-layers" id="validation-layers">Validation layers</a></h2>
<p>As mentioned earlier, Vulkan is designed for high performance and low driver overhead. Therefore it will include very limited error checking and debugging capabilities by default. The driver will often crash instead of returning an error code if you do something wrong, or worse, it will appear to work on your graphics card and completely fail on others.</p>
<p>Vulkan allows you to enable extensive checks through a feature known as <em>validation layers</em>. Validation layers are pieces of code that can be inserted between the API and the graphics driver to do things like running extra checks on function parameters and tracking memory management problems. The nice thing is that you can enable them during development and then completely disable them when releasing your application for zero overhead. Anyone can write their own validation layers, but the Vulkan SDK by LunarG provides a standard set of validation layers that we'll be using in this tutorial. You also need to register a callback function to receive debug messages from the layers.</p>
<p>Because Vulkan is so explicit about every operation and the validation layers are so extensive, it can actually be a lot easier to find out why your screen is black compared to OpenGL and Direct3D!</p>
<h1><a class="header" href="#development-environment" id="development-environment">Development environment</a></h1>
<p>In this chapter we'll set up your environment for developing Vulkan applications by installing the Vulkan SDK for your operating system. This tutorial assumes you already have a working Rust (1.47+) development environment.</p>
<h2><a class="header" href="#cargo-project" id="cargo-project">Cargo project</a></h2>
<p>First let's create our Cargo project:</p>
<p><code>cargo new vulkan-tutorial</code></p>
<p>After this command has executed, you'll have a folder called <code>vulkan-tutorial</code> containing a minimal Cargo project which produces a Rust executable.</p>
<p>Open the <code>Cargo.toml</code> file in the folder and add these dependencies in the pre-existing <code>[dependencies]</code> section:</p>
<pre><code class="language-toml">anyhow = &quot;1&quot;
lazy_static = &quot;1&quot;
log = &quot;0.4&quot;
nalgebra-glm = &quot;0.3&quot;
png = &quot;0.16&quot;
pretty_env_logger = &quot;0.4&quot;
tobj = &quot;2&quot;
vulkanalia = { version = &quot;*&quot;, features = [&quot;libloading_&quot;, &quot;winit_&quot;] }
winit = &quot;0.23&quot;
</code></pre>
<ul>
<li><code>anyhow</code> – used for simple error handling</li>
<li><code>lazy_static</code> – used to store static data like vertices</li>
<li><code>log</code> – used for logging statements</li>
<li><code>nalgebra-glm</code> – used as a Rust replacement for <a href="https://glm.g-truc.net">GLM</a> (graphics math library)</li>
<li><code>png</code> – used to load PNGs to use as textures</li>
<li><code>pretty_env_logger</code> – used to print our logs to the console</li>
<li><code>tobj</code> – used to load 3D models in the <a href="https://en.wikipedia.org/wiki/Wavefront_.obj_file">Wavefront .obj format</a></li>
<li><code>vulkanalia</code> – used to call the Vulkan API</li>
<li><code>winit</code> – used to create a window to render to</li>
</ul>
<h2><a class="header" href="#vulkan-sdk" id="vulkan-sdk">Vulkan SDK</a></h2>
<p>The most important component you'll need for developing Vulkan applications is the SDK. It includes the headers, standard validation layers, debugging tools and a loader for the Vulkan functions. The loader looks up the functions in the driver at runtime, similarly to GLEW for OpenGL - if you're familiar with that.</p>
<h3><a class="header" href="#windows" id="windows">Windows</a></h3>
<p>The SDK can be downloaded from the <a href="https://vulkan.lunarg.com/">LunarG website</a> using the buttons at the bottom of the page. You don't have to create an account, but it will give you access to some additional documentation that may be useful to you.</p>
<p><img src="./images/vulkan_sdk_download_buttons.png" alt="" /></p>
<p>Proceed through the installation and pay attention to the install location of the SDK. The first thing we'll do is verify that your graphics card and driver properly support Vulkan. Go to the directory where you installed the SDK, open the <code>Bin</code> directory and run the <code>vkcube.exe</code> demo. You should see the following:</p>
<p><img src="./images/cube_demo.png" alt="" /></p>
<p>If you receive an error message then ensure that your drivers are up-to-date, include the Vulkan runtime and that your graphics card is supported. See the <a href="introduction.html">introduction chapter</a> for links to drivers from the major vendors.</p>
<p>There is another program in this directory that will be useful for development. The <code>glslangValidator.exe</code> and <code>glslc.exe</code> programs will be used to compile shaders from the human-readable <a href="https://en.wikipedia.org/wiki/OpenGL_Shading_Language">GLSL</a> to bytecode. We'll cover this in depth in the <a href="pipeline/shader_modules.html">shader modules chapter</a>. The <code>Bin</code> directory also contains the binaries of the Vulkan loader and the validation layers, while the <code>Lib</code> directory contains the libraries.</p>
<p>Feel free to explore the other files, but we won't need them for this tutorial.</p>
<h3><a class="header" href="#linux" id="linux">Linux</a></h3>
<p>These instructions will be aimed at Ubuntu users, but you may be able to follow along by changing the <code>apt</code> commands to the package manager commands that are appropriate for you.</p>
<p>The most important components you'll need for developing Vulkan applications on Linux are the Vulkan loader, validation layers, and a couple of command-line utilities to test whether your machine is Vulkan-capable:</p>
<ul>
<li><code>sudo apt install vulkan-tools</code>: Command-line utilities, most importantly <code>vulkaninfo</code> and <code>vkcube</code>. Run these to confirm your machine supports Vulkan.</li>
<li><code>sudo apt install libvulkan-dev</code>: Installs Vulkan loader. The loader looks up the functions in the driver at runtime, similarly to GLEW for OpenGL - if you're familiar with that.</li>
<li><code>sudo apt install vulkan-validationlayers-dev</code>: Installs the standard validation layers. These are crucial when debugging Vulkan applications, and we'll discuss them in the upcoming chapter.</li>
</ul>
<p>If installation was successful, you should be all set with the Vulkan portion. Remember to run <code>vkcube</code> and ensure you see the following pop up in a window:</p>
<p><img src="./images/cube_demo_nowindow.png" alt="" /></p>
<p>If you receive an error message then ensure that your drivers are up-to-date, include the Vulkan runtime and that your graphics card is supported. See the <a href="introduction.html">introduction chapter</a> for links to drivers from the major vendors.</p>
<h3><a class="header" href="#macos" id="macos">macOS</a></h3>
<p>These instructions will assume you are using the <a href="https://brew.sh/">Homebrew package manager</a>. Also, keep in mind that you will need at least MacOS version 10.11, and your device needs to support the <a href="https://en.wikipedia.org/wiki/Metal_(API)#Supported_GPUs">Metal API</a>.</p>
<p>The SDK can be downloaded from the <a href="https://vulkan.lunarg.com/">LunarG website</a> using the buttons at the bottom of the page. You don't have to create an account, but it will give you access to some additional documentation that may be useful to you.</p>
<p><img src="./images/vulkan_sdk_download_buttons.png" alt="" /></p>
<p>The SDK version for MacOS internally uses <a href="https://moltengl.com/">MoltenVK</a>. There is no native support for Vulkan on MacOS, so what MoltenVK does is actually act as a layer that translates Vulkan API calls to Apple's Metal graphics framework. With this you can take advantage of debugging and performance benefits of Apple's Metal framework.</p>
<p>After downloading it, simply extract the contents to a folder of your choice. Inside the extracted folder, in the <code>Applications</code> folder you should have some executable files that will run a few demos using the SDK. Run the <code>vkcube</code> executable and you will see the following:</p>
<p><img src="./images/cube_demo_mac.png" alt="" /></p>
<h1><a class="header" href="#faq" id="faq">FAQ</a></h1>
<p>This page lists solutions to common problems that you may encounter while developing Vulkan applications.</p>
<ul>
<li>
<p><strong>I get an access violation error in the core validation layer</strong>: Make sure that MSI Afterburner / RivaTuner Statistics Server is not running, because it has some compatibility problems with Vulkan.</p>
</li>
<li>
<p><strong>I don't see any messages from the validation layers / Validation layers are not available</strong>: First make sure that the validation layers get a chance to print errors by keeping the terminal open after your program exits. You can do this from Visual Studio by running your program with Ctrl-F5 instead of F5, and on Linux by executing your program from a terminal window. If there are still no messages and you are sure that validation layers are turned on, then you should ensure that your Vulkan SDK is correctly installed by following the &quot;Verify the Installation&quot; instructions <a href="https://vulkan.lunarg.com/doc/view/1.2.135.0/windows/getting_started.html">on this page</a>. Also ensure that your SDK version is at least 1.1.106.0 to support the <code>VK_LAYER_KHRONOS_validation</code> layer.</p>
</li>
<li>
<p><strong>vkCreateSwapchainKHR triggers an error in SteamOverlayVulkanLayer64.dll</strong>: This appears to be a compatibility problem in the Steam client beta. There are a few possible workarounds:</p>
<ul>
<li>Opt out of the Steam beta program.</li>
<li>Set the <code>DISABLE_VK_LAYER_VALVE_steam_overlay_1</code> environment variable to <code>1</code></li>
<li>Delete the Steam overlay Vulkan layer entry in the registry under <code>HKEY_LOCAL_MACHINE\SOFTWARE\Khronos\Vulkan\ImplicitLayers</code></li>
</ul>
</li>
</ul>
<p>Example:</p>
<p><img src="./images/steam_layers_env.png" alt="" /></p>
<h1><a class="header" href="#base-code" id="base-code">Base code</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/00_base_code.rs">main.rs</a></p>
<p>In the <code>Development environment</code> chapter we created a Cargo project and added the necessary dependencies. In this chapter we will be replacing the code in the <code>src/main.rs</code> file with the following code:</p>
<pre><pre class="playground"><code class="language-rust">use anyhow::*;
use winit::dpi::LogicalSize;
use winit::event::{Event, WindowEvent};
use winit::event_loop::{ControlFlow, EventLoop};
use winit::window::{Window, WindowBuilder};

fn main() -&gt; Result&lt;()&gt; {
    pretty_env_logger::init();
    info!(&quot;Starting program...&quot;);

    // Window

    let event_loop = EventLoop::new();
    let window = WindowBuilder::new()
        .with_title(&quot;Vulkan Tutorial (Rust)&quot;)
        .with_inner_size(LogicalSize::new(1024, 768))
        .build(&amp;event_loop)?;

    // App

    let mut app = App::create(&amp;window)?;
    let mut destroying = false;
    event_loop.run(move |event, _, control_flow| {
        *control_flow = ControlFlow::Poll;
        match event {
            // Render a frame if our Vulkan app is not being destroyed.
            Event::MainEventsCleared if !destroying =&gt; app.render(&amp;window).unwrap(),
            // Destroy our Vulkan app.
            Event::WindowEvent { event: WindowEvent::CloseRequested, .. } =&gt; {
                destroying = true;
                *control_flow = ControlFlow::Exit;
                app.destroy();
            }
            _ =&gt; {}
        }
    });
}

/// Our Vulkan app.
#[derive(Clone, Debug)]
struct App {}

impl App {
    /// Creates our Vulkan app.
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        Ok(Self {})
    }

    /// Renders a frame for our Vulkan app.
    fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
        Ok(())
    }

    /// Destroys our Vulkan app.
    fn destroy(&amp;mut self) {}
}

/// The Vulkan handles and associated properties used by our Vulkan app.
#[derive(Clone, Debug, Default)]
struct AppData {}
</code></pre></pre>
<p>We first import <code>anyhow::Result</code> which will be used to easily represent all of the results in our program. Next we import all of the <code>winit</code> types we need to create a window and start an event loop for that window.</p>
<p>Next comes our <code>main</code> function (which returns the imported <code>anyhow::Result</code> type). This function starts by initializing <code>pretty_env_logger</code> which will print our logs to the console (as shown later).</p>
<p>Then we create an event loop and window to render to using <code>winit</code> using <code>LogicalSize</code> which will scale the window according to the DPI of your display. If you want to know more about UI scaling you can read the <a href="https://docs.rs/winit/latest/winit/dpi/index.html">relevant <code>winit</code> documentation</a>.</p>
<p>Next we create an instance of our Vulkan app (<code>App</code>) and enter into our rendering loop. This loop will continually render our scene to the window until you request the window to be closed at which point the app will be destroyed and the program will exit. The <code>destroying</code> flag is necessary to not keep attempting to render the scene while the app is being destroyed which would most likely result in the program crashing after attempting to access Vulkan resources that have been destroyed.</p>
<p>Lastly comes <code>App</code> and <code>AppData</code>. <code>App</code> will be used to implement the setup, rendering, and destruction logic required for the Vulkan program we will be building over the course of the following chapters. <code>AppData</code> will serve simply as a container for the large number of Vulkan resources we will need to create and initialize which will allow for them to be easily passed to functions to be read and/or modified.</p>
<p>This will come in handy because many of the following chapters consist of adding a function which takes a <code>&amp;mut AppData</code> and creates and initializes Vulkan resources. These functions will then be called from our <code>App::create</code> constructor method to set up our Vulkan app. Then, before our program exits, these Vulkan resources will be released by our <code>App::destroy</code> method.</p>
<h2><a class="header" href="#resource-management" id="resource-management">Resource management</a></h2>
<p>Just like each chunk of memory allocated in C with <code>malloc</code> requires a corresponding call to <code>free</code>, every Vulkan object that we create needs to be explicitly destroyed when we no longer need it. In Rust it is possible to perform automatic resource management using <a href="https://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization">RAII</a> possibly combined with smart pointers like <code>Rc</code> or <code>Arc</code>. However, the author of <a href="https://vulkan-tutorial.com">https://vulkan-tutorial.com</a> chose to be explicit about allocation and deallocation of Vulkan objects in this tutorial and I have decided to take the same approach. After all, Vulkan's niche is to be explicit about every operation to avoid mistakes, so it's good to be explicit about the lifetime of objects to learn how the API works.</p>
<p>After following this tutorial, you could implement automatic resource management by writing Rust structs that wrap Vulkan objects and release them in their <code>Drop</code> implementation. RAII is the recommended model for larger Vulkan programs, but for learning purposes it's always good to know what's going on behind the scenes.</p>
<p>Vulkan objects are either created directly with commands like <code>vkCreateXXX</code>, or allocated through another object with commands like <code>vkAllocateXXX</code>. After making sure that an object is no longer used anywhere, you need to destroy it with the counterparts <code>vkDestroyXXX</code> and <code>vkFreeXXX</code>. The parameters for these commands generally vary for different types of objects, but there is one parameter that they all share: <code>pAllocator</code>. This is an optional parameter that allows you to specify callbacks for a custom memory allocator. We will ignore this parameter in the tutorial and always pass <code>None</code> as argument.</p>
<h1><a class="header" href="#instance" id="instance">Instance</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/01_instance_creation.rs">main.rs</a></p>
<p>The very first thing you will want to do is initialize the Vulkan library by creating an <em>instance</em>. The instance is the connection between your application and the Vulkan library and creating it involves specifying some details about your application to the driver. To get started, add the following imports:</p>
<pre><code class="language-rust noplaypen">use vulkanalia::loader::{LibloadingLoader, LIBRARY};
use vulkanalia::winit as vk_winit;
use vulkanalia::prelude::v1_0::*;
</code></pre>
<p>Here we first import <code>LibloadingLoader</code> which serves as <code>vulkanalia</code>'s <code>libloading</code> integration which we will use to load the initial Vulkan commands from the Vulkan shared library. The standard name of the Vulkan shared library on your operating system (e.g., <code>vulkan-1.dll</code> on Windows) is then imported as <code>LIBRARY</code>.</p>
<p>Next we import <code>vulkanalia</code>'s <code>winit</code> integration as <code>vk_winit</code> which in this chapter we will use to enumerate the global Vulkan extensions required to render to a <code>winit</code> window. In a future chapter we will also use <code>vk_winit</code> to link our Vulkan instance with our window.</p>
<p>Lastly we import the Vulkan 1.0 prelude from <code>vulkanalia</code> which will provide all of the other Vulkan-related imports we will need for this and future chapters.</p>
<p>Now, to create an instance we'll next have to fill in a struct with some information about our application. This data is technically optional, but it may provide some useful information to the driver in order to optimize our specific application (e.g., because it uses a well-known graphics engine with certain special behavior). This struct is called <code>vk::ApplicationInfo</code> and we'll create it in a new function called <code>create_instance</code> that takes a Vulkan entry point (which we will create later) and returns a Vulkan instance:</p>
<pre><code class="language-rust noplaypen">fn create_instance(entry: &amp;Entry) -&gt; Result&lt;Instance&gt; {
    let application_info = vk::ApplicationInfo::builder()
        .application_name(b&quot;Vulkan Tutorial\0&quot;)
        .application_version(vk::make_version(1, 0, 0))
        .engine_name(b&quot;No Engine\0&quot;)
        .engine_version(vk::make_version(1, 0, 0))
        .api_version(vk::make_version(1, 0, 0));
}
</code></pre>
<p>A lot of information in Vulkan is passed through structs instead of function parameters and we'll have to fill in one more struct to provide sufficient information for creating an instance. This next struct is not optional and tells the Vulkan driver which global extensions and validation layers we want to use. Global here means that they apply to the entire program and not a specific device, which will become clear in the next few chapters. First we'll need to use <code>vulkanalia</code>'s <code>winit</code> integration to enumerate the required global extensions and convert them into null-terminated C strings (<code>*const c_char</code>):</p>
<pre><code class="language-rust noplaypen">let extensions = vk_winit::get_required_instance_extensions(entry)?
    .iter()
    .map(|e| e.to_cstr().as_ptr())
    .collect::&lt;Vec&lt;_&gt;&gt;();
</code></pre>
<p>With our list of required global extensions in hand we can create and return a Vulkan instance using the Vulkan entry point passed into this function:</p>
<pre><code class="language-rust noplaypen">let info = vk::InstanceCreateInfo::builder()
    .application_info(&amp;application_info)
    .enabled_extension_names(&amp;extensions);

Ok(entry.create_instance(&amp;info, None)?)
</code></pre>
<p>As you'll see, the general pattern that object creation function parameters in Vulkan follow is:</p>
<ul>
<li>Reference to struct with creation info</li>
<li>Optional reference to custom allocator callbacks, always <code>None</code> in this tutorial</li>
</ul>
<p>Now that we have a function to create Vulkan instances from entry points, we next need to create a Vulkan entry point. This entry point will load the Vulkan commands used to query instance support and create instances. But before we do that, let's add some fields to our <code>App</code> struct to store the Vulkan entry point and instance we will be creating:</p>
<pre><code class="language-rust noplaypen">struct App {
    entry: Entry,
    instance: Instance,
}
</code></pre>
<p>To populate these fields, update the <code>App::create</code> method to the following:</p>
<pre><code class="language-rust noplaypen">fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
    let loader = LibloadingLoader::new(LIBRARY)?;
    let entry = Entry::new(loader).map_err(|b| anyhow!(&quot;{}&quot;, b))?;

    let instance = create_instance(&amp;entry)?;

    Ok(Self { entry, instance })
}
</code></pre>
<p>Here we first create a Vulkan function loader which will be used to load the initial Vulkan commands from the Vulkan shared library. Next we create the Vulkan entry point using the function loader which will load all of the commands we need to manage Vulkan instances. Lastly we are now able to call our <code>create_instance</code> function with the Vulkan entry point.</p>
<h2><a class="header" href="#cleaning-up" id="cleaning-up">Cleaning up</a></h2>
<p>The <code>Instance</code> should only be destroyed right before the program exits. It can be destroyed in the <code>App::destroy</code> method using the <code>destroy_instance</code> command wrapper:</p>
<pre><code class="language-rust noplaypen">fn destroy(&amp;mut self) {
    self.instance.destroy_instance(None);
}
</code></pre>
<p>Like the Vulkan commands used to create objects, the commands used to destroy objects also take an optional reference to custom allocator callbacks. So like before, we pass <code>None</code> to indicate we are content with the default allocation behavior.</p>
<h2><a class="header" href="#instance-vs-vkinstance" id="instance-vs-vkinstance"><code>Instance</code> vs <code>vk::Instance</code></a></h2>
<p>When we call <code>create_instance</code>, what we get back is not a raw Vulkan instance as would be returned by the Vulkan command <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/vkCreateInstance.html"><code>vkCreateInstance</code></a>. Instead what we got back is a custom type defined by <code>vulkanalia</code> which combines both a raw Vulkan instance and the commands loaded for that specific instance.</p>
<p>This is the <code>Instance</code> type we have been using (imported from the <code>vulkanalia</code> prelude) which should not be confused with the <code>vk::Instance</code> type which represents a raw Vulkan instance. In future chapters we will also use the <code>Device</code> type which, like <code>Instance</code>, is a pairing of a raw Vulkan device (<code>vk::Device</code>) and the commands loaded for that specific device. Fortunately we will not be using <code>vk::Instance</code> or <code>vk::Device</code> directly so you won't need to worry about getting them mixed up.</p>
<p>Because an <code>Instance</code> contains both a Vulkan instance and the associated commands, the command wrappers like <code>destroy_instance</code> implemented for an <code>Instance</code> are able to provide the Vulkan instance when it is required by the underlying Vulkan command.</p>
<p>If you look at the documentation for the <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/vkDestroyInstance.html"><code>vkDestroyInstance</code></a> command, you will see that it takes two parameters: the instance to destroy and the optional custom allocator callbacks. However, <code>destroy_instance</code> only takes the optional custom allocator callbacks because it is able to provide the raw Vulkan handle as the first parameter itself as described above.</p>
<p>Before continuing with the more complex steps after instance creation, it's time to evaluate our debugging options by checking out validation layers.</p>
<h1><a class="header" href="#validation-layers-1" id="validation-layers-1">Validation layers</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/02_validation_layers.rs">main.rs</a></p>
<p>The Vulkan API is designed around the idea of minimal driver overhead and one of the manifestations of that goal is that there is very limited error checking in the API by default. Even mistakes as simple as setting enumerations to incorrect values are generally not explicitly handled and will simply result in crashes or undefined behavior. Because Vulkan requires you to be very explicit about everything you're doing, it's easy to make many small mistakes like using a new GPU feature and forgetting to request it at logical device creation time.</p>
<p>However, that doesn't mean that these checks can't be added to the API. Vulkan introduces an elegant system for this known as validation layers. Validation layers are optional components that hook into Vulkan function calls to apply additional operations. Common operations in validation layers are:</p>
<ul>
<li>Checking the values of parameters against the specification to detect misuse</li>
<li>Tracking creation and destruction of objects to find resource leaks</li>
<li>Checking thread safety by tracking the threads that calls originate from</li>
<li>Logging every call and its parameters to the standard output</li>
<li>Tracing Vulkan calls for profiling and replaying</li>
</ul>
<p>Here's an example of what the implementation of a function in a diagnostics validation layer could look like (in C):</p>
<pre><code class="language-c">VkResult vkCreateInstance(
    const VkInstanceCreateInfo* pCreateInfo,
    const VkAllocationCallbacks* pAllocator,
    VkInstance* instance
) {
    if (pCreateInfo == nullptr || instance == nullptr) {
        log(&quot;Null pointer passed to required parameter!&quot;);
        return VK_ERROR_INITIALIZATION_FAILED;
    }

    return real_vkCreateInstance(pCreateInfo, pAllocator, instance);
}
</code></pre>
<p>These validation layers can be freely stacked to include all the debugging functionality that you're interested in. You can simply enable validation layers for debug builds and completely disable them for release builds, which gives you the best of both worlds!</p>
<p>Vulkan does not come with any validation layers built-in, but the LunarG Vulkan SDK provides a nice set of layers that check for common errors. They're also completely <a href="https://github.com/KhronosGroup/Vulkan-ValidationLayers">open source</a>, so you can check which kind of mistakes they check for and contribute. Using the validation layers is the best way to avoid your application breaking on different drivers by accidentally relying on undefined behavior.</p>
<p>Validation layers can only be used if they have been installed onto the system. For example, the LunarG validation layers are only available on PCs with the Vulkan SDK installed.</p>
<p>There were formerly two different types of validation layers in Vulkan: instance and device specific. The idea was that instance layers would only check calls related to global Vulkan objects like instances, and device specific layers would only check calls related to a specific GPU. Device specific layers have now been deprecated, which means that instance validation layers apply to all Vulkan calls. The specification document still recommends that you enable validation layers at device level as well for compatibility, which is required by some implementations. We'll simply specify the same layers as the instance at logical device level, which we'll see later on.</p>
<p>Before we get started, we'll need some new imports for this chapter:</p>
<pre><code class="language-rust noplaypen">use std::collections::HashSet;
use std::ffi::CStr;
use std::os::raw::c_void;

use log::*;

use vulkanalia::vk::ExtDebugUtilsExtension;
</code></pre>
<p><code>HashSet</code> will be used for storing and querying supported layers and the other imports will be used in the function we will be writing to log messages from the validation layer with the exception of <code>vk::ExtDebugUtilsExtension</code> which provides the commands for managing debugging functionality.</p>
<h2><a class="header" href="#using-validation-layers" id="using-validation-layers">Using validation layers</a></h2>
<p>In this section we'll see how to enable the standard diagnostics layers provided by the Vulkan SDK. Just like extensions, validation layers need to be enabled by specifying their name. All of the useful standard validation is bundled into a layer included in the SDK that is known as <code>VK_LAYER_KHRONOS_validation</code>.</p>
<p>Let's first add two configuration variables to the program to specify the layers to enable and whether to enable them or not. I've chosen to base that value on whether the program is being compiled in debug mode or not.</p>
<pre><code class="language-rust noplaypen">const VALIDATION_ENABLED: bool =
    cfg!(debug_assertions);

const VALIDATION_LAYER: vk::ExtensionName =
    vk::to_extension_name(b&quot;VK_LAYER_KHRONOS_validation\0&quot;);
</code></pre>
<p>We'll add some new code to our <code>create_instance</code> function that collects the supported instance layers into a <code>HashSet</code>, checks that the validation layer is available, and creates a list of layer names containing the validation layer. This code should go right below where the <code>vk::ApplicationInfo</code> struct is built:</p>
<pre><code class="language-rust noplaypen">let available_layers = entry
    .enumerate_instance_layer_properties()?
    .iter()
    .map(|l| l.layer_name)
    .collect::&lt;HashSet&lt;_&gt;&gt;();

if VALIDATION_ENABLED &amp;&amp; !available_layers.contains(&amp;VALIDATION_LAYER) {
    return Err(anyhow!(&quot;Validation layer requested but not supported.&quot;));
}

let layers = if VALIDATION_ENABLED {
    vec![VALIDATION_LAYER.to_cstr().as_ptr()]
} else {
    Vec::new()
};
</code></pre>
<p>Then you'll need to specify the requested layers in <code>vk::CreateInstanceInfo</code> by adding a call to the <code>enabled_layer_names</code> builder method:</p>
<pre><code class="language-rust noplaypen">let info = vk::InstanceCreateInfo::builder()
    .application_info(&amp;application_info)
    .enabled_layer_names(&amp;layers)
    .enabled_extension_names(&amp;extensions);
</code></pre>
<p>Now run the program in debug mode and ensure that the <code>Validation layer requested but not supported.</code> error does not occur. If it does, then have a look at the FAQ. If you get past that check, then <code>entry.create_instance(...)</code> should never return a <code>vk::Result::ERROR_LAYER_NOT_PRESENT</code> error but you should still run the program to be sure.</p>
<h2><a class="header" href="#message-callback" id="message-callback">Message callback</a></h2>
<p>The validation layers will print debug messages to the standard output by default, but we can also handle them ourselves by providing an explicit callback in our program. This will also allow you to decide which kind of messages you would like to see, because not all are necessarily (fatal) errors. If you don't want to do that right now then you may skip to the last section in this chapter.</p>
<p>To set up a callback in the program to handle messages and the associated details, we have to set up a debug messenger with a callback using the <code>VK_EXT_debug_utils</code> extension.</p>
<p>We'll add some more code to our <code>create_instance</code> function. This time we'll modify the <code>extensions</code> list to be mutable and then add the debug utilities extension to the list when the validation layer is enabled:</p>
<pre><code class="language-rust noplaypen">let mut extensions = vk_winit::get_required_instance_extensions(entry)?
    .iter()
    .map(|e| e.to_cstr().as_ptr())
    .collect::&lt;Vec&lt;_&gt;&gt;();

if VALIDATION_ENABLED {
    extensions.push(vk::EXT_DEBUG_UTILS_EXTENSION.to_cstr().as_ptr());
}
</code></pre>
<p>Run the program to make sure you don't receive a <code>vk::Result::ERROR_EXTENSION_NOT_PRESENT</code> error. We don't really need to check for the existence of this extension, because it should be implied by the availability of the validation layers.</p>
<p>Now let's see what a debug callback function looks like. Add a new <code>extern &quot;system&quot;</code> function called <code>debugCallback</code> with the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/type.PFN_vkDebugUtilsMessengerCallbackEXT.html"><code>PFN_vkDebugUtilsMessengerCallbackEXT</code></a> prototype. The <code>extern &quot;system&quot;</code> is necessary to support Vulkan calling it from C.</p>
<pre><code class="language-rust noplaypen">extern &quot;system&quot; fn debug_callback(
    severity: vk::DebugUtilsMessageSeverityFlagsEXT,
    type_: vk::DebugUtilsMessageTypeFlagsEXT,
    data: *const vk::DebugUtilsMessengerCallbackDataEXT,
    _: *mut c_void,
) -&gt; vk::Bool32 {
    let data = unsafe { *data };
    let message = unsafe { CStr::from_ptr(data.message) }.to_string_lossy();

    if severity &gt;= vk::DebugUtilsMessageSeverityFlagsEXT::ERROR {
        error!(&quot;({:?}) {}&quot;, type_, message);
    } else if severity &gt;= vk::DebugUtilsMessageSeverityFlagsEXT::WARNING {
        warn!(&quot;({:?}) {}&quot;, type_, message);
    } else if severity &gt;= vk::DebugUtilsMessageSeverityFlagsEXT::INFO {
        debug!(&quot;({:?}) {}&quot;, type_, message);
    } else {
        trace!(&quot;({:?}) {}&quot;, type_, message);
    }

    vk::FALSE
}
</code></pre>
<p>The first parameter specifies the severity of the message, which is one of the following flags:</p>
<ul>
<li><code>vk::DebugUtilsMessageSeverityFlagsEXT::VERBOSE</code>: Diagnostic message</li>
<li><code>vk::DebugUtilsMessageSeverityFlagsEXT::INFO</code>: Informational message like the creation of a resource</li>
<li><code>vk::DebugUtilsMessageSeverityFlagsEXT::WARNING</code>: Message about behavior that is not necessarily an error, but very likely a bug in your application</li>
<li><code>vk::DebugUtilsMessageSeverityFlagsEXT::ERROR</code>: Message about behavior that is invalid and may cause crashes</li>
</ul>
<p>The values of this enumeration are set up in such a way that you can use a comparison operation to check if a message is equal or worse compared to some level of severity which we use here to decide on which <code>log</code> macro is appropriate to use when logging the message.</p>
<p>The <code>type_</code> parameter can have the following values:</p>
<ul>
<li><code>vk::DebugUtilsMessageTypeFlagsEXT::GENERAL</code>: Some event has happened that is unrelated to the specification or performance</li>
<li><code>vk::DebugUtilsMessageTypeFlagsEXT::VALIDATION</code>: Something has happened that violates the specification or indicates a possible mistake</li>
<li><code>vk::DebugUtilsMessageTypeFlagsEXT::PERFORMANCE</code>: Potential non-optimal use of Vulkan</li>
</ul>
<p>The <code>pCallbackData</code> parameter refers to a <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.DebugUtilsMessengerCallbackDataEXT.html"><code>vk::DebugUtilsMessengerCallbackDataEXT</code></a> struct containing the details of the message itself, with the most important members being:</p>
<ul>
<li><code>message</code>: The debug message as a null-terminated string (<code>*const c_char</code>)</li>
<li><code>objects</code>: Array of Vulkan object handles related to the message</li>
<li><code>object_count</code>: Number of objects in array</li>
</ul>
<p>Finally, the last parameter, here ignored as <code>_</code>, contains a pointer that was specified during the setup of the callback and allows you to pass your own data to it.</p>
<p>The callback returns a (Vulkan) boolean that indicates if the Vulkan call that triggered the validation layer message should be aborted. If the callback returns true, then the call is aborted with the <code>vk::Result::ERROR_VALIDATION_FAILED_EXT</code> error. This is normally only used to test the validation layers themselves, so you should always return <code>vk::FALSE</code>.</p>
<p>All that remains now is telling Vulkan about the callback function. Perhaps somewhat surprisingly, even the debug callback in Vulkan is managed with a handle that needs to be explicitly created and destroyed. Such a callback is part of a debug messenger and you can have as many of them as you want. Add a field to the <code>AppData</code> struct:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    messenger: vk::DebugUtilsMessengerEXT,
}
</code></pre>
<p>Now modify the end of the <code>create_instance</code> function to look like this:</p>
<pre><code class="language-rust noplaypen">fn create_instance(entry: &amp;Entry, data: &amp;mut AppData) -&gt; Result&lt;Instance&gt; {
    // ...

    let instance = entry.create_instance(&amp;info, None)?;

    if VALIDATION_ENABLED {
        let debug_info = vk::DebugUtilsMessengerCreateInfoEXT::builder()
            .message_severity(vk::DebugUtilsMessageSeverityFlagsEXT::all())
            .message_type(vk::DebugUtilsMessageTypeFlagsEXT::all())
            .user_callback(Some(debug_callback));

        data.messenger = instance.create_debug_utils_messenger_ext(&amp;debug_info, None)?;
    }

    Ok(instance)
}
</code></pre>
<p>We have first extracted our Vulkan instance out of the return expression so we can use it to add our debug callback.</p>
<p>Then we construct a <code>vk::DebugUtilsMessengerCreateInfoEXT</code> struct which provides information about our debug callback and how it will be called.</p>
<p>The <code>message_severity</code> field allows you to specify all the types of severities you would like your callback to be called for. I've requested that messages of all severity be included. This would normally produce a lot of verbose general debug info but we can filter that out using a log level when we are not interested in it.</p>
<p>Similarly the <code>message_type</code> field lets you filter which types of messages your callback is notified about. I've simply enabled all types here. You can always disable some if they're not useful to you.</p>
<p>Finally, the <code>user_callback</code> field specifies the callback function. You can optionally pass a mutable reference to the <code>user_data</code> field which will be passed along to the callback function via the <code>data</code> parameter. You could use this to pass a pointer to the <code>AppData</code> struct, for example.</p>
<p>Lastly we call <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.ExtDebugUtilsExtension.html#method.create_debug_utils_messenger_ext"><code>vk::ExtDebugUtilsExtension::create_debug_utils_messenger_ext</code></a> to register our debug callback with the Vulkan instance.</p>
<p>The <code>vk::DebugUtilsMessengerEXT</code> object we created needs to cleaned up before our app exits. We'll do this in <code>App::destroy</code> before we destroy the instance:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        if VALIDATION_ENABLED {
            self.instance.destroy_debug_utils_messenger_ext(self.data.messenger, None);
        }

        self.instance.destroy_instance(None);
    }
}
</code></pre>
<h2><a class="header" href="#debugging-instance-creation-and-destruction" id="debugging-instance-creation-and-destruction">Debugging instance creation and destruction</a></h2>
<p>Although we've now added debugging with validation layers to the program we're not covering everything quite yet. The <code>instance.create_debug_utils_messenger_ext(...)</code> call requires a valid instance to have been created and <code>instance.destroy_debug_utils_messenger_ext(...)</code> must be called before the instance is destroyed. This currently leaves us unable to debug any issues in the <code>entry.create_instance(...)</code> and <code>entry.destroy_instance(...)</code> calls.</p>
<p>However, if you closely read the <a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/77d9f42e075e6a483a37351c14c5e9e3122f9113/appendices/VK_EXT_debug_utils.txt#L84-L91">extension documentation</a>, you'll see that there is a way to create a separate debug utils messenger specifically for those two function calls. It requires you to simply pass a pointer to a <code>vk::DebugUtilsMessengerCreateInfoEXT</code> struct in the <code>next</code> extension field of <code>vk::InstanceCreateInfo</code>. Before we do this, let's first discuss how extending structs works in Vulkan.</p>
<p>The <code>s_type</code> field that is present on many Vulkan structs was briefly mentioned in the <a href="setup/../overview.html#builders">Builders section</a> of the Overview chapter. It was said that this field must be set to the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.StructureType.html"><code>vk::StructureType</code></a> enum value indicating the type of the struct (e.g., <code>vk::StructureType::APPLICATION_INFO</code> for a <code>vk::ApplicationInfo</code> struct).</p>
<p>You may have wondered what the purpose of this field is: doesn't Vulkan already know the type of structs passed to its commands? The purpose of this field is wrapped up with the purpose of the <code>next</code> field that always accompanies the <code>s_type</code> field in Vulkan structs: the ability to <em>extend</em> a Vulkan struct with other Vulkan structs.</p>
<p>The <code>next</code> field in a Vulkan struct may be used to specify a <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/html/vkspec.html#fundamentals-validusage-pNext">structure pointer chain</a>. <code>next</code> can be either be null or a pointer to a Vulkan struct that is permitted by Vulkan to extend the struct. Each struct in this chain of structs is used to provide additional information to the Vulkan command the root structure is passed to. This feature of Vulkan allows for extending the functionality of Vulkan commands without breaking backwards compabilitity.</p>
<p>When you pass such a chain of structs to a Vulkan command, it must iterate through the structs to collect all of the information from the structs. Because of this, Vulkan can't know the type of each structure in the chain, hence the need for the <code>s_type</code> field.</p>
<p>The builder structs provided by <code>vulkanalia</code> allow for easily building these pointer chains in a type-safe manner. For example, take a look at the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.InstanceCreateInfoBuilder.html"><code>vk::InstanceCreateInfoBuilder</code></a> builder struct, specifically the <code>push_next</code> method. This method allows adding any Vulkan struct for which the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.ExtendsInstanceCreateInfo.html"><code>vk::ExtendsInstanceCreateInfo</code></a> trait is implemented for to the pointer chain for a <code>vk::InstanceCreateInfo</code>.</p>
<p>One such struct is <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.DebugUtilsMessengerCreateInfoEXT.html"><code>vk::DebugUtilsMessengerCreateInfoEXT</code></a>, which we will now use to extend our <code>vk::InstanceCreateInfo</code> struct to set up our debug callback. To do this we'll continue to modify our <code>create_instance</code> function. This time we'll make the <code>info</code> struct mutable so we can modify its pointer chain before moving the <code>debug_info</code> struct, now also mutable, below it so we can push it onto <code>info</code>'s pointer chain:</p>
<pre><code class="language-rust noplaypen">let mut info = vk::InstanceCreateInfo::builder()
    .application_info(&amp;application_info)
    .enabled_layer_names(&amp;layers)
    .enabled_extension_names(&amp;extensions);

let mut debug_info = vk::DebugUtilsMessengerCreateInfoEXT::builder()
    .message_severity(vk::DebugUtilsMessageSeverityFlagsEXT::all())
    .message_type(vk::DebugUtilsMessageTypeFlagsEXT::all())
    .user_callback(Some(debug_callback));

if VALIDATION_ENABLED {
    info = info.push_next(&amp;mut debug_info);
}
</code></pre>
<p><code>debug_info</code> needs to be defined outside of the conditional since it needs to live until we are done calling <code>entry.create_instance(...)</code>. Fortunately we can rely on the Rust compiler to protect us from pushing a struct that doesn't live long enough onto a pointer chain due to the lifetimes defined for the <code>vulkanalia</code> builder structs.</p>
<p>Now we should be able to run our program and see logs from our debug callback, but first we'll need to set the <code>RUST_LOG</code> environment variable so that <code>pretty_env_logger</code> will enable the log levels we are interested in. Initially set the log level to <code>debug</code> so we can be sure it is working, here is an example on Windows (Powershell):</p>
<p><img src="setup/../images/validation_layer_test.png" alt="" /></p>
<p>If everything is working you shouldn't see any warning or error messages. Going forward you may want to increase the minimum log level to <code>info</code> using <code>RUST_LOG</code> to reduce the verbosity of the logs unless you are trying to debug an error.</p>
<h2><a class="header" href="#configuration" id="configuration">Configuration</a></h2>
<p>There are a lot more settings for the behavior of validation layers than just the flags specified in the <code>vk::DebugUtilsMessengerCreateInfoEXT</code> struct. Browse to the Vulkan SDK and go to the <code>Config</code> directory. There you will find a <code>vk_layer_settings.txt</code> file that explains how to configure the layers.</p>
<p>To configure the layer settings for your own application, copy the file to the working directory of your project's executable and follow the instructions to set the desired behavior. However, for the remainder of this tutorial I'll assume that you're using the default settings.</p>
<p>Throughout this tutorial I'll be making a couple of intentional mistakes to show you how helpful the validation layers are with catching them and to teach you how important it is to know exactly what you're doing with Vulkan. Now it's time to look at Vulkan devices in the system.</p>
<h1><a class="header" href="#physical-devices-and-queue-families" id="physical-devices-and-queue-families">Physical devices and queue families</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/03_physical_device_selection.rs">main.rs</a></p>
<p>After initializing the Vulkan library through an <code>Instance</code> we need to look for and select a graphics card in the system that supports the features we need. In fact we can select any number of graphics cards and use them simultaneously, but in this tutorial we'll stick to the first graphics card that suits our needs.</p>
<p>We'll add a <code>pick_physical_device</code> function which will accomplish this task and write the physical device and related information to an instance of <code>AppData</code>. We'll also need a <code>data: AppData</code> field in our <code>App</code> struct which will be used to store all of the Vulkan objects and related properties for our app. With this in place we can construct and populate an <code>AppData</code> instance in our <code>App::create</code> method.</p>
<pre><code class="language-rust noplaypen">struct App {
    // ...
    data: AppData,
}

impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...

        let mut data = AppData::default();
        pick_physical_device(&amp;instance, &amp;mut data)?;

        Ok(Self { entry, instance, data })
    }
}

fn pick_physical_device(instance: &amp;Instance, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    Ok(())
}
</code></pre>
<p>The graphics card that we'll end up selecting will be stored in a <code>vk::PhysicalDevice</code> handle that is added as a new field to the <code>AppData</code> struct. This object will be implicitly destroyed when the <code>Instance</code> is destroyed, so we won't need to do anything new in the <code>App::destroy</code> method.</p>
<pre><code class="language-rust noplaypen">struct AppData {
    physical_device: vk::PhysicalDevice,
}
</code></pre>
<h2><a class="header" href="#device-suitability" id="device-suitability">Device suitability</a></h2>
<p>We'll need a way to determine whether a physical device meets our needs. We'll start by creating a function that returns whether a supplied physical device supports everything we require:</p>
<pre><code class="language-rust noplaypen">fn check_physical_device(
    instance: &amp;Instance,
    data: &amp;AppData,
    physical_device: vk::PhysicalDevice,
) -&gt; Result&lt;bool&gt; {
    Ok(true)
}
</code></pre>
<p>To evaluate whether a physical device meets our needs we can start by querying for some details. Basic device properties like the name, type, and supported Vulkan version can be queried using <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.InstanceV1_0.html#method.get_physical_device_properties"><code>vk::InstanceV1_0::get_physical_device_properties</code></a>:</p>
<pre><code class="language-rust noplaypen">let properties = instance
    .get_physical_device_properties(physical_device);
</code></pre>
<p>The support for optional features like texture compression, 64 bit floats, and multi viewport rendering (useful for VR) can be queried using <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.InstanceV1_0.html#method.get_physical_device_features"><code>vk::InstanceV1_0::get_physical_device_features</code></a>:</p>
<pre><code class="language-rust noplaypen">let features = instance
    .get_physical_device_features(physical_device);
</code></pre>
<p>There are more details that can be queried from devices that we'll discuss later concerning device memory and queue families (see the next section).</p>
<p>As an example, let's say we consider our application only usable for dedicated graphics cards that support geometry shaders. Then the <code>check_physical_device</code> function would look like this:</p>
<pre><code class="language-rust noplaypen">fn check_physical_device(
    instance: &amp;Instance,
    data: &amp;AppData,
    physical_device: vk::PhysicalDevice,
) -&gt; Result&lt;bool&gt; {
    let properties = instance.get_physical_device_properties(physical_device);
    let features = instance.get_physical_device_features(physical_device);
    Ok(
        properties.device_type == vk::PhysicalDeviceType::DISCRETE_GPU
            &amp;&amp; features.geometry_shader == vk::TRUE,
    )
}
</code></pre>
<p>Instead of just checking if a device is suitable or not and going with the first one, you could also give each device a score and pick the highest one. That way you could favor a dedicated graphics card by giving it a higher score, but fall back to an integrated GPU if that's the only available one. You could also just display the names of the choices and allow the user to select.</p>
<p>Next we'll discuss the first real required feature.</p>
<h2><a class="header" href="#queue-families" id="queue-families">Queue families</a></h2>
<p>It has been briefly touched upon before that almost every operation in Vulkan, anything from drawing to uploading textures, requires commands to be submitted to a queue. There are different types of queues that originate from different queue families and each family of queues allows only a subset of commands. For example, there could be a queue family that only allows processing of compute commands or one that only allows memory transfer related commands.</p>
<p>We need to check which queue families are supported by the device and which one of these supports the commands that we want to use. For that purpose we'll add a new struct <code>QueueFamilyIndices</code> that stores the indices of the queue families we need.</p>
<p>Right now we are only going to look for a queue that supports graphics commands, so the struct and its implementation will look like this:</p>
<pre><code class="language-rust noplaypen">#[derive(Copy, Clone, Debug)]
struct QueueFamilyIndices {
    graphics: u32,
}

impl QueueFamilyIndices {
    fn get(
        instance: &amp;Instance,
        data: &amp;AppData,
        physical_device: vk::PhysicalDevice,
    ) -&gt; Result&lt;Self&gt; {
        let properties = instance
            .get_physical_device_queue_family_properties(physical_device);

        let graphics = properties
            .iter()
            .position(|p| p.queue_flags.contains(vk::QueueFlags::GRAPHICS))
            .map(|i| i as u32);

        if let Some(graphics) = graphics {
            Ok(Self { graphics })
        } else {
            Err(anyhow!(&quot;Failed to get required queue family indices.&quot;))
        }
    }
}
</code></pre>
<p>The queue properties returned by <code>instance.get_physical_device_queue_family_properties(...)</code> contains various details about the queue families supported by the physical device, including the type of operations supported and the number of queues that can be created based on that family. Here we are looking for the first queue family that supports graphics operations as indicated by <code>vk::QueueFlags::GRAPHICS</code>.</p>
<p>Now that we have this fancy queue family lookup method, we can use it as a check in the <code>check_physical_device</code> function to ensure the device can process the commands we want to use:</p>
<pre><code class="language-rust noplaypen">fn check_physical_device(
    instance: &amp;Instance,
    data: &amp;AppData,
    physical_device: vk::PhysicalDevice,
) -&gt; Result&lt;bool&gt; {
    QueueFamilyIndices::get(instance, data, physical_device)?;
    Ok(true)
}
</code></pre>
<p>Lastly we can iterate over the physical devices and pick the first that satisfies our requirements as indicated by <code>check_physical_device</code>. To do this, add the following code to <code>pick_physical_device</code>:</p>
<pre><code class="language-rust noplaypen">data.physical_device = instance
    .enumerate_physical_devices()?
    .into_iter()
    .find(|pd| match check_physical_device(instance, data, *pd) {
        Ok(suitable) =&gt; suitable,
        Err(e) =&gt; {
            warn!(&quot;Failed to check physical device suitability: {}&quot;, e);
            false
        }
    })
    .ok_or_else(|| anyhow!(&quot;Failed to find suitable physical device.&quot;))?;
</code></pre>
<p>Great, that's all we need for now to find the right physical device! The next step is to create a logical device to interface with it.</p>
<h1><a class="header" href="#logical-device-and-queues" id="logical-device-and-queues">Logical device and queues</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/04_logical_device.rs">main.rs</a></p>
<p>After selecting a physical device to use we need to set up a logical device to interface with it. The logical device creation process is similar to the instance creation process and describes the features we want to use. We also need to specify which queues to create now that we've queried which queue families are available. You can even create multiple logical devices from the same physical device if you have varying requirements.</p>
<p>Start by adding a new <code>App</code> field to store the logical device in:</p>
<pre><code class="language-rust noplaypen">struct App {
    // ...
    device: Device,
}
</code></pre>
<p>Next, add a <code>create_logical_device</code> function that is called from <code>App:create</code> and add the resulting logical device to the <code>App</code> initializer:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...

        let device = create_logical_device(&amp;instance, &amp;mut data)?;

        Ok(Self { entry, instance, data, device })
    }
}

fn create_logical_device(instance: &amp;Instance, data: &amp;mut AppData) -&gt; Result&lt;Device&gt; {
}
</code></pre>
<h2><a class="header" href="#specifying-the-queues-to-be-created" id="specifying-the-queues-to-be-created">Specifying the queues to be created</a></h2>
<p>The creation of a logical device involves specifying a bunch of details in structs again, of which the first one will be <code>vk::DeviceQueueCreateInfo</code>. This structure describes the number of queues we want for a single queue family. Right now we're only interested in a queue with graphics capabilities.</p>
<pre><code class="language-rust noplaypen">let indices = QueueFamilyIndices::get(instance, data, data.physical_device)?;

let queue_priorities = &amp;[1.0];
let queue_info = vk::DeviceQueueCreateInfo::builder()
    .queue_family_index(indices.graphics)
    .queue_priorities(queue_priorities);
</code></pre>
<p>The currently available drivers will only allow you to create a small number of queues for each queue family and you don't really need more than one. That's because you can create all of the command buffers on multiple threads and then submit them all at once on the main thread with a single low-overhead call.</p>
<p>Vulkan lets you assign priorities to queues to influence the scheduling of command buffer execution using floating point numbers between <code>0.0</code> and <code>1.0</code>. This is required even when only creating a single queue.</p>
<h2><a class="header" href="#specifying-the-layers-to-enable" id="specifying-the-layers-to-enable">Specifying the layers to enable</a></h2>
<p>The next piece of information we need to provide bears a resemblance to the <code>vk::CreateInstanceInfo</code> struct. Once again we need to specify any layers or extensions we want to enable, but this time any specified extensions are device specific rather than global.</p>
<p>An example of a device specific extension is <code>VK_KHR_swapchain</code>, which allows you to present rendered images from that device to windows. It is possible that there are Vulkan devices in the system that lack this ability, for example because they only support compute operations. We will come back to this extension in the swapchain chapter.</p>
<p>Previous implementations of Vulkan made a distinction between instance and device specific validation layers, but this is no longer the case. That means that the layer names we pass to <code>enabled_layer_names</code> later are ignored by up-to-date implementations. However, it is still a good idea to set them anyway to be compatible with older implementations.</p>
<p>We wont be enabling any device extensions yet, so we will just construct a list of layer names containing the validation layer if validation is enabled.</p>
<pre><code class="language-rust noplaypen">let layers = if VALIDATION_ENABLED {
    vec![VALIDATION_LAYER.to_cstr().as_ptr()]
} else {
    vec![]
};
</code></pre>
<h2><a class="header" href="#specifying-used-device-features" id="specifying-used-device-features">Specifying used device features</a></h2>
<p>The next information to specify is the set of device features that we'll be using. These are the features that we queried support for with <code>vk::InstanceV1_0::get_physical_device_features</code> in the previous chapter, like geometry shaders. Right now we don't need anything special, so we can simply define it and leave everything to the default values (<code>false</code>). We'll come back to this structure once we're about to start doing more interesting things with Vulkan.</p>
<pre><code class="language-rust noplaypen">let features = vk::PhysicalDeviceFeatures::builder();
</code></pre>
<h2><a class="header" href="#creating-the-logical-device" id="creating-the-logical-device">Creating the logical device</a></h2>
<p>With the previous two structures and the validation layer (if enabled) in place, we can fill in the main <code>vk::DeviceCreateInfo</code> structure.</p>
<pre><code class="language-rust noplaypen">let queue_infos = &amp;[queue_info];
let info = vk::DeviceCreateInfo::builder()
    .queue_create_infos(queue_infos)
    .enabled_layer_names(&amp;layers)
    .enabled_features(&amp;features);
</code></pre>
<p>That's it, we're now ready to instantiate the logical device with a call to the appropriately named <a href="https://docs.rs/vulkanalia/latest/vulkanalia/struct.Instance.html#method.create_device"><code>Instance::create_device</code></a> method.</p>
<pre><code class="language-rust noplaypen">let device = instance.create_device(data.physical_device, &amp;info, None)?;
</code></pre>
<p>The parameters are the physical device to interface with, the queue and usage info we just specified, and the optional allocation callbacks. Similarly to the instance creation function, this call can return errors based on enabling non-existent extensions or specifying the desired usage of unsupported features.</p>
<p>The device should be destroyed in <code>App::destroy</code>:</p>
<pre><code class="language-rust noplaypen">fn destroy(&amp;mut self) {
    self.device.destroy_device(None);
    // ...
}
</code></pre>
<p>Logical devices don't interact directly with instances, which is why it's not included as a parameter.</p>
<h2><a class="header" href="#retrieving-queue-handles" id="retrieving-queue-handles">Retrieving queue handles</a></h2>
<p>The queues are automatically created along with the logical device, but we don't have a handle to interface with them yet. First add a new <code>AppData</code> field to store a handle to the graphics queue:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    graphics_queue: vk::Queue,
}
</code></pre>
<p>Device queues are implicitly cleaned up when the device is destroyed, so we don't need to do anything in <code>App::destroy</code>.</p>
<p>We can use the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.get_device_queue"><code>DeviceV1_0::get_device_queue</code></a> function to retrieve queue handles for each queue family. The parameters are the logical device, queue family, and queue index. Because we're only creating a single queue from this family, we'll simply use index 0.</p>
<pre><code class="language-rust noplaypen">data.graphics_queue = device.get_device_queue(indices.graphics, 0);
</code></pre>
<p>Lastly, return the created logical device from <code>create_logical_device</code>:</p>
<pre><code class="language-rust noplaypen">Ok(device)
</code></pre>
<p>With the logical device and queue handles we can now actually start using the graphics card to do things! In the next few chapters we'll set up the resources to present results to the window system.</p>
<h1><a class="header" href="#window-surface" id="window-surface">Window surface</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/05_window_surface.rs">main.rs</a></p>
<p>Since Vulkan is a platform agnostic API, it can not interface directly with the window system on its own. To establish the connection between Vulkan and the window system to present results to the screen, we need to use the WSI (Window System Integration) extensions. In this chapter we'll discuss the first one, which is <code>VK_KHR_surface</code>. It exposes a <code>vk::SurfaceKHR</code> object that represents an abstract type of surface to present rendered images to. The surface in our program will be backed by the window that we've already opened with <code>winit</code>.</p>
<p>The <code>VK_KHR_surface</code> extension is an instance level extension and we've actually already enabled it, because it's included in the list returned by <code>vk_winit::get_required_instance_extensions</code>. The list also includes some other WSI extensions that we'll use in the next couple of chapters.</p>
<p>The window surface needs to be created right after the instance creation, because it can actually influence the physical device selection. The reason we postponed this is because window surfaces are part of the larger topic of render targets and presentation for which the explanation would have cluttered the basic setup. It should also be noted that window surfaces are an entirely optional component in Vulkan, if you just need off-screen rendering. Vulkan allows you to do that without hacks like creating an invisible window (necessary for OpenGL).</p>
<p>While we can freely import types for extensions like the struct <code>vk::SurfaceKHR</code>, we need to import the <code>vulkanalia</code> extension trait for <code>VK_KHR_surface</code> before we can call any of the Vulkan commands added by the extension. Add the following import for <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.KhrSurfaceExtension.html"><code>vk::KhrSurfaceExtension</code></a>:</p>
<pre><code class="language-rust noplaypen">use vulkanalia::vk::KhrSurfaceExtension;
</code></pre>
<h2><a class="header" href="#window-surface-creation" id="window-surface-creation">Window surface creation</a></h2>
<p>Start by adding a <code>surface</code> field in <code>AppData</code> above the other fields.</p>
<pre><code class="language-rust noplaypen">struct AppData {
    surface: vk::SurfaceKHR,
    // ...
}
</code></pre>
<p>Although the <code>vk::SurfaceKHR</code> object and its usage is platform agnostic, its creation isn't because it depends on window system details. For example, it needs the <code>HWND</code> and <code>HMODULE</code> handles on Windows. Therefore there is a platform-specific addition to the extension, which on Windows is called <code>VK_KHR_win32_surface</code> and is also automatically included in the list from <code>vk_winit::get_required_instance_extensions</code>.</p>
<p>I will demonstrate how this platform specific extension can be used to create a surface on Windows, but we won't actually use it in this tutorial. It doesn't make any sense to use a library like GLFW and then proceed to use platform-specific code anyway. <code>vulkanalia</code> has <a href="https://docs.rs/vulkanalia/latest/vulkanalia/winit/fn.create_surface.html"><code>vk_winit::create_surface</code></a> that handles the platform differences for us. Still, it's good to see what it does behind the scenes before we start relying on it.</p>
<p>Because a window surface is a Vulkan object, it comes with a <code>vk::Win32SurfaceCreateInfoKHR</code> struct that needs to be filled in. It has two important parameters: <code>hinstance</code> and <code>hwnd</code>. These are the handles to the process and the window.</p>
<pre><code class="language-rust noplaypen">use winit::platform::windows::WindowExtWindows;

let info = vk::Win32SurfaceCreateInfoKHR::builder()
    .hinstance(window.hinstance())
    .hwnd(window.hwnd());
</code></pre>
<p>The <code>WindowExtWindows</code> trait is imported from <code>winit</code> because it allows us to access platform-specific methods on the <code>winit</code> <code>Window</code> struct. In this case, it permits us to get the process and window handles for the window created by <code>winit</code>.</p>
<p>After that the surface can be created with <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.KhrWin32SurfaceExtension.html#method.create_win32_surface_khr"><code>vk::KhrWin32SurfaceExtension::create_win32_surface_khr</code></a>, which includes parameters for the surface creation details and custom allocators. Technically this is a WSI extension function, but it is so commonly used that the standard Vulkan loader includes it, so unlike other extensions you don't need to explicitly load it. However, we do need to import the <code>vulkanalia</code> extension trait for <code>VK_KHR_win32_surface</code>.</p>
<pre><code class="language-rust noplaypen">use vk::KhrWin32SurfaceExtension;

let surface = instance.create_win32_surface_khr(&amp;info, None).unwrap();
</code></pre>
<p>The process is similar for other platforms like Linux, where <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.KhrXcbSurfaceExtension.html#method.create_xcb_surface_khr"><code>vk::KhrXcbSurfaceExtension::create_xcb_surface_khr</code></a> takes an XCB connection and window as creation details with X11.</p>
<p>The <code>vk_winit::create_surface</code> function performs exactly this operation with a different implementation for each platform. We'll now integrate it into our program. Add a call to the function in <code>App::create</code> right before we pick a physical device.</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...

        let mut data = AppData::default();
        data.surface = vk_winit::create_surface(&amp;instance, window)?;
        pick_physical_device(&amp;instance, &amp;mut data)?;

        // ...
    }
}
</code></pre>
<p>The parameters are the Vulkan instance and the <code>winit</code> window. Once we have our surface, it can be destroyed in <code>App::destroy</code> using the Vulkan API:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        // ...
        self.instance.destroy_surface_khr(self.data.surface, None);
        self.instance.destroy_instance(None);
    }
}
</code></pre>
<p>Make sure that the surface is destroyed before the instance.</p>
<h2><a class="header" href="#querying-for-presentation-support" id="querying-for-presentation-support">Querying for presentation support</a></h2>
<p>Although the Vulkan implementation may support window system integration, that does not mean that every device in the system supports it. Therefore we need to extend the <code>QueueFamilyIndices</code> struct to ensure that a device can present images to the surface we created. Since the presentation is a queue-specific feature, the problem is actually about finding a queue family that supports presenting to the surface we created.</p>
<p>It's actually possible that the queue families supporting drawing commands and the ones supporting presentation do not overlap. Therefore we have to take into account that there could be a distinct presentation queue by modifying the <code>QueueFamilyIndices</code> struct:</p>
<pre><code class="language-rust noplaypen">struct QueueFamilyIndices {
    graphics: u32,
    present: u32,
}
</code></pre>
<p>Next, we'll modify the <code>QueueFamilyIndices::get</code> method to look for a queue family that has the capability of presenting to our window surface. The function to check for that is <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.KhrSurfaceExtension.html#method.get_physical_device_surface_support_khr"><code>vk::KhrSurfaceExtension::get_physical_device_surface_support_khr</code></a>, which takes the physical device, queue family index. and surface as parameters and returns whether presentation is supported for that combination of physical device, queue family, and surface.</p>
<p>Modify <code>QueueFamilyIndices::get</code> to find a presentation queue family index below where a graphics queue family index is found.</p>
<pre><code class="language-rust noplaypen">let mut present = None;
for (index, properties) in properties.iter().enumerate() {
    if instance.get_physical_device_surface_support_khr(
        physical_device,
        index as u32,
        data.surface,
    )? {
        present = Some(index as u32);
    }
}
</code></pre>
<p>We'll also need to add <code>present</code> to the final expression:</p>
<pre><code class="language-rust noplaypen">if let (Some(graphics), Some(present)) = (graphics, present) {
    Ok(Self { graphics, present })
} else {
    Err(anyhow!(&quot;Failed to get required queue family indices.&quot;))
}
</code></pre>
<p>Note that it's very likely that these end up being the same queue family after all, but throughout the program we will treat them as if they were separate queues for a uniform approach. Nevertheless, you could add logic to explicitly prefer a physical device that supports drawing and presentation in the same queue for improved performance.</p>
<h2><a class="header" href="#creating-the-presentation-queue" id="creating-the-presentation-queue">Creating the presentation queue</a></h2>
<p>The one thing that remains is modifying the logical device creation procedure to create the presentation queue and retrieve the <code>VkQueue</code> handle. Add a field to <code>AppData</code> for the handle:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    present_queue: vk::Queue,
}
</code></pre>
<p>Next, we need to have multiple <code>vk::DeviceQueueCreateInfo</code> structs to create a queue from both families. An elegant way to do that is to create a set of all unique queue families that are necessary for the required queues. We'll do this in the <code>create_logical_device</code> function:</p>
<pre><code class="language-rust noplaypen">let indices = QueueFamilyIndices::get(instance, data, data.physical_device)?;

let mut unique_indices = HashSet::new();
unique_indices.insert(indices.graphics);
unique_indices.insert(indices.present);

let queue_priorities = &amp;[1.0];
let queue_infos = unique_indices
    .iter()
    .map(|i| {
        vk::DeviceQueueCreateInfo::builder()
            .queue_family_index(*i)
            .queue_priorities(queue_priorities)
    })
    .collect::&lt;Vec&lt;_&gt;&gt;();
</code></pre>
<p>And delete the previous <code>queue_infos</code> slice and take a reference to the <code>queue_infos</code> list for <code>vk::DeviceCreateInfo</code>:</p>
<pre><code class="language-rust noplaypen">let info = vk::DeviceCreateInfo::builder()
    .queue_create_infos(&amp;queue_infos)
    .enabled_layer_names(&amp;layers)
    .enabled_features(&amp;features);
</code></pre>
<p>If the queue families are the same, then we only need to pass its index once. Finally, add a call to retrieve the queue handle:</p>
<pre><code class="language-rust noplaypen">data.present_queue = device.get_device_queue(indices.present, 0);
</code></pre>
<p>In case the queue families are the same, the two handles will most likely have the same value now. In the next chapter we're going to look at swapchains and how they give us the ability to present images to the surface.</p>
<h1><a class="header" href="#swapchain" id="swapchain">Swapchain</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/06_swapchain_creation.rs">main.rs</a></p>
<p>Vulkan does not have the concept of a &quot;default framebuffer&quot;, hence it requires an infrastructure that will own the buffers we will render to before we visualize them on the screen. This infrastructure is known as the <em>swapchain</em> and must be created explicitly in Vulkan. The swapchain is essentially a queue of images that are waiting to be presented to the screen. Our application will acquire such an image to draw to it, and then return it to the queue. How exactly the queue works and the conditions for presenting an image from the queue depend on how the swapchain is set up, but the general purpose of the swapchain is to synchronize the presentation of images with the refresh rate of the screen.</p>
<h2><a class="header" href="#checking-for-swapchain-support" id="checking-for-swapchain-support">Checking for swapchain support</a></h2>
<p>Not all graphics cards are capable of presenting images directly to a screen for various reasons, for example because they are designed for servers and don't have any display outputs. Secondly, since image presentation is heavily tied into the window system and the surfaces associated with windows, it is not actually part of the Vulkan core. You have to enable the <code>VK_KHR_swapchain</code> device extension after querying for its support. Also, like before, you need to import the <code>vulkanalia</code> extension trait for <code>VK_KHR_swapchain</code>:</p>
<pre><code class="language-rust noplaypen">use vulkanalia::vk::KhrSwapchainExtension;
</code></pre>
<p>Then we'll first extend the <code>check_physical_device</code> function to check if this extension is supported. We've previously seen how to list the extensions that are supported by a <code>vk::PhysicalDevice</code>, so doing that should be fairly straightforward.</p>
<p>First declare a list of required device extensions, similar to the list of validation layers to enable.</p>
<pre><code class="language-rust noplaypen">const DEVICE_EXTENSIONS: &amp;[vk::ExtensionName] = &amp;[vk::KHR_SWAPCHAIN_EXTENSION];
</code></pre>
<p>Next, create a new function <code>check_physical_device_extensions</code> that is called from <code>check_physical_device</code> as an additional check:</p>
<pre><code class="language-rust noplaypen">fn check_physical_device(
    instance: &amp;Instance,
    data: &amp;AppData,
    physical_device: vk::PhysicalDevice,
) -&gt; Result&lt;bool&gt; {
    QueueFamilyIndices::get(instance, data, physical_device)?;
    let extensions = check_physical_device_extensions(instance, physical_device)?;
    Ok(extensions)
}

fn check_physical_device_extensions(
    instance: &amp;Instance,
    physical_device: vk::PhysicalDevice,
) -&gt; Result&lt;bool&gt; {
    Ok(true)
}
</code></pre>
<p>Modify the body of the function to enumerate the extensions and check if all of the required extensions are amongst them.</p>
<pre><code class="language-rust noplaypen">fn check_physical_device_extensions(
    instance: &amp;Instance,
    physical_device: vk::PhysicalDevice,
) -&gt; Result&lt;bool&gt; {
    let extensions = instance
        .enumerate_device_extension_properties(physical_device, None)?
        .iter()
        .map(|e| e.extension_name)
        .collect::&lt;HashSet&lt;_&gt;&gt;();
    Ok(DEVICE_EXTENSIONS.iter().all(|e| extensions.contains(e)))
}
</code></pre>
<p>Now run the code and verify that your graphics card is indeed capable of creating a swapchain. It should be noted that the availability of a presentation queue, as we checked in the previous chapter, implies that the swapchain extension must be supported. However, it's still good to be explicit about things, and the extension does have to be explicitly enabled.</p>
<h2><a class="header" href="#enabling-device-extensions" id="enabling-device-extensions">Enabling device extensions</a></h2>
<p>Using a swapchain requires enabling the <code>VK_KHR_swapchain</code> extension first. Enabling the extension just requires a small change to the logical device creation structure in the <code>create_logical_device</code> function, first we'll convert our list of extensions to a list of null-terminated strings:</p>
<pre><code class="language-rust noplaypen">let extensions = DEVICE_EXTENSIONS
    .iter()
    .map(|n| n.to_cstr().as_ptr())
    .collect::&lt;Vec&lt;_&gt;&gt;();
</code></pre>
<p>Then we just need to add the extension names to the <code>vk::DeviceCreateInfo</code> struct:</p>
<pre><code class="language-rust noplaypen">let info = vk::DeviceCreateInfo::builder()
    .queue_create_infos(&amp;queue_infos)
    .enabled_layer_names(&amp;layers)
    .enabled_extension_names(&amp;extensions)
    .enabled_features(&amp;features);
</code></pre>
<h2><a class="header" href="#querying-details-of-swapchain-support" id="querying-details-of-swapchain-support">Querying details of swapchain support</a></h2>
<p>Just checking if a swapchain is available is not sufficient, because it may not actually be compatible with our window surface. Creating a swapchain also involves a lot more settings than instance and device creation, so we need to query for some more details before we're able to proceed.</p>
<p>There are basically three kinds of properties we need to check:</p>
<ul>
<li>Basic surface capabilities (min/max number of images in swapchain, min/max width and height of images)</li>
<li>Surface formats (pixel format, color space)</li>
<li>Available presentation modes</li>
</ul>
<p>Similar to <code>QueueFamilyIndices</code>, we'll use a struct to pass these details around once they've been queried. The three aforementioned types of properties come in the form of the following structs and lists of structs:</p>
<pre><code class="language-rust noplaypen">#[derive(Clone, Debug)]
struct SwapchainSupport {
    capabilities: vk::SurfaceCapabilitiesKHR,
    formats: Vec&lt;vk::SurfaceFormatKHR&gt;,
    present_modes: Vec&lt;vk::PresentModeKHR&gt;,
}
</code></pre>
<p>We'll now create a new method <code>SwapchainSupport::get</code> that will initialize this struct with all of the structs we need.</p>
<pre><code class="language-rust noplaypen">impl SwapchainSupport {
    fn get(
        instance: &amp;Instance,
        data: &amp;AppData,
        physical_device: vk::PhysicalDevice,
    ) -&gt; Result&lt;Self&gt; {
        Ok(Self {
            capabilities: instance
                .get_physical_device_surface_capabilities_khr(
                    physical_device, data.surface)?,
            formats: instance
                .get_physical_device_surface_formats_khr(
                    physical_device, data.surface)?,
            present_modes: instance
                .get_physical_device_surface_present_modes_khr(
                    physical_device, data.surface)?,
        })
    }
}
</code></pre>
<p>The meaning of these structs and exactly which data they contain is discussed in the next section.</p>
<p>All of the details are in the struct now, so let's extend <code>check_physical_device</code> once more to utilize this method to verify that swapchain support is adequate. swapchain support is sufficient for this tutorial if there is at least one supported image format and one supported presentation mode given the window surface we have.</p>
<pre><code class="language-rust noplaypen">let support = SwapchainSupport::get(instance, data, physical_device)?;
let swapchain = !support.formats.is_empty() &amp;&amp; !support.present_modes.is_empty();
</code></pre>
<p>It is important that we only try to query for swapchain support after verifying that the extension is available. The last line of the function changes to:</p>
<pre><code class="language-rust noplaypen">Ok(extensions &amp;&amp; swapchain)
</code></pre>
<h2><a class="header" href="#choosing-the-right-settings-for-the-swapchain" id="choosing-the-right-settings-for-the-swapchain">Choosing the right settings for the swapchain</a></h2>
<p>If the conditions we just added were met then the support is definitely sufficient, but there may still be many different modes of varying optimality. We'll now write a couple of functions to find the right settings for the best possible swapchain. There are three types of settings to determine:</p>
<ul>
<li>Surface format (color depth)</li>
<li>Presentation mode (conditions for &quot;swapping&quot; images to the screen)</li>
<li>Swap extent (resolution of images in swapchain)</li>
</ul>
<p>For each of these settings we'll have an ideal value in mind that we'll go with if it's available and otherwise we'll create some logic to find the next best thing.</p>
<h3><a class="header" href="#surface-format" id="surface-format">Surface format</a></h3>
<p>The function for this setting starts out like this. We'll later pass the <code>formats</code> field of the <code>SwapchainSupport</code> struct as argument.</p>
<pre><code class="language-rust noplaypen">fn get_swapchain_surface_format(
    formats: &amp;[vk::SurfaceFormatKHR],
) -&gt; vk::SurfaceFormatKHR {
}
</code></pre>
<p>Each <code>vk::SurfaceFormatKHR</code> entry contains a <code>format</code> and a <code>color_space</code> member. The <code>format</code> member specifies the color channels and types. For example, <code>vk::Format::B8G8R8A8_SRGB</code> means that we store the B, G, R and alpha channels in that order with an 8 bit unsigned integer for a total of 32 bits per pixel. The <code>color_space</code> member indicates if the SRGB color space is supported or not using the <code>vk::ColorSpace::SRGB_NONLINEAR_KHR</code> flag.</p>
<p>For the color space we'll use SRGB if it is available, because it <a href="http://stackoverflow.com/questions/12524623/">results in more accurate perceived colors</a>. It is also pretty much the standard color space for images, like the textures we'll use later on. Because of that we should also use an SRGB color format, of which one of the most common ones is <code>vk::Format::B8G8R8A8_SRGB</code>.</p>
<p>Let's go through the list and see if the preferred combination is available:</p>
<pre><code class="language-rust noplaypen">fn get_swapchain_surface_format(
    formats: &amp;[vk::SurfaceFormatKHR],
) -&gt; vk::SurfaceFormatKHR {
    formats
        .iter()
        .cloned()
        .find(|f| {
            f.format == vk::Format::B8G8R8A8_SRGB
                &amp;&amp; f.color_space == vk::ColorSpaceKHR::SRGB_NONLINEAR
        })
        .unwrap_or_else(|| formats[0])
}
</code></pre>
<p>If that also fails then we could rank the available formats based on how &quot;good&quot; they are, but in most cases it's okay to just settle with the first format that is specified hence <code>.unwrap_or_else(|| formats[0])</code>.</p>
<h3><a class="header" href="#presentation-mode" id="presentation-mode">Presentation mode</a></h3>
<p>The presentation mode is arguably the most important setting for the swapchain, because it represents the actual conditions for showing images to the screen. There are four possible modes available in Vulkan:</p>
<ul>
<li><code>vk::PresentModeKHR::IMMEDIATE</code>: Images submitted by your application are transferred to the screen right away, which may result in tearing.</li>
<li><code>vk::PresentModeKHR::FIFO</code>: The swapchain is a queue where the display takes an image from the front of the queue when the display is refreshed and the program inserts rendered images at the back of the queue. If the queue is full then the program has to wait. This is most similar to vertical sync as found in modern games. The moment that the display is refreshed is known as &quot;vertical blank&quot;.</li>
<li><code>vk::PresentModeKHR::FIFO_RELAXED</code>: This mode only differs from the previous one if the application is late and the queue was empty at the last vertical blank. Instead of waiting for the next vertical blank, the image is transferred right away when it finally arrives. This may result in visible tearing.</li>
<li><code>vk::PresentModeKHR::MAILBOX</code>: This is another variation of the second mode. Instead of blocking the application when the queue is full, the images that are already queued are simply replaced with the newer ones. This mode can be used to implement triple buffering, which allows you to avoid tearing with significantly less latency issues than standard vertical sync that uses double buffering.</li>
</ul>
<p>Only the <code>vk::PresentModeKHR::FIFO</code> mode is guaranteed to be available, so we'll again have to write a function that looks for the best mode that is available:</p>
<pre><code class="language-rust noplaypen">fn get_swapchain_present_mode(
    present_modes: &amp;[vk::PresentModeKHR],
) -&gt; vk::PresentModeKHR {
}
</code></pre>
<p>I personally think that triple buffering is a very nice trade-off. It allows us to avoid tearing while still maintaining a fairly low latency by rendering new images that are as up-to-date as possible right until the vertical blank. So, let's look through the list to see if it's available and fall back to FIFO if it isn't:</p>
<pre><code class="language-rust noplaypen">fn get_swapchain_present_mode(
    present_modes: &amp;[vk::PresentModeKHR],
) -&gt; vk::PresentModeKHR {
    present_modes
        .iter()
        .cloned()
        .find(|m| *m == vk::PresentModeKHR::MAILBOX)
        .unwrap_or(vk::PresentModeKHR::FIFO)
}
</code></pre>
<h3><a class="header" href="#swap-extent" id="swap-extent">Swap extent</a></h3>
<p>That leaves only one major property, for which we'll add one last function:</p>
<pre><code class="language-rust noplaypen">fn get_swapchain_extent(
    window: &amp;Window,
    capabilities: vk::SurfaceCapabilitiesKHR.
) -&gt; vk::Extent2D {
}
</code></pre>
<p>The swap extent is the resolution of the swapchain images and it's almost always exactly equal to the resolution of the window that we're drawing to. The range of the possible resolutions is defined in the <code>vk::SurfaceCapabilitiesKHR</code> structure. Vulkan tells us to match the resolution of the window by setting the width and height in the <code>current_extent</code> member. However, some window managers do allow us to differ here and this is indicated by setting the width and height in <code>current_extent</code> to a special value: the maximum value of <code>u32</code>. In that case we'll pick the resolution that best matches the window within the <code>min_image_extent</code> and <code>max_image_extent</code> bounds.</p>
<pre><code class="language-rust noplaypen">fn get_swapchain_extent(
    window: &amp;Window,
    capabilities: vk::SurfaceCapabilitiesKHR,
) -&gt; vk::Extent2D {
    if capabilities.current_extent.width != u32::max_value() {
        capabilities.current_extent
    } else {
        let size = window.inner_size();
        let clamp = |min: u32, max: u32, v: u32| min.max(max.min(v));
        vk::Extent2D::builder()
            .width(clamp(
                capabilities.min_image_extent.width,
                capabilities.max_image_extent.width,
                size.width,
            ))
            .height(clamp(
                capabilities.min_image_extent.height,
                capabilities.max_image_extent.height,
                size.height,
            ))
            .build()
    }
}
</code></pre>
<p>We define the <code>clamp</code> function to restrict the actual size of the window within the supported range supported by the Vulkan device.</p>
<h2><a class="header" href="#creating-the-swapchain" id="creating-the-swapchain">Creating the swapchain</a></h2>
<p>Now that we have all of these helper functions assisting us with the choices we have to make at runtime, we finally have all the information that is needed to create a working swapchain.</p>
<p>Create a <code>create_swapchain</code> function that starts out with the results of these calls and make sure to call it from <code>App::create</code> after logical device creation.</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...

        let device = create_logical_device(&amp;instance, &amp;mut data)?;
        create_swapchain(window, &amp;instance, &amp;device, &amp;mut data)?;

        // ...
    }
}

fn create_swapchain(
    window: &amp;Window,
    instance: &amp;Instance,
    device: &amp;Device,
    data: &amp;mut AppData,
) -&gt; Result&lt;()&gt; {
    let indices = QueueFamilyIndices::get(instance, data, data.physical_device)?;
    let support = SwapchainSupport::get(instance, data, data.physical_device)?;

    let surface_format = get_swapchain_surface_format(&amp;support.formats);
    let present_mode = get_swapchain_present_mode(&amp;support.present_modes);
    let extent = get_swapchain_extent(window, support.capabilities);

    Ok(())
}
</code></pre>
<p>Aside from these properties we also have to decide how many images we would like to have in the swapchain. The implementation specifies the minimum number that it requires to function:</p>
<pre><code class="language-rust noplaypen">let image_count = support.capabilities.min_image_count;
</code></pre>
<p>However, simply sticking to this minimum means that we may sometimes have to wait on the driver to complete internal operations before we can acquire another image to render to. Therefore it is recommended to request at least one more image than the minimum:</p>
<pre><code class="language-rust noplaypen">let image_count = support.capabilities.min_image_count + 1;
</code></pre>
<p>We should also make sure to not exceed the maximum number of images while doing this, where <code>0</code> is a special value that means that there is no maximum:</p>
<pre><code class="language-rust noplaypen">let mut image_count = support.capabilities.min_image_count + 1;
if support.capabilities.max_image_count != 0
    &amp;&amp; image_count &gt; support.capabilities.min_image_count
{
    image_count = support.capabilities.max_image_count;
}
</code></pre>
<p>Next, we need to specify how to handle swapchain images that will be used across multiple queue families. That will be the case in our application if the graphics queue family is different from the presentation queue. We'll be drawing on the images in the swapchain from the graphics queue and then submitting them on the presentation queue. There are two ways to handle images that are accessed from multiple queues:</p>
<ul>
<li><code>vk::SharingMode::EXCLUSIVE</code>: An image is owned by one queue family at a time and ownership must be explicitly transferred before using it in another queue family. This option offers the best performance.</li>
<li><code>vk::SharingMode::CONCURRENT</code>: Images can be used across multiple queue families without explicit ownership transfers.</li>
</ul>
<p>If the queue families differ, then we'll be using the concurrent mode in this tutorial to avoid having to do the ownership chapters, because these involve some concepts that are better explained at a later time. Concurrent mode requires you to specify in advance between which queue families ownership will be shared using the <code>queue_family_indices</code> builder struct method If the graphics queue family and presentation queue family are the same, which will be the case on most hardware, then we should stick to exclusive mode, because concurrent mode requires you to specify at least two distinct queue families.</p>
<pre><code class="language-rust noplaypen">let mut queue_family_indices = vec![];
let image_sharing_mode = if indices.graphics != indices.present {
    queue_family_indices.push(indices.graphics);
    queue_family_indices.push(indices.present);
    vk::SharingMode::CONCURRENT
} else {
    vk::SharingMode::EXCLUSIVE
};
</code></pre>
<p>As is tradition with Vulkan objects, creating the swapchain object requires filling in a large structure. It starts out very familiarly:</p>
<pre><code class="language-rust noplaypen">let info = vk::SwapchainCreateInfoKHR::builder()
    .surface(data.surface)
    // continued...
</code></pre>
<p>After specifying which surface the swapchain should be tied to, the details of the swapchain images are specified:</p>
<pre><code class="language-rust noplaypen">    .min_image_count(image_count)
    .image_format(surface_format.format)
    .image_color_space(surface_format.color_space)
    .image_extent(extent)
    .image_array_layers(1)
    .image_usage(vk::ImageUsageFlags::COLOR_ATTACHMENT)
</code></pre>
<p>The <code>image_array_layers</code> specifies the amount of layers each image consists of. This is always <code>1</code> unless you are developing a stereoscopic 3D application. The <code>image_usage</code> bitmask specifies what kind of operations we'll use the images in the swapchain for. In this tutorial we're going to render directly to them, which means that they're used as color attachment. It is also possible that you'll render images to a separate image first to perform operations like post-processing. In that case you may use a value like <code>vk::ImageUsageFlags::TRANSFER_DST</code> instead and use a memory operation to transfer the rendered image to a swapchain image.</p>
<pre><code class="language-rust noplaypen">    .image_sharing_mode(image_sharing_mode)
    .queue_family_indices(&amp;queue_family_indices)
</code></pre>
<p>Next we'll provide the image sharing mode and indices of the queue families permitted to share the swapchain images.</p>
<pre><code class="language-rust noplaypen">    .pre_transform(support.capabilities.current_transform)
</code></pre>
<p>We can specify that a certain transform should be applied to images in the swapchain if it is supported (<code>supported_transforms</code> in <code>capabilities</code>), like a 90 degree clockwise rotation or horizontal flip. To specify that you do not want any transformation, simply specify the current transformation.</p>
<pre><code class="language-rust noplaypen">    .composite_alpha(vk::CompositeAlphaFlagsKHR::OPAQUE)
</code></pre>
<p>The <code>composite_alpha</code> method specifies if the alpha channel should be used for blending with other windows in the window system. You'll almost always want to simply ignore the alpha channel, hence <code>vk::CompositeAlphaFlagsKHR::OPAQUE</code>.</p>
<pre><code class="language-rust noplaypen">    .present_mode(present_mode)
    .clipped(true)
</code></pre>
<p>The <code>present_mode</code> member speaks for itself. If the <code>clipped</code> member is set to <code>true</code> then that means that we don't care about the color of pixels that are obscured, for example because another window is in front of them. Unless you really need to be able to read these pixels back and get predictable results, you'll get the best performance by enabling clipping.</p>
<pre><code class="language-rust noplaypen">    .old_swapchain(vk::SwapchainKHR::null());
</code></pre>
<p>That leaves one last method, <code>old_swapchain</code>. With Vulkan it's possible that your swapchain becomes invalid or unoptimized while your application is running, for example because the window was resized. In that case the swapchain actually needs to be recreated from scratch and a reference to the old one must be specified in this method. This is a complex topic that we'll learn more about in a future chapter. For now we'll assume that we'll only ever create one swapchain. We could omit this method since the underlying field will default to a null handle, but we'll leave it in for completeness.</p>
<p>Now add an <code>AppData</code> field to store the <code>vk::SwapchainKHR</code> object:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    swapchain: vk::SwapchainKHR,
}
</code></pre>
<p>Creating the swapchain is now as simple as calling <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.KhrSwapchainExtension.html#method.create_swapchain_khr"><code>vk::KhrSwapchainExtension::create_swapchain</code></a>:</p>
<pre><code class="language-rust noplaypen">data.swapchain = device.create_swapchain_khr(&amp;info, None)?;
</code></pre>
<p>The parameters are the swapchain creation info and optional custom allocators. No surprises there. It should be cleaned up in <code>App::destroy</code> before the device:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.device.destroy_swapchain_khr(self.data.swapchain, None);
        // ...
    }
}
</code></pre>
<p>Now run the application to ensure that the swapchain is created successfully! If at this point you get an access violation error in <code>vkCreateSwapchainKHR</code> or see a message like <code>Failed to find 'vkGetInstanceProcAddress' in layer SteamOverlayVulkanLayer.dll</code>, then see the <a href="presentation/../faq.html">FAQ entry</a> about the Steam overlay layer.</p>
<p>Try removing the <code>.image_extent(extent)</code> line from where you are building the <code>vk::SwapchainCreateInfoKHR</code> struct with validation layers enabled. You'll see that one of the validation layers immediately catches the mistake and some helpful messages are printed which call out the illegal value provided for <code>image_extent</code>:</p>
<p><img src="presentation/../images/swapchain_validation_layer.png" alt="" /></p>
<h2><a class="header" href="#retrieving-the-swapchain-images" id="retrieving-the-swapchain-images">Retrieving the swapchain images</a></h2>
<p>The swapchain has been created now, so all that remains is retrieving the handles of the <code>vk::Image</code>s in it. We'll reference these during rendering operations in later chapters. Add an <code>AppData</code> field to store the handles:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    swapchain_images: Vec&lt;vk::Image&gt;,
}
</code></pre>
<p>The images were created by the implementation for the swapchain and they will be automatically cleaned up once the swapchain has been destroyed, therefore we don't need to add any cleanup code.</p>
<p>I'm adding the code to retrieve the handles to the end of the <code>create_swapchain</code> function, right after the <code>device.create_swapchain_khr(...)</code> call.</p>
<pre><code class="language-rust noplaypen">data.swapchain_images = device.get_swapchain_images_khr(data.swapchain)?;
</code></pre>
<p>One last thing, store the format and extent we've chosen for the swapchain images in <code>AppData</code> fields. We'll need them in future chapters.</p>
<pre><code class="language-rust noplaypen">impl AppData {
    // ...
    swapchain_format: vk::Format,
    swapchain_extent: vk::Extent2D,
    swapchain: vk::SwapchainKHR,
    swapchain_images: Vec&lt;vk::Image&gt;,
}
</code></pre>
<p>And then in <code>create_swapchain</code>:</p>
<pre><code class="language-rust noplaypen">data.swapchain_format = surface_format.format;
data.swapchain_extent = extent;
</code></pre>
<p>We now have a set of images that can be drawn onto and can be presented to the window. The next chapter will begin to cover how we can set up the images as render targets and then we start looking into the actual graphics pipeline and drawing commands!</p>
<h1><a class="header" href="#image-views" id="image-views">Image views</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/07_image_views.rs">main.rs</a></p>
<p>To use any <code>vk::Image</code>, including those in the swapchain, in the render pipeline we have to create a <code>vk::ImageView</code> object. An image view is quite literally a view into an image. It describes how to access the image and which part of the image to access, for example if it should be treated as a 2D texture depth texture without any mipmapping levels.</p>
<p>In this chapter we'll write a <code>create_image_views</code> function that creates a basic image view for every image in the swapchain so that we can use them as color targets later on.</p>
<p>First add an <code>AppData</code> field to store the image views in:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    swapchain_image_views: Vec&lt;vk::ImageView&gt;,
}

</code></pre>
<p>Create the <code>create_image_views</code> function and call it right after swapchain creation in <code>App::create</code>.</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...
        create_swapchain_image_views(&amp;device, &amp;mut data)?;
        // ...
    }
}

fn create_swapchain_image_views(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    Ok(())
}
</code></pre>
<p>What we next need to do is iterate over the swapchain images to create an image view for each:</p>
<pre><code class="language-rust noplaypen">fn create_swapchain_image_views(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    data.swapchain_image_views = data
        .swapchain_images
        .iter()
        .map(|i| {

        })
        .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;()?;

    Ok(())
}
</code></pre>
<p>For each image view we are creating we'll first need to define the color component mapping for the image view. This allows you to swizzle the color channels around. For example, you can map all of the channels to the red channel for a monochrome texture. You can also map constant values of <code>0</code> and <code>1</code> to a channel. In our case we'll stick to the default mapping.</p>
<pre><code class="language-rust noplaypen">let components = vk::ComponentMapping::builder()
    .r(vk::ComponentSwizzle::IDENTITY)
    .g(vk::ComponentSwizzle::IDENTITY)
    .b(vk::ComponentSwizzle::IDENTITY)
    .a(vk::ComponentSwizzle::IDENTITY);
</code></pre>
<p>Next we will define the subresource range for the image view which describes the image's purpose and which part of the image should be accessed. Our images will be used as color targets without any mipmapping levels or multiple layers.</p>
<pre><code class="language-rust noplaypen">let subresource_range = vk::ImageSubresourceRange::builder()
    .aspect_mask(vk::ImageAspectFlags::COLOR)
    .base_mip_level(0)
    .level_count(1)
    .base_array_layer(0)
    .layer_count(1);
</code></pre>
<p>If you were working on a stereographic 3D application, then you would create a swapchain with multiple layers. You could then create multiple image views for each image representing the views for the left and right eyes by accessing different layers.</p>
<p>We can now create a <code>vk::ImageViewCreateInfo</code> struct which provides the parameters for image view creation.</p>
<pre><code class="language-rust noplaypen">let info = vk::ImageViewCreateInfo::builder()
    .image(*i)
    .view_type(vk::ImageViewType::_2D)
    .format(data.swapchain_format)
    .components(components)
    .subresource_range(subresource_range);
</code></pre>
<p>The <code>view_type</code> and <code>format</code> fields specify how the image data should be interpreted. The <code>view_type</code> field allows you to treat images as 1D textures, 2D textures, 3D textures, and cube maps.</p>
<p>Creating the image view is now a matter of calling <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.create_image_view"><code>DeviceV1_0::create_image_view</code></a>:</p>
<pre><code class="language-rust noplaypen">device.create_image_view(&amp;info, None)
</code></pre>
<p>Unlike images, the image views were explicitly created by us, so we need to add a similar loop to destroy them again in <code>App::destroy</code>:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.data.swapchain_image_views
            .iter()
            .for_each(|v| self.device.destroy_image_view(*v, None));
        // ...
    }
}
</code></pre>
<p>An image view is sufficient to start using an image as a texture, but it's not quite ready to be used as a render target just yet. That requires one more step of indirection, known as a framebuffer. But first we'll have to set up the graphics pipeline.</p>
<h1><a class="header" href="#introduction-1" id="introduction-1">Introduction</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/08_graphics_pipeline.rs">main.rs</a></p>
<p>Over the course of the next few chapters we'll be setting up a graphics pipeline that is configured to draw our first triangle. The graphics pipeline is the sequence of operations that take the vertices and textures of your meshes all the way to the pixels in the render targets. A simplified overview is displayed below:</p>
<p><img src="pipeline/../images/vulkan_simplified_pipeline.svg" alt="" /></p>
<p>The <em>input assembler</em> collects the raw vertex data from the buffers you specify and may also use an index buffer to repeat certain elements without having to duplicate the vertex data itself.</p>
<p>The <em>vertex shader</em> is run for every vertex and generally applies transformations to turn vertex positions from model space to screen space. It also passes per-vertex data down the pipeline.</p>
<p>The <em>tessellation shaders</em> allow you to subdivide geometry based on certain rules to increase the mesh quality. This is often used to make surfaces like brick walls and staircases look less flat when they are nearby.</p>
<p>The <em>geometry shader</em> is run on every primitive (triangle, line, point) and can discard it or output more primitives than came in. This is similar to the tessellation shader, but much more flexible. However, it is not used much in today's applications because the performance is not that good on most graphics cards except for Intel's integrated GPUs.</p>
<p>The <em>rasterization</em> stage discretizes the primitives into <em>fragments</em>. These are the pixel elements that they fill on the framebuffer. Any fragments that fall outside the screen are discarded and the attributes outputted by the vertex shader are interpolated across the fragments, as shown in the figure. Usually the fragments that are behind other primitive fragments are also discarded here because of depth testing.</p>
<p>The <em>fragment shader</em> is invoked for every fragment that survives and determines which framebuffer(s) the fragments are written to and with which color and depth values. It can do this using the interpolated data from the vertex shader, which can include things like texture coordinates and normals for lighting.</p>
<p>The <em>color blending</em> stage applies operations to mix different fragments that map to the same pixel in the framebuffer. Fragments can simply overwrite each other, add up or be mixed based upon transparency.</p>
<p>Stages with a green color are known as <em>fixed-function</em> stages. These stages allow you to tweak their operations using parameters, but the way they work is predefined.</p>
<p>Stages with an orange color on the other hand are <em>programmable</em>, which means that you can upload your own code to the graphics card to apply exactly the operations you want. This allows you to use fragment shaders, for example, to implement anything from texturing and lighting to ray tracers. These programs run on many GPU cores simultaneously to process many objects, like vertices and fragments in parallel.</p>
<p>If you've used older APIs like OpenGL and Direct3D before, then you'll be used to being able to change any pipeline settings at will with calls like <code>glBlendFunc</code> and <code>OMSetBlendState</code>. The graphics pipeline in Vulkan is almost completely immutable, so you must recreate the pipeline from scratch if you want to change shaders, bind different framebuffers or change the blend function. The disadvantage is that you'll have to create a number of pipelines that represent all of the different combinations of states you want to use in your rendering operations. However, because all of the operations you'll be doing in the pipeline are known in advance, the driver can optimize for it much better.</p>
<p>Some of the programmable stages are optional based on what you intend to do. For example, the tessellation and geometry stages can be disabled if you are just drawing simple geometry. If you are only interested in depth values then you can disable the fragment shader stage, which is useful for <a href="https://en.wikipedia.org/wiki/Shadow_mapping">shadow map</a> generation.</p>
<p>In the next chapter we'll first create the two programmable stages required to put a triangle onto the screen: the vertex shader and fragment shader. The fixed-function configuration like blending mode, viewport, rasterization will be set up in the chapter after that. The final part of setting up the graphics pipeline in Vulkan involves the specification of input and output framebuffers.</p>
<p>Create a <code>create_pipeline</code> function that is called right after <code>create_swapchain_image_views</code> in <code>App::create</code>. We'll work on this function throughout the following chapters.</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...
        create_swapchain_image_views(&amp;device, &amp;mut data)?;
        create_pipeline(&amp;device, &amp;mut data)?;
        // ...
    }
}

fn create_pipeline(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    Ok(())
}
</code></pre>
<h1><a class="header" href="#shader-modules" id="shader-modules">Shader modules</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/09_shader_modules.rs">main.rs</a> | <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/shaders/09/shader.vert">shader.vert</a> | <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/shaders/09/shader.frag">shader.frag</a></p>
<p>Unlike earlier APIs, shader code in Vulkan has to be specified in a bytecode format as opposed to human-readable syntax like <a href="https://en.wikipedia.org/wiki/OpenGL_Shading_Language">GLSL</a> and <a href="https://en.wikipedia.org/wiki/High-Level_Shading_Language">HLSL</a>. This bytecode format is called <a href="https://www.khronos.org/spir">SPIR-V</a> and is designed to be used with both Vulkan and OpenCL (both Khronos APIs). It is a format that can be used to write graphics and compute shaders, but we will focus on shaders used in Vulkan's graphics pipelines in this tutorial.</p>
<p>The advantage of using a bytecode format is that the compilers written by GPU vendors to turn shader code into native code are significantly less complex. The past has shown that with human-readable syntax like GLSL, some GPU vendors were rather flexible with their interpretation of the standard. If you happen to write non-trivial shaders with a GPU from one of these vendors, then you'd risk other vendor's drivers rejecting your code due to syntax errors, or worse, your shader running differently because of compiler bugs. With a straightforward bytecode format like SPIR-V that will hopefully be avoided.</p>
<p>However, that does not mean that we need to write this bytecode by hand. Khronos has released their own vendor-independent compiler that compiles GLSL to SPIR-V. This compiler is designed to verify that your shader code is fully standards compliant and produces one SPIR-V binary that you can ship with your program. You can also include this compiler as a library to produce SPIR-V at runtime, but we won't be doing that in this tutorial. Although we can use this compiler directly via <code>glslangValidator.exe</code>, we will be using <code>glslc.exe</code> by Google instead. The advantage of <code>glslc</code> is that it uses the same parameter format as well-known compilers like GCC and Clang and includes some extra functionality like <em>includes</em>. Both of them are already included in the Vulkan SDK, so you don't need to download anything extra.</p>
<p>GLSL is a shading language with a C-style syntax. Programs written in it have a <code>main</code> function that is invoked for every object. Instead of using parameters for input and a return value as output, GLSL uses global variables to handle input and output. The language includes many features to aid in graphics programming, like built-in vector and matrix primitives. Functions for operations like cross products, matrix-vector products and reflections around a vector are included. The vector type is called <code>vec</code> with a number indicating the amount of elements. For example, a 3D position would be stored in a <code>vec3</code>. It is possible to access single components through fields like <code>.x</code>, but it's also possible to create a new vector from multiple components at the same time. For example, the expression <code>vec3(1.0, 2.0, 3.0).xy</code> would result in <code>vec2</code>. The constructors of vectors can also take combinations of vector objects and scalar values. For example, a <code>vec3</code> can be constructed with <code>vec3(vec2(1.0, 2.0), 3.0)</code>.</p>
<p>As the previous chapter mentioned, we need to write a vertex shader and a fragment shader to get a triangle on the screen. The next two sections will cover the GLSL code of each of those and after that I'll show you how to produce two SPIR-V binaries and load them into the program.</p>
<h2><a class="header" href="#vertex-shader" id="vertex-shader">Vertex shader</a></h2>
<p>The vertex shader processes each incoming vertex. It takes its attributes, like world position, color, normal and texture coordinates as input. The output is the final position in clip coordinates and the attributes that need to be passed on to the fragment shader, like color and texture coordinates. These values will then be interpolated over the fragments by the rasterizer to produce a smooth gradient.</p>
<p>A <em>clip coordinate</em> is a four dimensional vector from the vertex shader that is subsequently turned into a <em>normalized device coordinate</em> by dividing the whole vector by its last component. These normalized device coordinates are <a href="https://en.wikipedia.org/wiki/Homogeneous_coordinates">homogeneous coordinates</a> that map the framebuffer to a [-1, 1] by [-1, 1] coordinate system that looks like the following:</p>
<p><img src="pipeline/../images/normalized_device_coordinates.svg" alt="" /></p>
<p>You should already be familiar with these if you have dabbled in computer graphics before. If you have used OpenGL before, then you'll notice that the sign of the Y coordinates is now flipped. The Z coordinate now uses the same range as it does in Direct3D, from 0 to 1.</p>
<p>For our first triangle we won't be applying any transformations, we'll just specify the positions of the three vertices directly as normalized device coordinates to create the following shape:</p>
<p><img src="pipeline/../images/triangle_coordinates.svg" alt="" /></p>
<p>We can directly output normalized device coordinates by outputting them as clip coordinates from the vertex shader with the last component set to <code>1</code>. That way the division to transform clip coordinates to normalized device coordinates will not change anything.</p>
<p>Normally these coordinates would be stored in a vertex buffer, but creating a vertex buffer in Vulkan and filling it with data is not trivial. Therefore I've decided to postpone that until after we've had the satisfaction of seeing a triangle pop up on the screen. We're going to do something a little unorthodox in the meanwhile: include the coordinates directly inside the vertex shader. The code looks like this:</p>
<pre><code class="language-glsl">#version 450

vec2 positions[3] = vec2[](
    vec2(0.0, -0.5),
    vec2(0.5, 0.5),
    vec2(-0.5, 0.5)
);

void main() {
    gl_Position = vec4(positions[gl_VertexIndex], 0.0, 1.0);
}
</code></pre>
<p>The <code>main</code> function is invoked for every vertex. The built-in <code>gl_VertexIndex</code> variable contains the index of the current vertex. This is usually an index into the vertex buffer, but in our case it will be an index into a hardcoded array of vertex data. The position of each vertex is accessed from the constant array in the shader and combined with dummy <code>z</code> and <code>w</code> components to produce a position in clip coordinates. The built-in variable <code>gl_Position</code> functions as the output.</p>
<h2><a class="header" href="#fragment-shader" id="fragment-shader">Fragment shader</a></h2>
<p>The triangle that is formed by the positions from the vertex shader fills an area on the screen with fragments. The fragment shader is invoked on these fragments to produce a color and depth for the framebuffer (or framebuffers). A simple fragment shader that outputs the color red for the entire triangle looks like this:</p>
<pre><code class="language-glsl">#version 450

layout(location = 0) out vec4 outColor;

void main() {
    outColor = vec4(1.0, 0.0, 0.0, 1.0);
}
</code></pre>
<p>The <code>main</code> function is called for every fragment just like the vertex shader <code>main</code> function is called for every vertex. Colors in GLSL are 4-component vectors with the R, G, B and alpha channels within the [0, 1] range. Unlike <code>gl_Position</code> in the vertex shader, there is no built-in variable to output a color for the current fragment. You have to specify your own output variable for each framebuffer where the <code>layout(location = 0)</code> modifier specifies the index of the framebuffer. The color red is written to this <code>outColor</code> variable that is linked to the first (and only) framebuffer at index <code>0</code>.</p>
<h2><a class="header" href="#per-vertex-colors" id="per-vertex-colors">Per-vertex colors</a></h2>
<p>Making the entire triangle red is not very interesting, wouldn't something like the following look a lot nicer?</p>
<p><img src="pipeline/../images/triangle_coordinates_colors.png" alt="" /></p>
<p>We have to make a couple of changes to both shaders to accomplish this. First off, we need to specify a distinct color for each of the three vertices. The vertex shader should now include an array with colors just like it does for positions:</p>
<pre><code class="language-glsl">vec3 colors[3] = vec3[](
    vec3(1.0, 0.0, 0.0),
    vec3(0.0, 1.0, 0.0),
    vec3(0.0, 0.0, 1.0)
);
</code></pre>
<p>Now we just need to pass these per-vertex colors to the fragment shader so it can output their interpolated values to the framebuffer. Add an output for color to the vertex shader and write to it in the <code>main</code> function:</p>
<pre><code class="language-glsl">layout(location = 0) out vec3 fragColor;

void main() {
    gl_Position = vec4(positions[gl_VertexIndex], 0.0, 1.0);
    fragColor = colors[gl_VertexIndex];
}
</code></pre>
<p>Next, we need to add a matching input in the fragment shader:</p>
<pre><code class="language-glsl">layout(location = 0) in vec3 fragColor;

void main() {
    outColor = vec4(fragColor, 1.0);
}
</code></pre>
<p>The input variable does not necessarily have to use the same name, they will be linked together using the indexes specified by the <code>location</code> directives. The <code>main</code> function has been modified to output the color along with an alpha value. As shown in the image above, the values for <code>fragColor</code> will be automatically interpolated for the fragments between the three vertices, resulting in a smooth gradient.</p>
<h2><a class="header" href="#compiling-the-shaders" id="compiling-the-shaders">Compiling the shaders</a></h2>
<p>Create a directory called <code>shaders</code> in the root directory of your project (adjacent to the <code>src</code> directory) and store the vertex shader in a file called <code>shader.vert</code> and the fragment shader in a file called <code>shader.frag</code> in that directory. GLSL shaders don't have an official extension, but these two are commonly used to distinguish them.</p>
<p>The contents of <code>shader.vert</code> should be:</p>
<pre><code class="language-glsl">#version 450

layout(location = 0) out vec3 fragColor;

vec2 positions[3] = vec2[](
    vec2(0.0, -0.5),
    vec2(0.5, 0.5),
    vec2(-0.5, 0.5)
);

vec3 colors[3] = vec3[](
    vec3(1.0, 0.0, 0.0),
    vec3(0.0, 1.0, 0.0),
    vec3(0.0, 0.0, 1.0)
);

void main() {
    gl_Position = vec4(positions[gl_VertexIndex], 0.0, 1.0);
    fragColor = colors[gl_VertexIndex];
}
</code></pre>
<p>And the contents of <code>shader.frag</code> should be:</p>
<pre><code class="language-glsl">#version 450

layout(location = 0) in vec3 fragColor;

layout(location = 0) out vec4 outColor;

void main() {
    outColor = vec4(fragColor, 1.0);
}
</code></pre>
<p>We're now going to compile these into SPIR-V bytecode using the <code>glslc</code> program.</p>
<p><strong>Windows</strong></p>
<p>Create a <code>compile.bat</code> file with the following contents:</p>
<pre><code class="language-bash">C:/VulkanSDK/x.x.x.x/Bin32/glslc.exe shader.vert -o vert.spv
C:/VulkanSDK/x.x.x.x/Bin32/glslc.exe shader.frag -o frag.spv
pause
</code></pre>
<p>Replace the path to <code>glslc.exe</code> with the path to where you installed the Vulkan SDK. Double click the file to run it.</p>
<p><strong>Linux</strong></p>
<p>Create a <code>compile.sh</code> file with the following contents:</p>
<pre><code class="language-bash">/home/user/VulkanSDK/x.x.x.x/x86_64/bin/glslc shader.vert -o vert.spv
/home/user/VulkanSDK/x.x.x.x/x86_64/bin/glslc shader.frag -o frag.spv
</code></pre>
<p>Replace the path to <code>glslc</code> with the path to where you installed the Vulkan SDK. Make the script executable with <code>chmod +x compile.sh</code> and run it.</p>
<p><strong>End of platform-specific instructions</strong></p>
<p>These two commands tell the compiler to read the GLSL source file and output a SPIR-V bytecode file using the <code>-o</code> (output) flag.</p>
<p>If your shader contains a syntax error then the compiler will tell you the line number and problem, as you would expect. Try leaving out a semicolon for example and run the compile script again. Also try running the compiler without any arguments to see what kinds of flags it supports. It can, for example, also output the bytecode into a human-readable format so you can see exactly what your shader is doing and any optimizations that have been applied at this stage.</p>
<p>Compiling shaders on the commandline is one of the most straightforward options and it's the one that we'll use in this tutorial, but it's also possible to compile shaders directly from your own code. The Vulkan SDK includes <a href="https://github.com/google/shaderc">libshaderc</a>, which is a library to compile GLSL code to SPIR-V from within your program.</p>
<h2><a class="header" href="#loading-a-shader" id="loading-a-shader">Loading a shader</a></h2>
<p>Now that we have a way of producing SPIR-V shaders, it's time to bring them into our program to plug them into the graphics pipeline at some point. We'll start by using <a href="https://doc.rust-lang.org/stable/std/macro.include_bytes.html"><code>include_bytes!</code></a> from the Rust standard library to include the compiled SPIR-V bytecode for the shaders in our executable.</p>
<pre><code class="language-rust noplaypen">fn create_pipeline(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    let vert = include_bytes!(&quot;../shaders/vert.spv&quot;);
    let frag = include_bytes!(&quot;../shaders/frag.spv&quot;);

    Ok(())
}
</code></pre>
<h2><a class="header" href="#creating-shader-modules" id="creating-shader-modules">Creating shader modules</a></h2>
<p>Before we can pass the code to the pipeline, we have to wrap it in a <code>vk::ShaderModule</code> object. Let's create a helper function <code>create_shader_module</code> to do that.</p>
<pre><code class="language-rust noplaypen">fn create_shader_module(
    device: &amp;Device,
    bytecode: &amp;[u8],
) -&gt; Result&lt;vk::ShaderModule&gt; {
}
</code></pre>
<p>The function will take a slice containing the bytecode as parameter and create a <code>vk::ShaderModule</code> from it using our logical device.</p>
<p>Creating a shader module is simple, we only need to specify the length of our bytecode slice and the bytecode slice itself. This information is specified in a <code>vk::ShaderModuleCreateInfo</code> structure. The one catch is that the size of the bytecode is specified in bytes, but the bytecode slice expected by this struct is a <code>&amp;[u32]</code> instead of a <code>&amp;[u8]</code>. Therefore we will first need to convert our <code>&amp;[u8]</code> into an <code>&amp;[u32]</code>. We will accomplish this with <a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.align_to"><code>slice::align_to</code></a> which can be used to convert a slice into a slice containing a type with a different size and/or alignment requirements.</p>
<pre><code class="language-rust noplaypen">let (prefix, code, suffix) = unsafe { bytecode.align_to::&lt;u32&gt;() };
if !prefix.is_empty() || !suffix.is_empty() {
    return Err(anyhow!(&quot;Shader bytecode is not properly aligned.&quot;));
}
</code></pre>
<p>The middle slice returned by this method (<code>code</code>) is a <code>&amp;[u32]</code> and is guaranteed to be correctly aligned. Any <code>u8</code>s in our <code>bytecode</code> slice that fell outside this alignment guarantee will appear in the first or third slices returned (<code>prefix</code> and <code>suffix</code>). We'll require that both of these slices are empty to ensure that our entire <code>bytecode</code> slice has been converted to a <code>&amp;[u32]</code> though you shouldn't have to worry about this failure case in practice.</p>
<p>We can then construct a <code>vk::ShaderModuleCreateInfo</code> and use it to call <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.create_shader_module"><code>DeviceV1_0::create_shader_module</code></a> to create the shader module:</p>
<pre><code class="language-rust noplaypen">let info = vk::ShaderModuleCreateInfo::builder()
    .code_size(bytecode.len())
    .code(code);

Ok(device.create_shader_module(&amp;info, None)?)
</code></pre>
<p>The parameters are the same as those in previous object creation functions: the create info structure and the optional custom allocators.</p>
<p>Shader modules are just a thin wrapper around the shader bytecode that we've previously loaded from a file and the functions defined in it. The compilation and linking of the SPIR-V bytecode to machine code for execution by the GPU doesn't happen until the graphics pipeline is created. That means that we're allowed to destroy the shader modules again as soon as pipeline creation is finished, which is why we'll make them local variables in the <code>create_pipeline</code> function instead of fields in <code>AppData</code>:</p>
<pre><code class="language-rust noplaypen">fn create_pipeline(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    let vert = include_bytes!(&quot;../shaders/vert.spv&quot;);
    let frag = include_bytes!(&quot;../shaders/frag.spv&quot;);

    let vert_shader_module = create_shader_module(device, &amp;vert[..])?;
    let frag_shader_module = create_shader_module(device, &amp;frag[..])?;

    // ...
</code></pre>
<p>The cleanup should then happen at the end of the function by adding two calls to <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.destroy_shader_module"><code>DeviceV1_0::destroy_shader_module</code></a>. All of the remaining code in this chapter will be inserted before these lines.</p>
<pre><code class="language-rust noplaypen">    // ...

    device.destroy_shader_module(vert_shader_module, None);
    device.destroy_shader_module(frag_shader_module, None);

    Ok(())
}
</code></pre>
<h2><a class="header" href="#shader-stage-creation" id="shader-stage-creation">Shader stage creation</a></h2>
<p>To actually use the shaders we'll need to assign them to a specific pipeline stage through <code>vk::PipelineShaderStageCreateInfo</code> structures as part of the actual pipeline creation process.</p>
<p>We'll start by filling in the structure for the vertex shader, again in the <code>create_pipeline</code> function.</p>
<pre><code class="language-rust noplaypen">let vert_stage = vk::PipelineShaderStageCreateInfo::builder()
    .stage(vk::ShaderStageFlags::VERTEX)
    .module(vert_shader_module)
    .name(b&quot;main\0&quot;[..].into());
</code></pre>
<p>The first step is telling Vulkan in which pipeline stage the shader is going to be used. There is an enum value for each of the programmable stages described in the previous chapter.</p>
<p>The next two fields specify the shader module containing the code, and the function to invoke, known as the <em>entrypoint</em>. That means that it's possible to combine multiple fragment shaders into a single shader module and use different entry points to differentiate between their behaviors. In this case we'll stick to the standard <code>main</code>, however.</p>
<p>There is one more (optional) member, <code>specialization_info</code>, which we won't be using here, but is worth discussing. It allows you to specify values for shader constants. You can use a single shader module where its behavior can be configured at pipeline creation by specifying different values for the constants used in it. This is more efficient than configuring the shader using variables at render time, because the compiler can do optimizations like eliminating <code>if</code> statements that depend on these values. If you don't have any constants like that, then you can just skip setting it as we are doing here.</p>
<p>Modifying the structure to suit the fragment shader is easy:</p>
<pre><code class="language-rust noplaypen">let frag_stage = vk::PipelineShaderStageCreateInfo::builder()
    .stage(vk::ShaderStageFlags::FRAGMENT)
    .module(frag_shader_module)
    .name(b&quot;main\0&quot;[..].into());
</code></pre>
<p>That's all there is to describing the programmable stages of the pipeline. In the next chapter we'll look at the fixed-function stages.</p>
<h1><a class="header" href="#fixed-functions" id="fixed-functions">Fixed functions</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/10_fixed_functions.rs">main.rs</a></p>
<p>The older graphics APIs provided default state for most of the stages of the graphics pipeline. In Vulkan you have to be explicit about everything, from viewport size to color blending function. In this chapter we'll fill in all of the structures to configure these fixed-function operations.</p>
<h2><a class="header" href="#vertex-input" id="vertex-input">Vertex input</a></h2>
<p>The <code>vk::PipelineVertexInputStateCreateInfo</code> structure describes the format of the vertex data that will be passed to the vertex shader. It describes this in roughly two ways:</p>
<ul>
<li>Bindings: spacing between data and whether the data is per-vertex or per-instance (see <a href="https://en.wikipedia.org/wiki/Geometry_instancing">instancing</a>)</li>
<li>Attribute descriptions: type of the attributes passed to the vertex shader, which binding to load them from and at which offset</li>
</ul>
<p>Because we're hard coding the vertex data directly in the vertex shader, we'll leave this structure with the defaults to specify that there is no vertex data to load for now. We'll get back to it in the vertex buffer chapter.</p>
<pre><code class="language-rust noplaypen">let vertex_input_state = vk::PipelineVertexInputStateCreateInfo::builder();
</code></pre>
<p>The <code>vertex_binding_descriptions</code> and <code>vertex_attribute_descriptions</code> fields for this struct that could have been set here would be slices of structs that describe the aforementioned details for loading vertex data. Add this structure to the <code>create_pipeline</code> function right after the <code>vk::PipelineShaderStageCreateInfo</code> structs.</p>
<h2><a class="header" href="#input-assembly" id="input-assembly">Input assembly</a></h2>
<p>The <code>vk::PipelineInputAssemblyStateCreateInfo</code> struct describes two things: what kind of geometry will be drawn from the vertices and if primitive restart should be enabled. The former is specified in the <code>topology</code> member and can have values like:</p>
<ul>
<li><code>vk::PrimitiveTopology::POINT_LIST</code>: points from vertices</li>
<li><code>vk::PrimitiveTopology::LINE_LIST</code>: line from every 2 vertices without reuse</li>
<li><code>vk::PrimitiveTopology::LINE_STRIP</code>: the end vertex of every line is used as start vertex for the next line</li>
<li><code>vk::PrimitiveTopology::TRIANGLE_LIST</code>: triangle from every 3 vertices without reuse</li>
<li><code>vk::PrimitiveTopology::TRIANGLE_STRIP </code>: the second and third vertex of every triangle are used as first two vertices of the next triangle</li>
</ul>
<p>Normally, the vertices are loaded from the vertex buffer by index in sequential order, but with an <em>element buffer</em> you can specify the indices to use yourself. This allows you to perform optimizations like reusing vertices. If you set the <code>primitive_restart_enable</code> member to <code>true</code>, then it's possible to break up lines and triangles in the <code>_STRIP</code> topology modes by using a special index of <code>0xFFFF</code> or <code>0xFFFFFFFF</code>.</p>
<p>We intend to draw triangles throughout this tutorial, so we'll stick to the following data for the structure:</p>
<pre><code class="language-rust noplaypen">let input_assembly_state = vk::PipelineInputAssemblyStateCreateInfo::builder()
    .topology(vk::PrimitiveTopology::TRIANGLE_LIST)
    .primitive_restart_enable(false);
</code></pre>
<h2><a class="header" href="#viewports-and-scissors" id="viewports-and-scissors">Viewports and scissors</a></h2>
<p>A viewport basically describes the region of the framebuffer that the output will be rendered to. This will almost always be <code>(0, 0)</code> to <code>(width, height)</code> and in this tutorial that will also be the case.</p>
<pre><code class="language-rust noplaypen">let viewport = vk::Viewport::builder()
    .x(0.0)
    .y(0.0)
    .width(data.swapchain_extent.width as f32)
    .height(data.swapchain_extent.height as f32)
    .min_depth(0.0)
    .max_depth(1.0);
</code></pre>
<p>Remember that the size of the swapchain and its images may differ from the <code>WIDTH</code> and <code>HEIGHT</code> of the window. The swapchain images will be used as framebuffers later on, so we should stick to their size.</p>
<p>The <code>min_depth</code> and <code>max_depth</code> values specify the range of depth values to use for the framebuffer. These values must be within the <code>[0.0, 1.0]</code> range, but <code>min_depth</code> may be higher than <code>max_depth</code>. If you aren't doing anything special, then you should stick to the standard values of <code>0.0</code> and <code>1.0</code>.</p>
<p>While viewports define the transformation from the image to the framebuffer, scissor rectangles define in which regions pixels will actually be stored. Any pixels outside the scissor rectangles will be discarded by the rasterizer. They function like a filter rather than a transformation. The difference is illustrated below. Note that the left scissor rectangle is just one of the many possibilities that would result in that image, as long as it's larger than the viewport.</p>
<p><img src="pipeline/../images/viewports_scissors.png" alt="" /></p>
<p>In this tutorial we simply want to draw to the entire framebuffer, so we'll specify a scissor rectangle that covers it entirely:</p>
<pre><code class="language-rust noplaypen">let scissor = vk::Rect2D::builder()
    .offset(vk::Offset2D { x: 0, y: 0 })
    .extent(data.swapchain_extent);
</code></pre>
<p>Now this viewport and scissor rectangle need to be combined into a viewport state using the <code>vk::PipelineViewportStateCreateInfo</code> struct. It is possible to use multiple viewports and scissor rectangles on some graphics cards, so its members reference an array of them. Using multiple requires enabling a GPU feature (see logical device creation).</p>
<pre><code class="language-rust noplaypen">let viewports = &amp;[viewport];
let scissors = &amp;[scissor];
let viewport_state = vk::PipelineViewportStateCreateInfo::builder()
    .viewports(viewports)
    .scissors(scissors);
</code></pre>
<h2><a class="header" href="#rasterizer" id="rasterizer">Rasterizer</a></h2>
<p>The rasterizer takes the geometry that is shaped by the vertices from the vertex shader and turns it into fragments to be colored by the fragment shader. It also performs <a href="https://en.wikipedia.org/wiki/Z-buffering">depth testing</a>, <a href="https://en.wikipedia.org/wiki/Back-face_culling">face culling</a> and the scissor test, and it can be configured to output fragments that fill entire polygons or just the edges (wireframe rendering). All this is configured using the <code>vk::PipelineRasterizationStateCreateInfo</code> structure.</p>
<pre><code class="language-rust noplaypen">let rasterization_state = vk::PipelineRasterizationStateCreateInfo::builder()
    .depth_clamp_enable(false)
    // continued...
</code></pre>
<p>If <code>depth_clamp_enable</code> is set to <code>true</code>, then fragments that are beyond the near and far planes are clamped to them as opposed to discarding them. This is useful in some special cases like shadow maps. Using this requires enabling a GPU feature.</p>
<pre><code class="language-rust noplaypen">    .rasterizer_discard_enable(false)
</code></pre>
<p>If <code>rasterizer_discard_enable</code> is set to <code>true</code>, then geometry never passes through the rasterizer stage. This basically disables any output to the framebuffer.</p>
<pre><code class="language-rust noplaypen">    .polygon_mode(vk::PolygonMode::FILL)
</code></pre>
<p>The <code>polygon_mode</code> determines how fragments are generated for geometry. The following modes are available:</p>
<ul>
<li><code>vk::PolygonMode::FILL</code>: fill the area of the polygon with fragments</li>
<li><code>vk::PolygonMode::LINE</code>: polygon edges are drawn as lines</li>
<li><code>vk::PolygonMode::POINT</code>: polygon vertices are drawn as points</li>
</ul>
<p>Using any mode other than fill requires enabling a GPU feature.</p>
<pre><code class="language-rust noplaypen">    .line_width(1.0)
</code></pre>
<p>The <code>line_width</code> member is straightforward, it describes the thickness of lines in terms of number of fragments. The maximum line width that is supported depends on the hardware and any line thicker than <code>1.0</code> requires you to enable the <code>wide_lines</code> GPU feature.</p>
<pre><code class="language-rust noplaypen">    .cull_mode(vk::CullModeFlags::BACK)
    .front_face(vk::FrontFace::CLOCKWISE)
</code></pre>
<p>The <code>cull_mode</code> variable determines the type of face culling to use. You can disable culling, cull the front faces, cull the back faces or both. The <code>front_face</code> variable specifies the vertex order for faces to be considered front-facing and can be clockwise or counterclockwise.</p>
<pre><code class="language-rust noplaypen">    .depth_bias_enable(false);
</code></pre>
<p>The rasterizer can alter the depth values by adding a constant value or biasing them based on a fragment's slope. This is sometimes used for shadow mapping, but we won't be using it. Just set <code>depth_bias_enable</code> to <code>false</code>.</p>
<h2><a class="header" href="#multisampling" id="multisampling">Multisampling</a></h2>
<p>The <code>vk::PipelineMultisampleStateCreateInfo</code> struct configures multisampling, which is one of the ways to perform <a href="https://en.wikipedia.org/wiki/Multisample_anti-aliasing">anti-aliasing</a>. It works by combining the fragment shader results of multiple polygons that rasterize to the same pixel. This mainly occurs along edges, which is also where the most noticeable aliasing artifacts occur. Because it doesn't need to run the fragment shader multiple times if only one polygon maps to a pixel, it is significantly less expensive than simply rendering to a higher resolution and then downscaling. Enabling it requires enabling a GPU feature.</p>
<pre><code class="language-rust noplaypen">let multisample_state = vk::PipelineMultisampleStateCreateInfo::builder()
    .sample_shading_enable(false)
    .rasterization_samples(vk::SampleCountFlags::_1);
</code></pre>
<p>We'll revisit multisampling in a later chapter, for now let's keep it disabled.</p>
<h2><a class="header" href="#depth-and-stencil-testing" id="depth-and-stencil-testing">Depth and stencil testing</a></h2>
<p>If you are using a depth and/or stencil buffer, then you also need to configure the depth and stencil tests using <code>vk::PipelineDepthStencilStateCreateInfo</code>. We don't have one right now, so we can simply ignore it for now. We'll get back to it in the depth buffering chapter.</p>
<h2><a class="header" href="#color-blending" id="color-blending">Color blending</a></h2>
<p>After a fragment shader has returned a color, it needs to be combined with the color that is already in the framebuffer. This transformation is known as color blending and there are two ways to do it:</p>
<ul>
<li>Mix the old and new value to produce a final color</li>
<li>Combine the old and new value using a bitwise operation</li>
</ul>
<p>There are two types of structs to configure color blending. The first struct, <code>vk::PipelineColorBlendAttachmentState</code> contains the configuration per attached framebuffer and the second struct, <code>vk::PipelineColorBlendStateCreateInfo</code> contains the <em>global</em> color blending settings. In our case we only have one framebuffer:</p>
<pre><code class="language-rust noplaypen">let attachment = vk::PipelineColorBlendAttachmentState::builder()
    .color_write_mask(vk::ColorComponentFlags::all())
    .blend_enable(false)
    .src_color_blend_factor(vk::BlendFactor::ONE)  // Optional
    .dst_color_blend_factor(vk::BlendFactor::ZERO) // Optional
    .color_blend_op(vk::BlendOp::ADD)              // Optional
    .src_alpha_blend_factor(vk::BlendFactor::ONE)  // Optional
    .dst_alpha_blend_factor(vk::BlendFactor::ZERO) // Optional
    .alpha_blend_op(vk::BlendOp::ADD);             // Optional
</code></pre>
<p>This per-framebuffer struct allows you to configure the first way of color blending. The operations that will be performed are best demonstrated using the following pseudocode:</p>
<pre><code class="language-rust noplaypen">if blend_enable {
    final_color.rgb = (src_color_blend_factor * new_color.rgb)
        &lt;color_blend_op&gt; (dst_color_blend_factor * old_color.rgb);
    final_color.a = (src_alpha_blend_factor * new_color.a)
        &lt;alpha_blend_op&gt; (dst_alpha_blend_factor * old_color.a);
} else {
    final_color = new_color;
}

final_color = final_color &amp; color_write_mask;
</code></pre>
<p>If <code>blend_enable</code> is set to <code>false</code>, then the new color from the fragment shader is passed through unmodified. Otherwise, the two mixing operations are performed to compute a new color. The resulting color is AND'd with the <code>color_write_mask</code> to determine which channels are actually passed through.</p>
<p>The most common way to use color blending is to implement alpha blending, where we want the new color to be blended with the old color based on its opacity. The <code>final_color</code> should then be computed as follows:</p>
<pre><code class="language-c++">final_color.rgb = new_alpha * new_color + (1 - new_alpha) * old_color;
final_color.a = new_alpha.a;
</code></pre>
<p>This can be accomplished with the following parameters:</p>
<pre><code class="language-rust noplaypen">let attachment = vk::PipelineColorBlendAttachmentState::builder()
    .color_write_mask(vk::ColorComponentFlags::all())
    .blend_enable(true)
    .src_color_blend_factor(vk::BlendFactor::SRC_ALPHA)
    .dst_color_blend_factor(vk::BlendFactor::ONE_MINUS_SRC_ALPHA)
    .color_blend_op(vk::BlendOp::ADD)
    .src_alpha_blend_factor(vk::BlendFactor::ONE)
    .dst_alpha_blend_factor(vk::BlendFactor::ZERO)
    .alpha_blend_op(vk::BlendOp::ADD);
</code></pre>
<p>You can find all of the possible operations in the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.BlendFactor.html"><code>vk::BlendFactor</code></a> and <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/struct.BlendOp.html"><code>vk::BlendOp</code></a> enumerations in the specification (or <code>vulkanalia</code>'s documentation).</p>
<p>The second structure references the array of structures for all of the framebuffers and allows you to set blend constants that you can use as blend factors in the aforementioned calculations.</p>
<pre><code class="language-rust noplaypen">let attachments = &amp;[attachment];
let color_blend_state = vk::PipelineColorBlendStateCreateInfo::builder()
    .logic_op_enable(false)
    .logic_op(vk::LogicOp::COPY)
    .attachments(attachments)
    .blend_constants([0.0, 0.0, 0.0, 0.0]);
</code></pre>
<p>If you want to use the second method of blending (bitwise combination), then you should set <code>logic_op_enable</code> to <code>true</code>. The bitwise operation can then be specified in the <code>logic_op</code> field. Note that this will automatically disable the first method, as if you had set <code>blend_enable</code> to <code>false</code> for every attached framebuffer! The <code>color_write_mask</code> will also be used in this mode to determine which channels in the framebuffer will actually be affected. It is also possible to disable both modes, as we've done here, in which case the fragment colors will be written to the framebuffer unmodified.</p>
<h2><a class="header" href="#dynamic-state" id="dynamic-state">Dynamic state</a></h2>
<p>A limited amount of the state that we've specified in the previous structs <em>can</em> actually be changed without recreating the pipeline. Examples are the size of the viewport, line width and blend constants. If you want to do that, then you'll have to fill in a <code>vk::PipelineDynamicStateCreateInfo</code> structure like this:</p>
<pre><code class="language-rust noplaypen">let dynamic_states = &amp;[
    vk::DynamicState::VIEWPORT,
    vk::DynamicState::LINE_WIDTH,
];

let dynamic_state = vk::PipelineDynamicStateCreateInfo::builder()
    .dynamic_states(dynamic_states);
</code></pre>
<p>This will cause the configuration of these values to be ignored and you will be required to specify the data at drawing time. We'll get back to this in a future chapter. This struct can be omitted if you don't have any dynamic state.</p>
<h2><a class="header" href="#pipeline-layout" id="pipeline-layout">Pipeline layout</a></h2>
<p>You can use <code>uniform</code> values in shaders, which are globals similar to dynamic state variables that can be changed at drawing time to alter the behavior of your shaders without having to recreate them. They are commonly used to pass the transformation matrix to the vertex shader, or to create texture samplers in the fragment shader.</p>
<p>These uniform values need to be specified during pipeline creation by creating a <code>vk::PipelineLayout</code> object. Even though we won't be using them until a future chapter, we are still required to create an empty pipeline layout.</p>
<p>Create an <code>AppData</code> field to hold this object, because we'll refer to it from other functions at a later point in time:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    pipeline_layout: vk::PipelineLayout,
}
</code></pre>
<p>And then create the object in the <code>create_pipeline</code> function:</p>
<pre><code class="language-rust noplaypen">let layout_info = vk::PipelineLayoutCreateInfo::builder();

data.pipeline_layout = device.create_pipeline_layout(&amp;layout_info, None)?;
</code></pre>
<p>The structure also specifies <em>push constants</em>, which are another way of passing dynamic values to shaders that we may get into in a future chapter. The pipeline layout will be referenced throughout the program's lifetime, so it should be destroyed in <code>App::destroy</code>:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.device.destroy_pipeline_layout(self.data.pipeline_layout, None);
        // ...
    }
}
</code></pre>
<h2><a class="header" href="#conclusion" id="conclusion">Conclusion</a></h2>
<p>That's it for all of the fixed-function state! It's a lot of work to set all of this up from scratch, but the advantage is that we're now nearly fully aware of everything that is going on in the graphics pipeline! This reduces the chance of running into unexpected behavior because the default state of certain components is not what you expect.</p>
<p>There is however one more object to create before we can finally create the graphics pipeline and that is a render pass.</p>
<h1><a class="header" href="#render-passes" id="render-passes">Render passes</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/11_render_passes.rs">main.rs</a></p>
<p>Before we can finish creating the pipeline, we need to tell Vulkan about the framebuffer attachments that will be used while rendering. We need to specify how many color and depth buffers there will be, how many samples to use for each of them and how their contents should be handled throughout the rendering operations. All of this information is wrapped in a <em>render pass</em> object, for which we'll create a new <code>create_render_pass</code> function. Call this function from <code>App::create</code> before <code>create_pipeline</code>.</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...
        create_render_pass(&amp;instance, &amp;device, &amp;mut data)?;
        create_pipeline(&amp;device, &amp;mut data)?;
        // ...
    }
}

fn create_render_pass(
    instance: &amp;Instance,
    device: &amp;Device,
    data: &amp;mut AppData,
) -&gt; Result&lt;()&gt; {
    Ok(())
}
</code></pre>
<h2><a class="header" href="#attachment-description" id="attachment-description">Attachment description</a></h2>
<p>In our case we'll have just a single color buffer attachment represented by one of the images from the swapchain. This will be represented by a <code>vk::AttachmentDescription</code> which we will build in <code>create_render_pass</code>.</p>
<pre><code class="language-rust noplaypen">let color_attachment = vk::AttachmentDescription::builder()
    .format(data.swapchain_format)
    .samples(vk::SampleCountFlags::_1)
    // continued...
</code></pre>
<p>The <code>format</code> of the color attachment should match the format of the swapchain images, and we're not doing anything with multisampling yet, so we'll stick to 1 sample.</p>
<pre><code class="language-rust noplaypen">    .load_op(vk::AttachmentLoadOp::CLEAR)
    .store_op(vk::AttachmentStoreOp::STORE)
</code></pre>
<p>The <code>load_op</code> and <code>store_op</code> determine what to do with the data in the attachment before rendering and after rendering. We have the following choices for <code>load_op</code>:</p>
<ul>
<li><code>vk::AttachmentLoadOp::LOAD</code>: Preserve the existing contents of the attachment</li>
<li><code>vk::AttachmentLoadOp::CLEAR</code>: Clear the values to a constant at the start</li>
<li><code>vk::AttachmentLoadOp::DONT_CARE</code>: Existing contents are undefined; we don't care about them</li>
</ul>
<p>In our case we're going to use the clear operation to clear the framebuffer to black before drawing a new frame. There are only two possibilities for the <code>store_op</code>:</p>
<ul>
<li><code>vk::AttachmentStoreOp::STORE</code>: Rendered contents will be stored in memory and can be read later</li>
<li><code>vk::AttachmentStoreOp::DONT_CARE</code>: Contents of the framebuffer will be undefined after the rendering operation</li>
</ul>
<p>We're interested in seeing the rendered triangle on the screen, so we're going with the store operation here.</p>
<pre><code class="language-rust noplaypen">    .stencil_load_op(vk::AttachmentLoadOp::DONT_CARE)
    .stencil_store_op(vk::AttachmentStoreOp::DONT_CARE)
</code></pre>
<p>The <code>load_op</code> and <code>store_op</code> apply to color and depth data, and <code>stencil_load_op</code> / <code>stencil_store_op</code> apply to stencil data. Our application won't do anything with the stencil buffer, so the results of loading and storing are irrelevant.</p>
<pre><code class="language-rust noplaypen">    .initial_layout(vk::ImageLayout::UNDEFINED)
    .final_layout(vk::ImageLayout::PRESENT_SRC_KHR);
</code></pre>
<p>Textures and framebuffers in Vulkan are represented by <code>vk::Image</code> objects with a certain pixel format, however the layout of the pixels in memory can change based on what you're trying to do with an image.</p>
<p>Some of the most common layouts are:</p>
<ul>
<li><code>vk::ImageLayout::COLOR_ATTACHMENT_OPTIMAL</code>: Images used as color attachment</li>
<li><code>vk::ImageLayout::PRESENT_SRC_KHR</code>: Images to be presented in the swapchain</li>
<li><code>vk::ImageLayout::TRANSFER_DST_OPTIMAL</code>: Images to be used as destination for a memory copy operation</li>
</ul>
<p>We'll discuss this topic in more depth in the texturing chapter, but what's important to know right now is that images need to be transitioned to specific layouts that are suitable for the operation that they're going to be involved in next.</p>
<p>The <code>initial_layout</code> specifies which layout the image will have before the render pass begins. The <code>final_layout</code> specifies the layout to automatically transition to when the render pass finishes. Using <code>vk::ImageLayout::UNDEFINED</code> for <code>initial_layout</code> means that we don't care what previous layout the image was in. The caveat of this special value is that the contents of the image are not guaranteed to be preserved, but that doesn't matter since we're going to clear it anyway. We want the image to be ready for presentation using the swapchain after rendering, which is why we use <code>vk::ImageLayout::PRESENT_SRC_KHR</code> as <code>final_layout</code>.</p>
<h2><a class="header" href="#subpasses-and-attachment-references" id="subpasses-and-attachment-references">Subpasses and attachment references</a></h2>
<p>A single render pass can consist of multiple subpasses. Subpasses are subsequent rendering operations that depend on the contents of framebuffers in previous passes, for example a sequence of post-processing effects that are applied one after another. If you group these rendering operations into one render pass, then Vulkan is able to reorder the operations and conserve memory bandwidth for possibly better performance. For our very first triangle, however, we'll stick to a single subpass.</p>
<p>Every subpass references one or more of the attachments that we've described using the structure in the previous sections. These references are themselves <code>vk::AttachmentReference</code> structs that look like this:</p>
<pre><code class="language-rust noplaypen">let color_attachment_ref = vk::AttachmentReference::builder()
    .attachment(0)
    .layout(vk::ImageLayout::COLOR_ATTACHMENT_OPTIMAL);
</code></pre>
<p>The <code>attachment</code> parameter specifies which attachment to reference by its index in the attachment descriptions array. Our array consists of a single <code>vk::AttachmentDescription</code>, so its index is <code>0</code>. The <code>layout</code> specifies which layout we would like the attachment to have during a subpass that uses this reference. Vulkan will automatically transition the attachment to this layout when the subpass is started. We intend to use the attachment to function as a color buffer and the <code>vk::ImageLayout::COLOR_ATTACHMENT_OPTIMAL</code> layout will give us the best performance, as its name implies.</p>
<p>The subpass is described using a <code>vk::SubpassDescription</code> structure:</p>
<pre><code class="language-rust noplaypen">let color_attachments = &amp;[color_attachment_ref];
let subpass = vk::SubpassDescription::builder()
    .pipeline_bind_point(vk::PipelineBindPoint::GRAPHICS)
    .color_attachments(color_attachments);
</code></pre>
<p>Vulkan may also support compute subpasses in the future, so we have to be explicit about this being a graphics subpass. Then we specify the reference to the color attachment.</p>
<p>The index of the attachment in this array is directly referenced from the fragment shader with the <code>layout(location = 0) out vec4 outColor</code> directive!</p>
<p>The following other types of attachments can be referenced by a subpass:</p>
<ul>
<li><code>input_attachments</code>: Attachments that are read from a shader</li>
<li><code>resolve_attachments</code>: Attachments used for multisampling color attachments</li>
<li><code>depth_stencil_attachment</code>: Attachment for depth and stencil data</li>
<li><code>preserve_attachments</code>: Attachments that are not used by this subpass, but for which the data must be preserved</li>
</ul>
<h2><a class="header" href="#render-pass" id="render-pass">Render pass</a></h2>
<p>Now that the attachment and a basic subpass referencing it have been described, we can create the render pass itself. Create a new class member variable to hold the <code>vk::RenderPass</code> object right above the <code>pipeline_layout</code> field in <code>AppData</code>:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    render_pass: vk::RenderPass,
    pipeline_layout: vk::PipelineLayout,
}
</code></pre>
<p>The render pass object can then be created by filling in the <code>vk::RenderPassCreateInfo</code> structure with an array of attachments and subpasses. The <code>vk::AttachmentReference</code> objects reference attachments using the indices of this array.</p>
<pre><code class="language-rust noplaypen">let attachments = &amp;[color_attachment];
let subpasses = &amp;[subpass];
let info = vk::RenderPassCreateInfo::builder()
    .attachments(attachments)
    .subpasses(subpasses);

data.render_pass = device.create_render_pass(&amp;info, None)?;
</code></pre>
<p>Just like the pipeline layout, the render pass will be referenced throughout the program, so it should only be cleaned up at the end in <code>App::destroy</code>:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.device.destroy_pipeline_layout(self.data.pipeline_layout, None);
        self.device.destroy_render_pass(self.data.render_pass, None);
        // ...
    }
}
</code></pre>
<p>That was a lot of work, but in the next chapter it all comes together to finally create the graphics pipeline object!</p>
<h1><a class="header" href="#conclusion-1" id="conclusion-1">Conclusion</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/12_graphics_pipeline_complete.rs">main.rs</a></p>
<p>We can now combine all of the structures and objects from the previous chapters to create the graphics pipeline! Here's the types of objects we have now, as a quick recap:</p>
<ul>
<li>Shader stages: the shader modules that define the functionality of the programmable stages of the graphics pipeline</li>
<li>Fixed-function state: all of the structures that define the fixed-function stages of the pipeline, like input assembly, rasterizer, viewport and color blending</li>
<li>Pipeline layout: the uniform and push values referenced by the shader that can be updated at draw time</li>
<li>Render pass: the attachments referenced by the pipeline stages and their usage</li>
</ul>
<p>All of these combined fully define the functionality of the graphics pipeline, so we can now begin filling in the <code>vk::GraphicsPipelineCreateInfo</code> structure at the end of the <code>create_pipeline</code> function. But before the calls to <code>DeviceV1_0:::destroy_shader_module</code> because these are still to be used during the creation.</p>
<pre><code class="language-rust noplaypen">let stages = &amp;[vert_stage, frag_stage];
let info = vk::GraphicsPipelineCreateInfo::builder()
    .stages(stages)
    // continued...
</code></pre>
<p>We start by providing an array of the <code>vk::PipelineShaderStageCreateInfo</code> structs.</p>
<pre><code class="language-rust noplaypen">    .vertex_input_state(&amp;vertex_input_state)
    .input_assembly_state(&amp;input_assembly_state)
    .viewport_state(&amp;viewport_state)
    .rasterization_state(&amp;rasterization_state)
    .multisample_state(&amp;multisample_state)
    .color_blend_state(&amp;color_blend_state)
</code></pre>
<p>Then we reference all of the structures describing the fixed-function stage.</p>
<pre><code class="language-rust noplaypen">    .layout(data.pipeline_layout)
</code></pre>
<p>After that comes the pipeline layout, which is a Vulkan handle rather than a struct reference.</p>
<pre><code class="language-rust noplaypen">    .render_pass(data.render_pass)
    .subpass(0);
</code></pre>
<p>And finally we have the reference to the render pass and the index of the sub pass where this graphics pipeline will be used. It is also possible to use other render passes with this pipeline instead of this specific instance, but they have to be <em>compatible</em> with <code>render_pass</code>. The requirements for compatibility are described <a href="https://www.khronos.org/registry/vulkan/specs/1.2/html/vkspec.html#renderpass-compatibility">here</a>, but we won't be using that feature in this tutorial.</p>
<pre><code class="language-rust noplaypen">    .base_pipeline_handle(vk::Pipeline::null()) // Optional.
    .base_pipeline_index(-1)                    // Optional.
</code></pre>
<p>There are actually two more parameters: <code>base_pipeline_handle</code> and <code>base_pipeline_index</code>. Vulkan allows you to create a new graphics pipeline by deriving from an existing pipeline. The idea of pipeline derivatives is that it is less expensive to set up pipelines when they have much functionality in common with an existing pipeline and switching between pipelines from the same parent can also be done quicker. You can either specify the handle of an existing pipeline with <code>base_pipeline_handle</code> or reference another pipeline that is about to be created by index with <code>base_pipeline_index</code>. Right now there is only a single pipeline, so we'll simply specify a null handle and an invalid index. These values are only used if the <code>vk::PipelineCreateFlags::DERIVATIVE</code> flag is also specified in the <code>flags</code> field of <code>vk::GraphicsPipelineCreateInfo</code>.</p>
<p>Now prepare for the final step by creating a field in <code>AppData</code> to hold the <code>vk::Pipeline</code> object:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    pipeline: vk::Pipeline,
}
</code></pre>
<p>And finally create the graphics pipeline:</p>
<pre><code class="language-rust noplaypen">data.pipeline = device.create_graphics_pipelines(
    vk::PipelineCache::null(), &amp;[info], None)?.0;
</code></pre>
<p>The <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.create_graphics_pipelines"><code>vk::DeviceV1_0::create_graphics_pipeline</code></a> function actually has more parameters than the usual object creation functions in Vulkan. It is designed to take multiple <code>vk::GraphicsPipelineCreateInfo</code> objects and create multiple <code>vk::Pipeline</code> objects in a single call.</p>
<p>The first parameter, for which we've passed the <code>vk::PipelineCache::null()</code> argument, references an optional <code>vk::PipelineCache</code> object. A pipeline cache can be used to store and reuse data relevant to pipeline creation across multiple calls to <code>vk::DeviceV1_0::create_graphics_pipeline</code> and even across program executions if the cache is stored to a file. This makes it possible to significantly speed up pipeline creation at a later time. We'll get into this in the pipeline cache chapter.</p>
<p>The graphics pipeline is required for all common drawing operations, so it should also only be destroyed at the end of the program in <code>App::destroy</code>:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.device.destroy_pipeline(self.data.pipeline, None);
        // ...
    }
}
</code></pre>
<p>Now run your program to confirm that all this hard work has resulted in a successful pipeline creation! We are already getting quite close to seeing something pop up on the screen. In the next couple of chapters we'll set up the actual framebuffers from the swapchain images and prepare the drawing commands.</p>
<h1><a class="header" href="#framebuffers" id="framebuffers">Framebuffers</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/13_framebuffers.rs">main.rs</a></p>
<p>We've talked a lot about framebuffers in the past few chapters and we've set up the render pass to expect a single framebuffer with the same format as the swapchain images, but we haven't actually created any yet.</p>
<p>The attachments specified during render pass creation are bound by wrapping them into a <code>vk::Framebuffer</code> object. A framebuffer object references all of the <code>vk::ImageView</code> objects that represent the attachments. In our case that will be only a single one: the color attachment. However, the image that we have to use for the attachment depends on which image the swapchain returns when we retrieve one for presentation. That means that we have to create a framebuffer for all of the images in the swapchain and use the one that corresponds to the retrieved image at drawing time.</p>
<p>To that end, create another <code>Vec</code> field in <code>AppData</code> to hold the framebuffers:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    framebuffers: Vec&lt;vk::Framebuffer&gt;,
}
</code></pre>
<p>We'll create the objects for this array in a new function <code>create_framebuffers</code> that is called from <code>App::create</code> right after creating the graphics pipeline:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...
        create_pipeline(&amp;device, &amp;mut data)?;
        create_framebuffers(&amp;device, &amp;mut data)?;
        // ...
    }
}

fn create_framebuffers(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    Ok(())
}
</code></pre>
<p>Start by mapping over the swapchain image views:</p>
<pre><code class="language-rust noplaypen">fn create_framebuffers(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    data.framebuffers = data
        .swapchain_image_views
        .iter()
        .map(|i| {

        })
        .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;()?;

    Ok(())
}
</code></pre>
<p>We'll then create a framebuffer for each image view:</p>
<pre><code class="language-rust noplaypen">let attachments = &amp;[*i];
let create_info = vk::FramebufferCreateInfo::builder()
    .render_pass(data.render_pass)
    .attachments(attachments)
    .width(data.swapchain_extent.width)
    .height(data.swapchain_extent.height)
    .layers(1);

device.create_framebuffer(&amp;create_info, None)
</code></pre>
<p>As you can see, creation of framebuffers is quite straightforward. We first need to specify with which <code>render_pass</code> the framebuffer needs to be compatible. You can only use a framebuffer with the render passes that it is compatible with, which roughly means that they use the same number and type of attachments.</p>
<p>The <code>attachments</code> field specifies the <code>vk::ImageView</code> objects that should be bound to the respective attachment descriptions in the render pass <code>attachment</code> array.</p>
<p>The <code>width</code> and <code>height</code> parameters are self-explanatory and <code>layers</code> refers to the number of layers in image arrays. Our swapchain images are single images, so the number of layers is <code>1</code>.</p>
<p>We should delete the framebuffers before the image views and render pass that they are based on, but only after we've finished rendering:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.data.framebuffers
            .iter()
            .for_each(|f| self.device.destroy_framebuffer(*f, None));
        // ...
    }
}
</code></pre>
<p>We've now reached the milestone where we have all of the objects that are required for rendering. In the next chapter we're going to write the first actual drawing commands.</p>
<h1><a class="header" href="#command-buffers" id="command-buffers">Command buffers</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/14_command_buffers.rs">main.rs</a></p>
<p>Commands in Vulkan, like drawing operations and memory transfers, are not executed directly using function calls. You have to record all of the operations you want to perform in command buffer objects. The advantage of this is that all of the hard work of setting up the drawing commands can be done in advance and in multiple threads. After that, you just have to tell Vulkan to execute the commands in the main loop.</p>
<h2><a class="header" href="#command-pools" id="command-pools">Command pools</a></h2>
<p>We have to create a command pool before we can create command buffers. Command pools manage the memory that is used to store the buffers and command buffers are allocated from them. Add a new <code>AppData</code> field to store a <code>vk::CommandPool</code>:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    command_pool: vk::CommandPool,
}
</code></pre>
<p>Then create a new function <code>create_command_pool</code> and call it from <code>App::create</code> after the framebuffers were created.</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...
        create_framebuffers(&amp;device, &amp;mut data)?;
        create_command_pool(&amp;instance, &amp;device, &amp;mut data)?;
        // ...
    }
}

fn create_command_pool(
    instance: &amp;Instance,
    device: &amp;Device,
    data: &amp;mut AppData,
) -&gt; Result&lt;()&gt; {
    Ok(())
}
</code></pre>
<p>Command pool creation only takes two parameters:</p>
<pre><code class="language-rust noplaypen">let indices = QueueFamilyIndices::get(instance, data, data.physical_device)?;

let info = vk::CommandPoolCreateInfo::builder()
    .flags(vk::CommandPoolCreateFlags::empty()) // Optional.
    .queue_family_index(indices.graphics);
</code></pre>
<p>Command buffers are executed by submitting them on one of the device queues, like the graphics and presentation queues we retrieved. Each command pool can only allocate command buffers that are submitted on a single type of queue. We're going to record commands for drawing, which is why we've chosen the graphics queue family.</p>
<p>There are three possible flags for command pools:</p>
<ul>
<li><code>vk::CommandPoolCreateFlags::TRANSIENT</code>: Hint that command buffers are rerecorded with new commands very often (may change memory allocation behavior)</li>
<li><code>vk::CommandPoolCreateFlags::RESET_COMMAND_BUFFER</code>: Allow command buffers to be rerecorded individually, without this flag they all have to be reset together</li>
<li><code>vk::CommandPoolCreateFlags::PROTECTED</code>: Creates &quot;protected&quot; command buffers which are stored in <a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/html/vkspec.html#memory-protected-access-rules">&quot;protected&quot; memory</a> where Vulkan prevents unauthorized operations from accessing the memory</li>
</ul>
<p>We will only record the command buffers at the beginning of the program and then execute them many times in the main loop and we don't need to protect our triangle with DRM, so we're not going to use any of these flags.</p>
<pre><code class="language-rust noplaypen">data.command_pool = device.create_command_pool(&amp;info, None)?;
</code></pre>
<p>Commands will be used throughout the program to draw things on the screen, so the pool should only be destroyed at the end:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.device.destroy_command_pool(self.data.command_pool, None);
        // ...
    }
}
</code></pre>
<h2><a class="header" href="#command-buffer-allocation" id="command-buffer-allocation">Command buffer allocation</a></h2>
<p>We can now start allocating command buffers and recording drawing commands in them. Because one of the drawing commands involves binding the right <code>vk::Framebuffer</code>, we'll actually have to record a command buffer for every image in the swapchain once again. To that end, create a list of <code>vk::CommandBuffer</code> objects as an <code>AppData</code> field. Command buffers will be automatically freed when their command pool is destroyed, so we don't need any explicit cleanup.</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    command_buffers: Vec&lt;vk::CommandBuffer&gt;,
}
</code></pre>
<p>We'll now start working on a <code>create_command_buffers</code> function that allocates and records the commands for each swapchain image.</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...
        create_command_pool(&amp;instance, &amp;device, &amp;mut data)?;
        create_command_buffers(&amp;device, &amp;mut data)?;
        // ...
    }
}

fn create_command_buffers(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    Ok(())
}
</code></pre>
<p>Command buffers are allocated with the <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.allocate_command_buffers"><code>vk::DeviceV1_0::allocate_command_buffers</code></a> function, which takes a <code>vk::CommandBufferAllocateInfo</code> struct as parameter that specifies the command pool and number of buffers to allocate:</p>
<pre><code class="language-rust noplaypen">let allocate_info = vk::CommandBufferAllocateInfo::builder()
    .command_pool(data.command_pool)
    .level(vk::CommandBufferLevel::PRIMARY)
    .command_buffer_count(data.framebuffers.len() as u32);

data.command_buffers = device.allocate_command_buffers(&amp;allocate_info)?;
</code></pre>
<p>The <code>level</code> parameter specifies if the allocated command buffers are primary or secondary command buffers.</p>
<ul>
<li><code>vk::CommandBufferLevel::PRIMARY</code>: Can be submitted to a queue for execution, but cannot be called from other command buffers.</li>
<li><code>vk::CommandBufferLevel::SECONDARY</code>: Cannot be submitted directly, but can be called from primary command buffers.</li>
</ul>
<p>We won't make use of the secondary command buffer functionality here, but you can imagine that it's helpful to reuse common operations from primary command buffers.</p>
<h2><a class="header" href="#starting-command-buffer-recording" id="starting-command-buffer-recording">Starting command buffer recording</a></h2>
<p>We begin recording a command buffer by calling <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.begin_command_buffer"><code>vk::DeviceV1_0::begin_command_buffer</code></a> with a small <code>vk::CommandBufferBeginInfo</code> structure as argument that specifies some details about the usage of this specific command buffer.</p>
<pre><code class="language-rust noplaypen">for (framebuffer, command_buffer) in data.framebuffers.iter().zip(data.command_buffers.iter()) {
    let inheritance = vk::CommandBufferInheritanceInfo::builder();

    let info = vk::CommandBufferBeginInfo::builder()
        .flags(vk::CommandBufferUsageFlags::empty()) // Optional.
        .inheritance_info(&amp;inheritance);             // Optional.

    device.begin_command_buffer(*command_buffer, &amp;info)?;
}
</code></pre>
<p>The <code>flags</code> parameter specifies how we're going to use the command buffer. The following values are available:</p>
<ul>
<li><code>vk::CommandBufferUsageFlags::ONE_TIME_SUBMIT</code>: The command buffer will be rerecorded right after executing it once.</li>
<li><code>vk::CommandBufferUsageFlags::RENDER_PASS_CONTINUE</code>: This is a secondary command buffer that will be entirely within a single render pass.</li>
<li><code>vk::CommandBufferUsageFlags::SIMULTANEOUS_USE</code>: The command buffer can be resubmitted while it is also already pending execution.</li>
</ul>
<p>None of these flags are applicable for us right now.</p>
<p>The <code>inheritance_info</code> parameter is only relevant for secondary command buffers. It specifies which state to inherit from the calling primary command buffers.</p>
<p>If the command buffer was already recorded once, then a call to <code>vk::DeviceV1_0::begin_command_buffer</code> will implicitly reset it. It's not possible to append commands to a buffer at a later time.</p>
<h2><a class="header" href="#starting-a-render-pass" id="starting-a-render-pass">Starting a render pass</a></h2>
<p>Before we can start a render pass we'll need to build some parameters.</p>
<pre><code class="language-rust noplaypen">let render_area = vk::Rect2D::builder()
    .offset(vk::Offset2D::default())
    .extent(data.swapchain_extent);
</code></pre>
<p>Here we define the size of the render area. The render area defines where shader loads and stores will take place during the execution of the render pass. The pixels outside this region will have undefined values. It should match the size of the attachments for best performance.</p>
<pre><code class="language-rust noplaypen">let clear_value = vk::ClearValue {
    color: vk::ClearColorValue {
        float32: [0.0, 0.0, 0.0, 1.0],
    },
};
</code></pre>
<p>Next we define a clear value that will be used to clear the framebuffer at the beginning of the render pass (because we used <code>vk::AttachmentLoadOp::CLEAR</code> when creating the render pass). <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/union.ClearValue.html"><code>vk::ClearValue</code></a> is a union that can be used to set clear values for color attachments or for depth/stencil attachments. Here we are setting the <code>color</code> field with a <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/union.ClearColorValue.html"><code>vk::ClearColorValue</code></a> union with 4 <code>f32</code>s that define a black clear color with 100% opacity.</p>
<p>Drawing starts by beginning the render pass with <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.cmd_begin_render_pass"><code>DeviceV1_0::begin_render_pass</code></a>. The render pass is configured using some parameters in a <code>vk::RenderPassBeginInfo</code> struct.</p>
<pre><code class="language-rust noplaypen">let clear_values = &amp;[clear_value];
let info = vk::RenderPassBeginInfo::builder()
    .render_pass(data.render_pass)
    .framebuffer(*framebuffer)
    .render_area(render_area)
    .clear_values(clear_values);
</code></pre>
<p>The first parameters are the render pass itself and the attachments to bind. We created a framebuffer for each swapchain image that specifies it as color attachment. Then we provide the previously constructed render area and clear value.</p>
<pre><code class="language-rust noplaypen">device.cmd_begin_render_pass(
    *command_buffer, &amp;info, vk::SubpassContents::INLINE);
</code></pre>
<p>The render pass can now begin. All of the functions that record commands can be recognized by their <code>cmd_</code> prefix. They all return <code>()</code>, so there is no need for error handling until we've finished recording.</p>
<p>The first parameter for every command is always the command buffer to record the command to. The second parameter specifies the details of the render pass we've just provided. The final parameter controls how the drawing commands within the render pass will be provided. It can have one of two values:</p>
<ul>
<li><code>vk::SubpassContents::INLINE</code>: The render pass commands will be embedded in the primary command buffer itself and no secondary command buffers will be executed.</li>
<li><code>vk::SubpassContents::SECONDARY_COMMAND_BUFFERS</code>: The render pass commands will be executed from secondary command buffers.</li>
</ul>
<p>We will not be using secondary command buffers, so we'll go with the first option.</p>
<h2><a class="header" href="#basic-drawing-commands" id="basic-drawing-commands">Basic drawing commands</a></h2>
<p>We can now bind the graphics pipeline:</p>
<pre><code class="language-rust noplaypen">device.cmd_bind_pipeline(
    *command_buffer, vk::PipelineBindPoint::GRAPHICS, data.pipeline);
</code></pre>
<p>The second parameter specifies if the pipeline object is a graphics or compute pipeline. We've now told Vulkan which operations to execute in the graphics pipeline and which attachment to use in the fragment shader, so all that remains is telling it to draw the triangle:</p>
<pre><code class="language-rust noplaypen">device.cmd_draw(*command_buffer, 3, 1, 0, 0);
</code></pre>
<p>The actual drawing function is a bit anticlimactic, but it's so simple because of all the information we specified in advance. It has the following parameters, aside from the command buffer:</p>
<ul>
<li><code>vertex_count</code>: Even though we don't have a vertex buffer, we technically still have 3 vertices to draw.</li>
<li><code>instance_count</code>: Used for instanced rendering, use <code>1</code> if you're not doing that.</li>
<li><code>first_vertex</code>: Used as an offset into the vertex buffer, defines the lowest value of <code>gl_VertexIndex</code>.</li>
<li><code>first_instance</code>: Used as an offset for instanced rendering, defines the lowest value of <code>gl_InstanceIndex</code>.</li>
</ul>
<h2><a class="header" href="#finishing-up" id="finishing-up">Finishing up</a></h2>
<p>The render pass can now be ended:</p>
<pre><code class="language-rust noplaypen">device.cmd_end_render_pass(*command_buffer);
</code></pre>
<p>And we've finished recording the command buffer:</p>
<pre><code class="language-rust noplaypen">device.end_command_buffer(*command_buffer)?;
</code></pre>
<p>In the next chapter we'll write the code for the main loop, which will acquire an image from the swapchain, execute the right command buffer and return the finished image to the swapchain.</p>
<h1><a class="header" href="#rendering-and-presentation" id="rendering-and-presentation">Rendering and presentation</a></h1>
<p><strong>Code:</strong> <a href="https://github.com/KyleMayes/vulkanalia/tree/master/tutorial/src/15_hello_triangle.rs">main.rs</a></p>
<p>This is the chapter where everything is going to come together. We're going to implement the <code>App::render</code> function that will be called from the main loop to put the triangle on the screen.</p>
<h2><a class="header" href="#synchronization" id="synchronization">Synchronization</a></h2>
<p>The <code>App::render</code> function will perform the following operations:</p>
<ul>
<li>Acquire an image from the swapchain</li>
<li>Execute the command buffer with that image as attachment in the framebuffer</li>
<li>Return the image to the swapchain for presentation</li>
</ul>
<p>Each of these events is set in motion using a single function call, but they are executed asynchronously. The function calls will return before the operations are actually finished and the order of execution is also undefined. That is unfortunate, because each of the operations depends on the previous one finishing.</p>
<p>There are two ways of synchronizing swapchain events: fences and semaphores. They're both objects that can be used for coordinating operations by having one operation signal and another operation wait for a fence or semaphore to go from the unsignaled to signaled state.</p>
<p>The difference is that the state of fences can be accessed from your program using calls like <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.wait_for_fences"><code>vk::DeviceV1_0::wait_for_fences</code></a> and semaphores cannot be. Fences are mainly designed to synchronize your application itself with rendering operation, whereas semaphores are used to synchronize operations within or across command queues. We want to synchronize the queue operations of draw commands and presentation, which makes semaphores the best fit.</p>
<h2><a class="header" href="#semaphores" id="semaphores">Semaphores</a></h2>
<p>We'll need one semaphore to signal that an image has been acquired and is ready for rendering, and another one to signal that rendering has finished and presentation can happen. Create two <code>AppData</code> fields to store these semaphore objects:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    image_available_semaphore: vk::Semaphore,
    render_finished_semaphore: vk::Semaphore,
}
</code></pre>
<p>To create the semaphores, we'll add the last <code>create</code> function for this part of the tutorial, <code>create_sync_objects</code>:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn create(window: &amp;Window) -&gt; Result&lt;Self&gt; {
        // ...
        create_command_buffers(&amp;device, &amp;mut data)?;
        create_sync_objects(&amp;device, &amp;mut data)?;
        // ...
    }
}

fn create_sync_objects(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    Ok(())
}
</code></pre>
<p>Creating semaphores requires filling in the <code>vk::SemaphoreCreateInfo</code>, but in the current version of the API it doesn't actually have any required fields.</p>
<pre><code class="language-rust noplaypen">fn create_sync_objects(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    let semaphore_info = vk::SemaphoreCreateInfo::builder();

    Ok(())
}
</code></pre>
<p>Future versions of the Vulkan API or extensions may add functionality for the <code>flags</code> and <code>p_next</code> parameters like it does for the other structures. Creating the semaphores follows the familiar pattern:</p>
<pre><code class="language-rust noplaypen">data.image_available_semaphore = device.create_semaphore(&amp;semaphore_info, None)?;
data.render_finished_semaphore = device.create_semaphore(&amp;semaphore_info, None)?;
</code></pre>
<p>The semaphores should be cleaned up at the end of the program, when all commands have finished and no more synchronization is necessary:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.device.destroy_semaphore(self.data.render_finished_semaphore, None);
        self.device.destroy_semaphore(self.data.image_available_semaphore, None);
        // ...
    }
}
</code></pre>
<h2><a class="header" href="#acquiring-an-image-from-the-swapchain" id="acquiring-an-image-from-the-swapchain">Acquiring an image from the swapchain</a></h2>
<p>As mentioned before, the first thing we need to do in the <code>App::render</code> function is acquire an image from the swapchain. Recall that the swapchain is an extension feature, so we must use a function with the <code>*_khr</code> naming convention:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
        let image_index = self
            .device
            .acquire_next_image_khr(
                self.data.swapchain,
                u64::max_value(),
                self.data.image_available_semaphore,
                vk::Fence::null(),
            )?
            .0 as usize;

        Ok(())
    }
}
</code></pre>
<p>The first parameter of <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.KhrSwapchainExtension.html#method.acquire_next_image_khr"><code>vk::KhrSwapchainExtension::acquire_next_image_khr</code></a> is the swapchain from which we wish to acquire an image. The second parameter specifies a timeout in nanoseconds for an image to become available. Using the maximum value of a 64 bit unsigned integer disables the timeout.</p>
<p>The next two parameters specify synchronization objects that are to be signaled when the presentation engine is finished using the image. That's the point in time where we can start drawing to it. It is possible to specify a semaphore, fence or both. We're going to use our <code>image_available_semaphore</code> for that purpose here.</p>
<p>This function returns the index of the swapchain image that has become available. The index refers to the <code>vk::Image</code> in our <code>swapchain_images</code> array. We're going to use that index to pick the right command buffer.</p>
<h2><a class="header" href="#submitting-the-command-buffer" id="submitting-the-command-buffer">Submitting the command buffer</a></h2>
<p>Queue submission and synchronization is configured through parameters in the <code>vk::SubmitInfo</code> structure.</p>
<pre><code class="language-rust noplaypen">let wait_semaphores = &amp;[self.data.image_available_semaphore];
let wait_stages = &amp;[vk::PipelineStageFlags::COLOR_ATTACHMENT_OUTPUT];
let command_buffers = &amp;[self.data.command_buffers[image_index as usize]];
let signal_semaphores = &amp;[self.data.render_finished_semaphore];
let submit_info = vk::SubmitInfo::builder()
    .wait_semaphores(wait_semaphores)
    .wait_dst_stage_mask(wait_stages)
    .command_buffers(command_buffers)
    .signal_semaphores(signal_semaphores);
</code></pre>
<p>The first two parameters, <code>wait_semaphores</code> and <code>wait_dst_stage_mask</code>, specifies which semaphores to wait on before execution begins and in which stage(s) of the pipeline to wait. We want to wait with writing colors to the image until it's available, so we're specifying the stage of the graphics pipeline that writes to the color attachment. That means that theoretically the implementation can already start executing our vertex shader and such while the image is not yet available. Each entry in the <code>wait_stages</code> array corresponds to the semaphore with the same index in <code>wait_semaphores</code>.</p>
<p>The next parameter, <code>command_buffers</code>, specifies which command buffers to actually submit for execution. As mentioned earlier, we should submit the command buffer that binds the swapchain image we just acquired as color attachment.</p>
<p>Lastly <code>signal_semaphores</code> specifies which semaphores to signal once the command buffer(s) have finished execution. In our case we're using the <code>render_finished_semaphore</code> for that purpose.</p>
<pre><code class="language-rust noplaypen">self.device.queue_submit(
    self.data.graphics_queue, &amp;[submit_info], vk::Fence::null())?;
</code></pre>
<p>We can now submit the command buffer to the graphics queue using <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.queue_submit"><code>vk::DeviceV1_0::queue_submit</code></a>. The function takes an array of <code>vk::SubmitInfo</code> structures as argument for efficiency when the workload is much larger. The last parameter references an optional fence that will be signaled when the command buffers finish execution. We're using semaphores for synchronization, so we'll just pass a <code>vk::Fence::null()</code>.</p>
<h2><a class="header" href="#subpass-dependencies" id="subpass-dependencies">Subpass dependencies</a></h2>
<p>Remember that the subpasses in a render pass automatically take care of image layout transitions. These transitions are controlled by <em>subpass dependencies</em>, which specify memory and execution dependencies between subpasses. We have only a single subpass right now, but the operations right before and right after this subpass also count as implicit &quot;subpasses&quot;.</p>
<p>There are two built-in dependencies that take care of the transition at the start of the render pass and at the end of the render pass, but the former does not occur at the right time. It assumes that the transition occurs at the start of the pipeline, but we haven't acquired the image yet at that point! There are two ways to deal with this problem. We could change the <code>wait_stages</code> for the <code>image_available_semaphore</code> to <code>vk::PipelineStageFlags::TOP_OF_PIPE</code> to ensure that the render passes don't begin until the image is available, or we can make the render pass wait for the <code>vk::PipelineStageFlags::COLOR_ATTACHMENT_OUTPUT</code> stage. I've decided to go with the second option here, because it's a good excuse to have a look at subpass dependencies and how they work.</p>
<p>Subpass dependencies are specified in <code>vk::SubpassDependency</code> structs. Go to the <code>create_render_pass</code> function and add one:</p>
<pre><code class="language-rust noplaypen">let dependency = vk::SubpassDependency::builder()
    .src_subpass(vk::SUBPASS_EXTERNAL)
    .dst_subpass(0)
    // continued...
</code></pre>
<p>The first two fields specify the indices of the dependency and the dependent subpass. The special value <code>vk::SUBPASS_EXTERNAL</code> refers to the implicit subpass before or after the render pass depending on whether it is specified in <code>src_subpass</code> or <code>dst_subpass</code>. The index <code>0</code> refers to our subpass, which is the first and only one. The <code>dst_subpass</code> must always be higher than <code>src_subpass</code> to prevent cycles in the dependency graph (unless one of the subpasses is <code>vk::SUBPASS_EXTERNAL</code>).</p>
<pre><code class="language-rust noplaypen">    .src_stage_mask(vk::PipelineStageFlags::COLOR_ATTACHMENT_OUTPUT)
    .src_access_mask(vk::AccessFlags::empty())
</code></pre>
<p>The next two fields specify the operations to wait on and the stages in which these operations occur. We need to wait for the swapchain to finish reading from the image before we can access it. This can be accomplished by waiting on the color attachment output stage itself.</p>
<pre><code class="language-rust noplaypen">    .dst_stage_mask(vk::PipelineStageFlags::COLOR_ATTACHMENT_OUTPUT)
    .dst_access_mask(vk::AccessFlags::COLOR_ATTACHMENT_WRITE)
</code></pre>
<p>The operations that should wait on this are in the color attachment stage and involve the writing of the color attachment. These settings will prevent the transition from happening until it's actually necessary (and allowed): when we want to start writing colors to it.</p>
<pre><code class="language-rust noplaypen">let attachments = &amp;[color_attachment];
let subpasses = &amp;[subpass];
let dependencies = &amp;[dependency];
let info = vk::RenderPassCreateInfo::builder()
    .attachments(attachments)
    .subpasses(subpasses)
    .dependencies(dependencies);
</code></pre>
<p>The <code>vk::RenderPassCreateInfo</code> struct has a field to specify an array of dependencies.</p>
<h2><a class="header" href="#presentation" id="presentation">Presentation</a></h2>
<p>The last step of drawing a frame is submitting the result back to the swapchain to have it eventually show up on the screen. Presentation is configured through a <code>vk::PresentInfoKHR</code> structure at the end of the <code>App::render</code> function.</p>
<pre><code class="language-rust noplaypen">let swapchains = &amp;[self.data.swapchain];
let image_indices = &amp;[image_index as u32];
let present_info = vk::PresentInfoKHR::builder()
    .wait_semaphores(signal_semaphores)
    .swapchains(swapchains)
    .image_indices(image_indices);
</code></pre>
<p>The first parameter specifies which semaphores to wait on before presentation can happen, just like <code>vk::SubmitInfo</code>.</p>
<p>The next two parameters specify the swapchains to present images to and the index of the image for each swapchain. This will almost always be a single one.</p>
<p>There is one last optional parameter called <code>results</code>. It allows you to specify an array of <code>vk::Result</code> values to check for every individual swapchain if presentation was successful. It's not necessary if you're only using a single swapchain, because you can simply use the return value of the present function.</p>
<pre><code class="language-rust noplaypen">self.device.queue_present_khr(self.data.present_queue, &amp;present_info)?;
</code></pre>
<p>The <a href="https://docs.rs/vulkanalia/0.1.0/vulkanalia/vk/trait.KhrSwapchainExtension.html#method.queue_present_khr"><code>vk::KhrSwapchainExtension::queue_present_khr</code></a> function submits the request to present an image to the swapchain. We'll modify the error handling for both <code>vk::KhrSwapchainExtension::acquire_next_image_khr</code> and <code>vk::KhrSwapchainExtension::queue_present_khr</code> in the next chapter, because their failure does not necessarily mean that the program should terminate, unlike the functions we've seen so far.</p>
<p>If you did everything correctly up to this point, then you should now see something resembling the following when you run your program:</p>
<p><img src="drawing/../images/triangle.png" alt="" /></p>
<blockquote>
<p>This colored triangle may look a bit different from the one you're used to seeing in graphics tutorials. That's because this tutorial lets the shader interpolate in linear color space and converts to sRGB color space afterwards. See <a href="https://medium.com/@heypete/hello-triangle-meet-swift-and-wide-color-6f9e246616d9">this blog post</a> for a discussion of the difference.</p>
</blockquote>
<p>Yay! Unfortunately, you'll see that when validation layers are enabled, the program crashes as soon as you close it. The messages printed to the terminal from <code>debug_callback</code> tell us why:</p>
<p><img src="drawing/../images/semaphore_in_use.png" alt="" /></p>
<p>Remember that all of the operations in <code>App::render</code> are asynchronous. That means that when we call <code>App::destroy</code> before exiting the loop in <code>main</code>, drawing and presentation operations may still be going on. Cleaning up resources while that is happening is a bad idea.</p>
<p>To fix that problem, we should wait for the logical device to finish operations using <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.device_wait_idle"><code>vk::DeviceV1_0::device_wait_idle</code></a> before calling <code>App::destroy</code>:</p>
<pre><code class="language-rust noplaypen">Event::WindowEvent { event: WindowEvent::CloseRequested, .. } =&gt; {
    destroying = true;
    *control_flow = ControlFlow::Exit;
    app.device.device_wait_idle().unwrap();
    app.destroy();
}
</code></pre>
<p>You can also wait for operations in a specific command queue to be finished with <a href="https://docs.rs/vulkanalia/latest/vulkanalia/vk/trait.DeviceV1_0.html#method.queue_wait_idle"><code>vk::DeviceV1_0::queue_wait_idle</code></a>. These functions can be used as a very rudimentary way to perform synchronization. You'll see that the program now exits without problems when closing the window.</p>
<h2><a class="header" href="#frames-in-flight" id="frames-in-flight">Frames in flight</a></h2>
<p>If you run your application with validation layers enabled now you may either get errors or notice that the memory usage slowly grows. The reason for this is that the application is rapidly submitting work in the <code>App::render</code> function, but doesn't actually check if any of it finishes. If the CPU is submitting work faster than the GPU can keep up with then the queue will slowly fill up with work. Worse, even, is that we are reusing the <code>image_available_semaphore</code> and <code>render_finished_semaphore</code> semaphores, along with the command buffers, for multiple frames at the same time!</p>
<p>The easy way to solve this is to wait for work to finish right after submitting it, for example by using <code>vk::DeviceV1_0::queue_wait_idle</code>:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
        // ...

        self.device.queue_present_khr(self.data.present_queue, &amp;present_info)?;
        self.device.queue_wait_idle(self.data.present_queue)?;

        Ok(())
    }
}
</code></pre>
<p>However, we are likely not optimally using the GPU in this way, because the whole graphics pipeline is only used for one frame at a time right now. The stages that the current frame has already progressed through are idle and could already be used for a next frame. We will now extend our application to allow for multiple frames to be <em>in-flight</em> while still bounding the amount of work that piles up.</p>
<p>Start by adding a constant at the top of the program that defines how many frames should be processed concurrently:</p>
<pre><code class="language-rust noplaypen">const MAX_FRAMES_IN_FLIGHT: usize = 2;
</code></pre>
<p>Each frame should have its own set of semaphores in <code>AppData</code>:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    image_available_semaphores: Vec&lt;vk::Semaphore&gt;,
    render_finished_semaphores: Vec&lt;vk::Semaphore&gt;,
}
</code></pre>
<p>The <code>create_sync_objects</code> function should be changed to create all of these:</p>
<pre><code class="language-rust noplaypen">fn create_sync_objects(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    let semaphore_info = vk::SemaphoreCreateInfo::builder();

    for _ in 0..MAX_FRAMES_IN_FLIGHT {
        data.image_available_semaphores
            .push(device.create_semaphore(&amp;semaphore_info, None)?);
        data.render_finished_semaphores
            .push(device.create_semaphore(&amp;semaphore_info, None)?);
    }

    Ok(())
}
</code></pre>
<p>Similarly, they should also all be cleaned up:</p>
<pre><code class="language-rust noplaypen">impl App {
    fn destroy(&amp;mut self) {
        self.data.render_finished_semaphores
            .iter()
            .for_each(|s| self.device.destroy_semaphore(*s, None));
        self.data.image_available_semaphores
            .iter()
            .for_each(|s| self.device.destroy_semaphore(*s, None));
        // ...
    }
}
</code></pre>
<p>To use the right pair of semaphores every time, we need to keep track of the current frame. We will use a frame index for that purpose which we'll add to <code>App</code> (initialize it to <code>0</code> in <code>App::create</code>):</p>
<pre><code class="language-rust noplaypen">struct App {
    // ...
    frame: usize,
}
</code></pre>
<p>The <code>App::render</code> function can now be modified to use the right objects:</p>
<pre><code class="language-rust noplaypen">fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
    let image_index = self
        .device
        .acquire_next_image_khr(
            self.data.swapchain,
            u64::max_value(),
            self.data.image_available_semaphores[self.frame],
            vk::Fence::null(),
        )?
        .0 as usize;

    // ...

    let wait_semaphores = &amp;[self.data.image_available_semaphores[self.frame]];

    // ...

    let signal_semaphores = &amp;[self.data.render_finished_semaphores[self.frame]];

    // ...

    Ok(())
}
</code></pre>
<p>Of course, we shouldn't forget to advance to the next frame every time:</p>
<pre><code class="language-rust noplaypen">fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
    // ...

    self.frame = (self.frame + 1) % MAX_FRAMES_IN_FLIGHT;

    Ok(())
}
</code></pre>
<p>By using the modulo (%) operator, we ensure that the frame index loops around after every <code>MAX_FRAMES_IN_FLIGHT</code> enqueued frames.</p>
<p>Although we've now set up the required objects to facilitate processing of multiple frames simultaneously, we still don't actually prevent more than <code>MAX_FRAMES_IN_FLIGHT</code> from being submitted. Right now there is only GPU-GPU synchronization and no CPU-GPU synchronization going on to keep track of how the work is going. We may be using the frame #0 objects while frame #0 is still in-flight!</p>
<p>To perform CPU-GPU synchronization, Vulkan offers a second type of synchronization primitive called <em>fences</em>. Fences are similar to semaphores in the sense that they can be signaled and waited for, but this time we actually wait for them in our own code. We'll first create a fence for each frame in <code>AppData</code>:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    in_flight_fences: Vec&lt;vk::Fence&gt;,
}
</code></pre>
<p>We'll create the fences together with the semaphores in the <code>create_sync_objects</code> function:</p>
<pre><code class="language-rust noplaypen">fn create_sync_objects(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    let semaphore_info = vk::SemaphoreCreateInfo::builder();
    let fence_info = vk::FenceCreateInfo::builder();

    for _ in 0..MAX_FRAMES_IN_FLIGHT {
        data.image_available_semaphores
            .push(device.create_semaphore(&amp;semaphore_info, None)?);
        data.render_finished_semaphores
            .push(device.create_semaphore(&amp;semaphore_info, None)?);

        data.in_flight_fences.push(device.create_fence(&amp;fence_info, None)?);
    }

    Ok(())
}
</code></pre>
<p>The creation of fences (<code>vk::Fence</code>) is very similar to the creation of semaphores. Also make sure to clean up the fences in <code>App::destroy</code>:</p>
<pre><code class="language-rust noplaypen">fn destroy(&amp;mut self) {
    self.data.in_flight_fences
        .iter()
        .for_each(|f| self.device.destroy_fence(*f, None));
    // ...
}
</code></pre>
<p>We will now change <code>App::render</code> to use the fences for synchronization. The <code>device.queue_submit(...)</code> call includes an optional parameter to pass a fence that should be signaled when the command buffer finishes executing. We can use this to signal that a frame has finished.</p>
<pre><code class="language-rust noplaypen">fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
    // ...

    self.device.queue_submit(
        self.data.graphics_queue,
        &amp;[submit_info],
        self.data.in_flight_fences[self.frame],
    )?;

    // ...
}
</code></pre>
<p>Now the only thing remaining is to change the beginning of <code>App::render</code> to wait for the frame to be finished:</p>
<pre><code class="language-rust noplaypen">fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
    self.device.wait_for_fences(
        &amp;[self.data.in_flight_fences[self.frame]],
        true,
        u64::max_value(),
    )?;

    self.device.reset_fences(&amp;[self.data.in_flight_fences[self.frame]])?;

    // ...
}
</code></pre>
<p>The <code>vk::DeviceV1_0::wait_for_fences</code> function takes an array of fences and waits for either any or all of them to be signaled before returning. The <code>true</code> we pass here indicates that we want to wait for all fences, but in the case of a single one it obviously doesn't matter. Just like <code>vk::KhrSwapchainExtension::acquire_next_image_khr</code> this function also takes a timeout. Unlike the semaphores, we manually need to restore the fence to the unsignaled state by resetting it with the <code>vk::DeviceV1_0::reset_fences</code> call.</p>
<p>If you run the program now, you'll notice something something strange. The application no longer seems to be rendering anything and might even be frozen.</p>
<p>That means that we're waiting for a fence that has not been submitted. The problem here is that, by default, fences are created in the unsignaled state. That means that <code>vk::DeviceV1_0::wait_for_fences</code> will wait forever if we haven't used the fence before. To solve that, we can change the fence creation to initialize it in the signaled state as if we had rendered an initial frame that finished:</p>
<pre><code class="language-rust noplaypen">fn create_sync_objects(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    // ...

    let fence_info = vk::FenceCreateInfo::builder()
        .flags(vk::FenceCreateFlags::SIGNALED);

    // ...
}
</code></pre>
<p>The memory leak is gone now, but the program is not quite working correctly yet. If <code>MAX_FRAMES_IN_FLIGHT</code> is higher than the number of swapchain images or <code>vk::KhrSwapchainExtension::acquire_next_image_khr</code> returns images out-of-order then it's possible that we may start rendering to a swapchain image that is already <em>in flight</em>. To avoid this, we need to track for each swapchain image if a frame in flight is currently using it. This mapping will refer to frames in flight by their fences so we'll immediately have a synchronization object to wait on before a new frame can use that image.</p>
<p>First add a new list called <code>images_in_flight</code> to <code>AppData</code> to track this:</p>
<pre><code class="language-rust noplaypen">struct AppData {
    // ...
    in_flight_fences: Vec&lt;vk::Fence&gt;,
    images_in_flight: Vec&lt;vk::Fence&gt;,
}
</code></pre>
<p>Prepare it in <code>create_sync_objects</code>:</p>
<pre><code class="language-rust noplaypen">fn create_sync_objects(device: &amp;Device, data: &amp;mut AppData) -&gt; Result&lt;()&gt; {
    // ...

    data.images_in_flight = data.swapchain_images
        .iter()
        .map(|_| vk::Fence::null())
        .collect();

    Ok(())
}
</code></pre>
<p>Initially not a single frame is using an image so we explicitly initialize it to <em>no fence</em>. Now we'll modify <code>App::render</code> to wait on any previous frame that is using the image that we've just been assigned for the new frame:</p>
<pre><code class="language-rust noplaypen">fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
    // ...

    let image_index = self
        .device
        .acquire_next_image_khr(
            self.data.swapchain,
            u64::max_value(),
            self.data.image_available_semaphores[self.frame],
            vk::Fence::null(),
        )?
        .0 as usize;

    if !self.data.images_in_flight[image_index as usize].is_null() {
        self.device.wait_for_fences(
            &amp;[self.data.images_in_flight[image_index as usize]],
            true,
            u64::max_value(),
        )?;
    }

    self.data.images_in_flight[image_index as usize] =
        self.data.in_flight_fences[self.frame];

    // ...
}
</code></pre>
<p>Because we now have more calls to <code>vk::DeviceV1_0::wait_for_fences</code>, the <code>vk::DeviceV1_0::reset_fences</code> call should be <strong>moved</strong>. It's best to simply call it right before actually using the fence:</p>
<pre><code class="language-rust noplaypen">fn render(&amp;mut self, window: &amp;Window) -&gt; Result&lt;()&gt; {
    // ...

    self.device.reset_fences(&amp;[self.data.in_flight_fences[self.frame]])?;

    self.device.queue_submit(
        self.data.graphics_queue,
        &amp;[submit_info],
        self.data.in_flight_fences[self.frame],
    )?;

    // ...
}
</code></pre>
<p>We've now implemented all the needed synchronization to ensure that there are no more than two frames of work enqueued and that these frames are not accidentally using the same image. Note that it is fine for other parts of the code, like the final cleanup, to rely on more rough synchronization like <code>vkDeviceWaitIdle</code>. You should decide on which approach to use based on performance requirements.</p>
<p>To learn more about synchronization through examples, have a look at <a href="https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples#swapchain-image-acquire-and-present">this extensive overview</a> by Khronos.</p>
<h2><a class="header" href="#conclusion-2" id="conclusion-2">Conclusion</a></h2>
<p>A little over 600 lines of code later, we've finally gotten to the stage of seeing something pop up on the screen! Bootstrapping a Vulkan program is definitely a lot of work, but the take-away message is that Vulkan gives you an immense amount of control through its explicitness. I recommend you to take some time now to reread the code and build a mental model of the purpose of all of the Vulkan objects in the program and how they relate to each other. We'll be building on top of that knowledge to extend the functionality of the program from this point on.</p>
<p>In the next chapter we'll deal with one more small thing that is required for a well-behaved Vulkan program.</p>
<h1><a class="header" href="#recreation" id="recreation">Recreation</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#vertex-input-description" id="vertex-input-description">Vertex input description</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#vertex-buffer-creation" id="vertex-buffer-creation">Vertex buffer creation</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#staging-buffer" id="staging-buffer">Staging buffer</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#index-buffer" id="index-buffer">Index buffer</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#descriptor-layout-and-buffer" id="descriptor-layout-and-buffer">Descriptor layout and buffer</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#descriptor-pool-and-sets" id="descriptor-pool-and-sets">Descriptor pool and sets</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#images" id="images">Images</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#image-view-and-sampler" id="image-view-and-sampler">Image view and sampler</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#combined-image-sampler" id="combined-image-sampler">Combined image sampler</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#depth-buffering" id="depth-buffering">Depth buffering</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#loading-models" id="loading-models">Loading models</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#generating-mipmaps" id="generating-mipmaps">Generating mipmaps</a></h1>
<p>Coming soon™.</p>
<h1><a class="header" href="#multisampling-1" id="multisampling-1">Multisampling</a></h1>
<p>Coming soon™.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
